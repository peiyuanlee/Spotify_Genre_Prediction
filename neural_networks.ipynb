{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daUPq1nUR5Cq"
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "4SiNHMHaR-rA",
    "outputId": "3f631486-0edf-42a0-9e73-ba8d9c3a89b5"
   },
   "outputs": [],
   "source": [
    "from nn_models import Four_Layer_NN, Six_Layer_NN, Ten_Layer_NN\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from preprocessing import preprocessing_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_raw = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")\n",
    "df = preprocessing_data(df_raw)\n",
    "genres = df['track_genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbUwhfrOQX7I"
   },
   "source": [
    "From the feature importance derived from random forests, we select the top 10 features to reduce noise from irrelevant features. To optimize model performance, we designed three feedforward neural network architectures with 4, 6, and 10 layers, incorporating dropout and batch normalization layers to mitigate overfitting and stabilize training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8oIqd7V6m3l"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(['track_genre', 'mode', 'explicit', 'liveness', 'key', 'time_signature'], axis = 1)\n",
    "y = LabelEncoder().fit_transform(df['track_genre'])\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=2000, random_state=123, stratify=y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=1000, random_state=123, stratify=y_temp)\n",
    "\n",
    "# Convert to categorical (onehot encoding matrices)\n",
    "y_train = to_categorical(y_train, num_classes=20)\n",
    "y_valid = to_categorical(y_valid, num_classes=20)\n",
    "y_test = to_categorical(y_test, num_classes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_GeEZ-zMABT"
   },
   "source": [
    "### Four Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "S8dQ-i5Qq4SG",
    "outputId": "3427165b-d8b2-45c3-b500-941bda1402e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1780 - loss: 3.0373 - val_accuracy: 0.4450 - val_loss: 2.0548\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3697 - loss: 2.2233 - val_accuracy: 0.5010 - val_loss: 1.8159\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4088 - loss: 2.0432 - val_accuracy: 0.5120 - val_loss: 1.7264\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4218 - loss: 1.9605 - val_accuracy: 0.5350 - val_loss: 1.6675\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4351 - loss: 1.9100 - val_accuracy: 0.5220 - val_loss: 1.6223\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4328 - loss: 1.8601 - val_accuracy: 0.5340 - val_loss: 1.5859\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4434 - loss: 1.8339 - val_accuracy: 0.5450 - val_loss: 1.5718\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4552 - loss: 1.7982 - val_accuracy: 0.5500 - val_loss: 1.5483\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4488 - loss: 1.8050 - val_accuracy: 0.5480 - val_loss: 1.5321\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4444 - loss: 1.8070 - val_accuracy: 0.5560 - val_loss: 1.5098\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4543 - loss: 1.7758 - val_accuracy: 0.5430 - val_loss: 1.5140\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4609 - loss: 1.7486 - val_accuracy: 0.5510 - val_loss: 1.4944\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4737 - loss: 1.7286 - val_accuracy: 0.5460 - val_loss: 1.4955\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4642 - loss: 1.7360 - val_accuracy: 0.5560 - val_loss: 1.4781\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4625 - loss: 1.7296 - val_accuracy: 0.5500 - val_loss: 1.4666\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4641 - loss: 1.7205 - val_accuracy: 0.5650 - val_loss: 1.4635\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4673 - loss: 1.7279 - val_accuracy: 0.5570 - val_loss: 1.4488\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4713 - loss: 1.7102 - val_accuracy: 0.5690 - val_loss: 1.4618\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4693 - loss: 1.7182 - val_accuracy: 0.5670 - val_loss: 1.4502\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4713 - loss: 1.7033 - val_accuracy: 0.5710 - val_loss: 1.4403\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4721 - loss: 1.6916 - val_accuracy: 0.5690 - val_loss: 1.4354\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4700 - loss: 1.7030 - val_accuracy: 0.5650 - val_loss: 1.4417\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4709 - loss: 1.6914 - val_accuracy: 0.5530 - val_loss: 1.4322\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4632 - loss: 1.7032 - val_accuracy: 0.5530 - val_loss: 1.4329\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4709 - loss: 1.6910 - val_accuracy: 0.5720 - val_loss: 1.4180\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4679 - loss: 1.6940 - val_accuracy: 0.5620 - val_loss: 1.4217\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4681 - loss: 1.6965 - val_accuracy: 0.5690 - val_loss: 1.4236\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4787 - loss: 1.6667 - val_accuracy: 0.5620 - val_loss: 1.4146\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4741 - loss: 1.6910 - val_accuracy: 0.5610 - val_loss: 1.4112\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4745 - loss: 1.6753 - val_accuracy: 0.5860 - val_loss: 1.4032\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4762 - loss: 1.6745 - val_accuracy: 0.5660 - val_loss: 1.4000\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4665 - loss: 1.6815 - val_accuracy: 0.5720 - val_loss: 1.4067\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4861 - loss: 1.6515 - val_accuracy: 0.5830 - val_loss: 1.3895\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4775 - loss: 1.6615 - val_accuracy: 0.5840 - val_loss: 1.3907\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4777 - loss: 1.6593 - val_accuracy: 0.5710 - val_loss: 1.3956\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4721 - loss: 1.6697 - val_accuracy: 0.5650 - val_loss: 1.4013\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4782 - loss: 1.6542 - val_accuracy: 0.5680 - val_loss: 1.3793\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4832 - loss: 1.6593 - val_accuracy: 0.5790 - val_loss: 1.3882\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4794 - loss: 1.6579 - val_accuracy: 0.5730 - val_loss: 1.4000\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4767 - loss: 1.6574 - val_accuracy: 0.5640 - val_loss: 1.3908\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4720 - loss: 1.6791 - val_accuracy: 0.5710 - val_loss: 1.3946\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4739 - loss: 1.6583 - val_accuracy: 0.5750 - val_loss: 1.3806\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4700 - loss: 1.6505 - val_accuracy: 0.5770 - val_loss: 1.3763\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4755 - loss: 1.6563 - val_accuracy: 0.5720 - val_loss: 1.3688\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4845 - loss: 1.6431 - val_accuracy: 0.5920 - val_loss: 1.3659\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4771 - loss: 1.6480 - val_accuracy: 0.5730 - val_loss: 1.3839\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4814 - loss: 1.6449 - val_accuracy: 0.5780 - val_loss: 1.3670\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4806 - loss: 1.6472 - val_accuracy: 0.5790 - val_loss: 1.3696\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4854 - loss: 1.6322 - val_accuracy: 0.5670 - val_loss: 1.3656\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4912 - loss: 1.6291 - val_accuracy: 0.5670 - val_loss: 1.3803\n",
      "Accuracy: 0.5660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1392 - loss: 3.1796 - val_accuracy: 0.4310 - val_loss: 2.1901\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3063 - loss: 2.3979 - val_accuracy: 0.4840 - val_loss: 1.9408\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3497 - loss: 2.2005 - val_accuracy: 0.4820 - val_loss: 1.8115\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3556 - loss: 2.1103 - val_accuracy: 0.4990 - val_loss: 1.7418\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3774 - loss: 2.0385 - val_accuracy: 0.5160 - val_loss: 1.6971\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3916 - loss: 1.9840 - val_accuracy: 0.5100 - val_loss: 1.6656\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3994 - loss: 1.9680 - val_accuracy: 0.5110 - val_loss: 1.6354\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4046 - loss: 1.9433 - val_accuracy: 0.5210 - val_loss: 1.6190\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3979 - loss: 1.9445 - val_accuracy: 0.5210 - val_loss: 1.6047\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4068 - loss: 1.9360 - val_accuracy: 0.5170 - val_loss: 1.6031\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4111 - loss: 1.9258 - val_accuracy: 0.5230 - val_loss: 1.5791\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4104 - loss: 1.8858 - val_accuracy: 0.5340 - val_loss: 1.5547\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4131 - loss: 1.8824 - val_accuracy: 0.5220 - val_loss: 1.5655\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4118 - loss: 1.8685 - val_accuracy: 0.5360 - val_loss: 1.5515\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4148 - loss: 1.8869 - val_accuracy: 0.5270 - val_loss: 1.5449\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4209 - loss: 1.8546 - val_accuracy: 0.5370 - val_loss: 1.5289\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4204 - loss: 1.8532 - val_accuracy: 0.5340 - val_loss: 1.5271\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4287 - loss: 1.8326 - val_accuracy: 0.5440 - val_loss: 1.5177\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4308 - loss: 1.8417 - val_accuracy: 0.5320 - val_loss: 1.5285\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4141 - loss: 1.8585 - val_accuracy: 0.5410 - val_loss: 1.5100\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4270 - loss: 1.8394 - val_accuracy: 0.5410 - val_loss: 1.5176\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4198 - loss: 1.8453 - val_accuracy: 0.5300 - val_loss: 1.5069\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4243 - loss: 1.8241 - val_accuracy: 0.5400 - val_loss: 1.5079\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4269 - loss: 1.8177 - val_accuracy: 0.5340 - val_loss: 1.4957\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4272 - loss: 1.8323 - val_accuracy: 0.5410 - val_loss: 1.4952\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4327 - loss: 1.8084 - val_accuracy: 0.5380 - val_loss: 1.4945\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4294 - loss: 1.8217 - val_accuracy: 0.5430 - val_loss: 1.4808\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4293 - loss: 1.8053 - val_accuracy: 0.5520 - val_loss: 1.4861\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4366 - loss: 1.8005 - val_accuracy: 0.5220 - val_loss: 1.4989\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4336 - loss: 1.8065 - val_accuracy: 0.5410 - val_loss: 1.4928\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4364 - loss: 1.8160 - val_accuracy: 0.5440 - val_loss: 1.4881\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4291 - loss: 1.8174 - val_accuracy: 0.5440 - val_loss: 1.4717\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4334 - loss: 1.8115 - val_accuracy: 0.5360 - val_loss: 1.4846\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4325 - loss: 1.8159 - val_accuracy: 0.5420 - val_loss: 1.4848\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4383 - loss: 1.7803 - val_accuracy: 0.5520 - val_loss: 1.4666\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4255 - loss: 1.8182 - val_accuracy: 0.5460 - val_loss: 1.4727\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4327 - loss: 1.8160 - val_accuracy: 0.5280 - val_loss: 1.4721\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4398 - loss: 1.7864 - val_accuracy: 0.5500 - val_loss: 1.4651\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4354 - loss: 1.7962 - val_accuracy: 0.5330 - val_loss: 1.4789\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4382 - loss: 1.7784 - val_accuracy: 0.5280 - val_loss: 1.4582\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4384 - loss: 1.7802 - val_accuracy: 0.5460 - val_loss: 1.4558\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4436 - loss: 1.7731 - val_accuracy: 0.5370 - val_loss: 1.4698\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4441 - loss: 1.7780 - val_accuracy: 0.5480 - val_loss: 1.4682\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4352 - loss: 1.7885 - val_accuracy: 0.5490 - val_loss: 1.4648\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4373 - loss: 1.7981 - val_accuracy: 0.5480 - val_loss: 1.4553\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4437 - loss: 1.7781 - val_accuracy: 0.5420 - val_loss: 1.4562\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 1.7921 - val_accuracy: 0.5420 - val_loss: 1.4556\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4492 - loss: 1.7625 - val_accuracy: 0.5520 - val_loss: 1.4532\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4280 - loss: 1.7979 - val_accuracy: 0.5430 - val_loss: 1.4569\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4421 - loss: 1.7922 - val_accuracy: 0.5440 - val_loss: 1.4399\n",
      "Accuracy: 0.5370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1330 - loss: 3.2178 - val_accuracy: 0.4090 - val_loss: 2.3290\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3270 - loss: 2.3771 - val_accuracy: 0.4890 - val_loss: 1.9604\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3883 - loss: 2.1360 - val_accuracy: 0.4960 - val_loss: 1.8188\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4204 - loss: 2.0104 - val_accuracy: 0.5210 - val_loss: 1.7306\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4348 - loss: 1.9300 - val_accuracy: 0.5170 - val_loss: 1.6821\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4455 - loss: 1.8950 - val_accuracy: 0.5330 - val_loss: 1.6513\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4511 - loss: 1.8444 - val_accuracy: 0.5260 - val_loss: 1.6071\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4621 - loss: 1.8086 - val_accuracy: 0.5270 - val_loss: 1.5857\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4553 - loss: 1.8177 - val_accuracy: 0.5370 - val_loss: 1.5689\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4553 - loss: 1.7891 - val_accuracy: 0.5280 - val_loss: 1.5540\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4604 - loss: 1.7859 - val_accuracy: 0.5540 - val_loss: 1.5334\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4669 - loss: 1.7552 - val_accuracy: 0.5430 - val_loss: 1.5221\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4656 - loss: 1.7527 - val_accuracy: 0.5530 - val_loss: 1.5139\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4649 - loss: 1.7428 - val_accuracy: 0.5460 - val_loss: 1.5090\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4748 - loss: 1.7247 - val_accuracy: 0.5480 - val_loss: 1.4965\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4725 - loss: 1.7204 - val_accuracy: 0.5390 - val_loss: 1.4972\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4782 - loss: 1.7045 - val_accuracy: 0.5380 - val_loss: 1.4918\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4731 - loss: 1.7094 - val_accuracy: 0.5540 - val_loss: 1.4774\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4710 - loss: 1.7225 - val_accuracy: 0.5510 - val_loss: 1.4662\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4689 - loss: 1.7102 - val_accuracy: 0.5570 - val_loss: 1.4581\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4781 - loss: 1.6768 - val_accuracy: 0.5420 - val_loss: 1.4507\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4735 - loss: 1.6844 - val_accuracy: 0.5500 - val_loss: 1.4411\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4788 - loss: 1.6824 - val_accuracy: 0.5520 - val_loss: 1.4449\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4833 - loss: 1.6802 - val_accuracy: 0.5600 - val_loss: 1.4245\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4822 - loss: 1.6659 - val_accuracy: 0.5610 - val_loss: 1.4250\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4768 - loss: 1.6576 - val_accuracy: 0.5640 - val_loss: 1.4236\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4828 - loss: 1.6707 - val_accuracy: 0.5700 - val_loss: 1.4179\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4849 - loss: 1.6593 - val_accuracy: 0.5700 - val_loss: 1.4052\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4842 - loss: 1.6417 - val_accuracy: 0.5510 - val_loss: 1.4167\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4846 - loss: 1.6439 - val_accuracy: 0.5610 - val_loss: 1.4035\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4920 - loss: 1.6309 - val_accuracy: 0.5630 - val_loss: 1.4013\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4870 - loss: 1.6308 - val_accuracy: 0.5610 - val_loss: 1.4036\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4891 - loss: 1.6228 - val_accuracy: 0.5720 - val_loss: 1.3845\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4866 - loss: 1.6261 - val_accuracy: 0.5770 - val_loss: 1.3809\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4884 - loss: 1.6234 - val_accuracy: 0.5560 - val_loss: 1.3918\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4933 - loss: 1.6141 - val_accuracy: 0.5710 - val_loss: 1.3833\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4831 - loss: 1.6337 - val_accuracy: 0.5520 - val_loss: 1.3998\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4960 - loss: 1.6094 - val_accuracy: 0.5660 - val_loss: 1.3728\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4953 - loss: 1.6209 - val_accuracy: 0.5660 - val_loss: 1.3729\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4808 - loss: 1.6275 - val_accuracy: 0.5640 - val_loss: 1.3642\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4952 - loss: 1.6183 - val_accuracy: 0.5470 - val_loss: 1.3667\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4950 - loss: 1.6206 - val_accuracy: 0.5760 - val_loss: 1.3612\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 1.6092 - val_accuracy: 0.5690 - val_loss: 1.3635\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 1.5871 - val_accuracy: 0.5720 - val_loss: 1.3635\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4946 - loss: 1.6098 - val_accuracy: 0.5590 - val_loss: 1.3606\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4877 - loss: 1.6129 - val_accuracy: 0.5790 - val_loss: 1.3511\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4984 - loss: 1.6004 - val_accuracy: 0.5810 - val_loss: 1.3463\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4998 - loss: 1.5889 - val_accuracy: 0.5810 - val_loss: 1.3531\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4948 - loss: 1.6043 - val_accuracy: 0.5720 - val_loss: 1.3563\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4914 - loss: 1.6042 - val_accuracy: 0.5770 - val_loss: 1.3391\n",
      "Accuracy: 0.5740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1321 - loss: 3.2469 - val_accuracy: 0.3780 - val_loss: 2.4257\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2629 - loss: 2.5509 - val_accuracy: 0.4340 - val_loss: 2.0676\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3331 - loss: 2.2959 - val_accuracy: 0.4610 - val_loss: 1.9115\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3580 - loss: 2.1559 - val_accuracy: 0.4920 - val_loss: 1.8289\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3758 - loss: 2.0828 - val_accuracy: 0.4990 - val_loss: 1.7672\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 2.0379 - val_accuracy: 0.5000 - val_loss: 1.7222\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3987 - loss: 2.0096 - val_accuracy: 0.5030 - val_loss: 1.6888\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4062 - loss: 1.9639 - val_accuracy: 0.5130 - val_loss: 1.6609\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4056 - loss: 1.9541 - val_accuracy: 0.5020 - val_loss: 1.6477\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4133 - loss: 1.9326 - val_accuracy: 0.5140 - val_loss: 1.6294\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4168 - loss: 1.9105 - val_accuracy: 0.5120 - val_loss: 1.6104\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4197 - loss: 1.8913 - val_accuracy: 0.5030 - val_loss: 1.6022\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4214 - loss: 1.8872 - val_accuracy: 0.5050 - val_loss: 1.5913\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4221 - loss: 1.8850 - val_accuracy: 0.5170 - val_loss: 1.5876\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4270 - loss: 1.8487 - val_accuracy: 0.5230 - val_loss: 1.5713\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4274 - loss: 1.8673 - val_accuracy: 0.5140 - val_loss: 1.5704\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4320 - loss: 1.8458 - val_accuracy: 0.5230 - val_loss: 1.5452\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4274 - loss: 1.8375 - val_accuracy: 0.5280 - val_loss: 1.5404\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4306 - loss: 1.8365 - val_accuracy: 0.5270 - val_loss: 1.5300\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4296 - loss: 1.8292 - val_accuracy: 0.5210 - val_loss: 1.5295\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4334 - loss: 1.8222 - val_accuracy: 0.5290 - val_loss: 1.5324\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4494 - loss: 1.8035 - val_accuracy: 0.5250 - val_loss: 1.5247\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4444 - loss: 1.7854 - val_accuracy: 0.5400 - val_loss: 1.5097\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4342 - loss: 1.8145 - val_accuracy: 0.5330 - val_loss: 1.5120\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4408 - loss: 1.7850 - val_accuracy: 0.5270 - val_loss: 1.5164\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4481 - loss: 1.7853 - val_accuracy: 0.5310 - val_loss: 1.5063\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4446 - loss: 1.8027 - val_accuracy: 0.5320 - val_loss: 1.5063\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4443 - loss: 1.7810 - val_accuracy: 0.5300 - val_loss: 1.4915\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4455 - loss: 1.7710 - val_accuracy: 0.5400 - val_loss: 1.4843\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4398 - loss: 1.7869 - val_accuracy: 0.5220 - val_loss: 1.4824\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4384 - loss: 1.7782 - val_accuracy: 0.5310 - val_loss: 1.4874\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4461 - loss: 1.7727 - val_accuracy: 0.5410 - val_loss: 1.4815\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4421 - loss: 1.7720 - val_accuracy: 0.5360 - val_loss: 1.4760\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4331 - loss: 1.7933 - val_accuracy: 0.5400 - val_loss: 1.4747\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4587 - loss: 1.7503 - val_accuracy: 0.5460 - val_loss: 1.4786\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4452 - loss: 1.7677 - val_accuracy: 0.5530 - val_loss: 1.4621\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4505 - loss: 1.7620 - val_accuracy: 0.5450 - val_loss: 1.4660\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4477 - loss: 1.7617 - val_accuracy: 0.5420 - val_loss: 1.4588\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4484 - loss: 1.7487 - val_accuracy: 0.5510 - val_loss: 1.4569\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4519 - loss: 1.7490 - val_accuracy: 0.5480 - val_loss: 1.4665\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4412 - loss: 1.7628 - val_accuracy: 0.5460 - val_loss: 1.4589\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4500 - loss: 1.7622 - val_accuracy: 0.5460 - val_loss: 1.4536\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4501 - loss: 1.7409 - val_accuracy: 0.5530 - val_loss: 1.4578\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4524 - loss: 1.7534 - val_accuracy: 0.5460 - val_loss: 1.4510\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4539 - loss: 1.7401 - val_accuracy: 0.5440 - val_loss: 1.4539\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4550 - loss: 1.7410 - val_accuracy: 0.5480 - val_loss: 1.4470\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4438 - loss: 1.7625 - val_accuracy: 0.5510 - val_loss: 1.4402\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4456 - loss: 1.7398 - val_accuracy: 0.5580 - val_loss: 1.4345\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4487 - loss: 1.7463 - val_accuracy: 0.5470 - val_loss: 1.4404\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4466 - loss: 1.7403 - val_accuracy: 0.5580 - val_loss: 1.4330\n",
      "Accuracy: 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2960 - loss: 2.4303 - val_accuracy: 0.4610 - val_loss: 1.7796\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4002 - loss: 1.9871 - val_accuracy: 0.4890 - val_loss: 1.6952\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4160 - loss: 1.9398 - val_accuracy: 0.4970 - val_loss: 1.7294\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4138 - loss: 1.9244 - val_accuracy: 0.4890 - val_loss: 1.6648\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4153 - loss: 1.9200 - val_accuracy: 0.5170 - val_loss: 1.6206\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4168 - loss: 1.8948 - val_accuracy: 0.5250 - val_loss: 1.6377\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4193 - loss: 1.9140 - val_accuracy: 0.4990 - val_loss: 1.6517\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4228 - loss: 1.8875 - val_accuracy: 0.4990 - val_loss: 1.6367\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4222 - loss: 1.9084 - val_accuracy: 0.4980 - val_loss: 1.6685\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4200 - loss: 1.8915 - val_accuracy: 0.4970 - val_loss: 1.6654\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4210 - loss: 1.8821 - val_accuracy: 0.4890 - val_loss: 1.6480\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4244 - loss: 1.8825 - val_accuracy: 0.5310 - val_loss: 1.6123\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4274 - loss: 1.8678 - val_accuracy: 0.5130 - val_loss: 1.6472\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4251 - loss: 1.9027 - val_accuracy: 0.4770 - val_loss: 1.6691\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4207 - loss: 1.8835 - val_accuracy: 0.4890 - val_loss: 1.6514\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4262 - loss: 1.8810 - val_accuracy: 0.4860 - val_loss: 1.6451\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4302 - loss: 1.8831 - val_accuracy: 0.5320 - val_loss: 1.5786\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4337 - loss: 1.8603 - val_accuracy: 0.5270 - val_loss: 1.6132\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4285 - loss: 1.8727 - val_accuracy: 0.5250 - val_loss: 1.5805\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4428 - loss: 1.8558 - val_accuracy: 0.5020 - val_loss: 1.6353\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4344 - loss: 1.8764 - val_accuracy: 0.5230 - val_loss: 1.5871\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4376 - loss: 1.8621 - val_accuracy: 0.5270 - val_loss: 1.6087\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4290 - loss: 1.8836 - val_accuracy: 0.5080 - val_loss: 1.5986\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4299 - loss: 1.8741 - val_accuracy: 0.5270 - val_loss: 1.6051\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4405 - loss: 1.8539 - val_accuracy: 0.5210 - val_loss: 1.5784\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4256 - loss: 1.8802 - val_accuracy: 0.5380 - val_loss: 1.5802\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4430 - loss: 1.8545 - val_accuracy: 0.5270 - val_loss: 1.5673\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4346 - loss: 1.8681 - val_accuracy: 0.5170 - val_loss: 1.6192\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4319 - loss: 1.8622 - val_accuracy: 0.4930 - val_loss: 1.6542\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4365 - loss: 1.8586 - val_accuracy: 0.5060 - val_loss: 1.6045\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4307 - loss: 1.8665 - val_accuracy: 0.5150 - val_loss: 1.6234\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4357 - loss: 1.8600 - val_accuracy: 0.5300 - val_loss: 1.5617\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4389 - loss: 1.8493 - val_accuracy: 0.5120 - val_loss: 1.5924\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4331 - loss: 1.8691 - val_accuracy: 0.5350 - val_loss: 1.5728\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4388 - loss: 1.8474 - val_accuracy: 0.5120 - val_loss: 1.6230\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4386 - loss: 1.8559 - val_accuracy: 0.5170 - val_loss: 1.6093\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4330 - loss: 1.8492 - val_accuracy: 0.5200 - val_loss: 1.5977\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4390 - loss: 1.8492 - val_accuracy: 0.5120 - val_loss: 1.5953\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4358 - loss: 1.8641 - val_accuracy: 0.4970 - val_loss: 1.6315\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4363 - loss: 1.8597 - val_accuracy: 0.5370 - val_loss: 1.5751\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4408 - loss: 1.8399 - val_accuracy: 0.4970 - val_loss: 1.6133\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4321 - loss: 1.8583 - val_accuracy: 0.5270 - val_loss: 1.5741\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4317 - loss: 1.8711 - val_accuracy: 0.5340 - val_loss: 1.5793\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4368 - loss: 1.8700 - val_accuracy: 0.5160 - val_loss: 1.6095\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 1.8657 - val_accuracy: 0.5210 - val_loss: 1.6202\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4345 - loss: 1.8540 - val_accuracy: 0.5140 - val_loss: 1.6128\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4370 - loss: 1.8544 - val_accuracy: 0.5180 - val_loss: 1.6212\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4366 - loss: 1.8759 - val_accuracy: 0.5030 - val_loss: 1.6328\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4389 - loss: 1.8401 - val_accuracy: 0.5240 - val_loss: 1.6031\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4314 - loss: 1.8623 - val_accuracy: 0.5030 - val_loss: 1.6118\n",
      "Accuracy: 0.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_16               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_17               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2662 - loss: 2.5647 - val_accuracy: 0.4310 - val_loss: 1.8320\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3500 - loss: 2.1314 - val_accuracy: 0.4280 - val_loss: 1.8507\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3705 - loss: 2.0805 - val_accuracy: 0.4560 - val_loss: 1.7507\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3718 - loss: 2.0558 - val_accuracy: 0.4840 - val_loss: 1.7455\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3754 - loss: 2.0628 - val_accuracy: 0.4960 - val_loss: 1.7070\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3756 - loss: 2.0323 - val_accuracy: 0.4730 - val_loss: 1.7336\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3851 - loss: 2.0199 - val_accuracy: 0.4820 - val_loss: 1.7362\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3775 - loss: 2.0426 - val_accuracy: 0.5160 - val_loss: 1.7054\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3878 - loss: 2.0331 - val_accuracy: 0.4860 - val_loss: 1.6992\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3892 - loss: 2.0174 - val_accuracy: 0.4990 - val_loss: 1.7081\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3909 - loss: 2.0093 - val_accuracy: 0.4920 - val_loss: 1.7218\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3863 - loss: 2.0259 - val_accuracy: 0.4660 - val_loss: 1.7086\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3962 - loss: 2.0203 - val_accuracy: 0.4890 - val_loss: 1.7173\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3824 - loss: 2.0175 - val_accuracy: 0.4890 - val_loss: 1.7178\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3947 - loss: 1.9986 - val_accuracy: 0.5050 - val_loss: 1.6976\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3838 - loss: 2.0144 - val_accuracy: 0.4740 - val_loss: 1.7393\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3890 - loss: 1.9974 - val_accuracy: 0.4780 - val_loss: 1.7004\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3952 - loss: 2.0132 - val_accuracy: 0.4940 - val_loss: 1.6920\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3898 - loss: 1.9981 - val_accuracy: 0.4860 - val_loss: 1.7040\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3881 - loss: 2.0125 - val_accuracy: 0.4910 - val_loss: 1.7263\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3982 - loss: 2.0094 - val_accuracy: 0.5090 - val_loss: 1.6587\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4008 - loss: 1.9948 - val_accuracy: 0.4870 - val_loss: 1.6847\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3911 - loss: 2.0252 - val_accuracy: 0.5030 - val_loss: 1.7210\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3965 - loss: 1.9875 - val_accuracy: 0.4990 - val_loss: 1.6772\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3931 - loss: 1.9990 - val_accuracy: 0.4800 - val_loss: 1.6822\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3979 - loss: 1.9936 - val_accuracy: 0.4780 - val_loss: 1.7105\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3856 - loss: 2.0248 - val_accuracy: 0.4820 - val_loss: 1.7218\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3947 - loss: 2.0028 - val_accuracy: 0.4890 - val_loss: 1.6984\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3895 - loss: 2.0024 - val_accuracy: 0.5130 - val_loss: 1.6451\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3972 - loss: 2.0015 - val_accuracy: 0.4650 - val_loss: 1.7224\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3984 - loss: 2.0145 - val_accuracy: 0.5110 - val_loss: 1.7016\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3900 - loss: 2.0107 - val_accuracy: 0.4940 - val_loss: 1.7036\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3921 - loss: 1.9900 - val_accuracy: 0.4920 - val_loss: 1.6804\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3885 - loss: 1.9911 - val_accuracy: 0.4940 - val_loss: 1.6651\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3993 - loss: 1.9817 - val_accuracy: 0.5080 - val_loss: 1.6413\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3923 - loss: 1.9945 - val_accuracy: 0.5230 - val_loss: 1.6618\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3929 - loss: 1.9941 - val_accuracy: 0.5010 - val_loss: 1.6818\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4000 - loss: 1.9937 - val_accuracy: 0.4980 - val_loss: 1.7216\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3970 - loss: 1.9859 - val_accuracy: 0.4940 - val_loss: 1.6734\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 1.9852 - val_accuracy: 0.5210 - val_loss: 1.7065\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 2.0101 - val_accuracy: 0.5040 - val_loss: 1.6726\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4005 - loss: 1.9796 - val_accuracy: 0.4920 - val_loss: 1.7126\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3907 - loss: 1.9951 - val_accuracy: 0.4840 - val_loss: 1.6818\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3883 - loss: 2.0173 - val_accuracy: 0.4650 - val_loss: 1.7501\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3930 - loss: 1.9896 - val_accuracy: 0.5070 - val_loss: 1.6844\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3904 - loss: 2.0095 - val_accuracy: 0.4870 - val_loss: 1.6651\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3953 - loss: 1.9893 - val_accuracy: 0.5060 - val_loss: 1.6908\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3943 - loss: 2.0145 - val_accuracy: 0.5070 - val_loss: 1.6997\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3966 - loss: 1.9958 - val_accuracy: 0.4950 - val_loss: 1.6919\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3973 - loss: 1.9944 - val_accuracy: 0.5080 - val_loss: 1.6839\n",
      "Accuracy: 0.4895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_18               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_19               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 2.5100 - val_accuracy: 0.4170 - val_loss: 1.8895\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4202 - loss: 1.9207 - val_accuracy: 0.4850 - val_loss: 1.6959\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4188 - loss: 1.8881 - val_accuracy: 0.5030 - val_loss: 1.6485\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4357 - loss: 1.8373 - val_accuracy: 0.5000 - val_loss: 1.6582\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4315 - loss: 1.8362 - val_accuracy: 0.4820 - val_loss: 1.6730\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4349 - loss: 1.8330 - val_accuracy: 0.4970 - val_loss: 1.6033\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4369 - loss: 1.8288 - val_accuracy: 0.5090 - val_loss: 1.5762\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4392 - loss: 1.8148 - val_accuracy: 0.5390 - val_loss: 1.5420\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4479 - loss: 1.8119 - val_accuracy: 0.5180 - val_loss: 1.5817\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4530 - loss: 1.7843 - val_accuracy: 0.5270 - val_loss: 1.5364\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4589 - loss: 1.7790 - val_accuracy: 0.5360 - val_loss: 1.5645\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4587 - loss: 1.7734 - val_accuracy: 0.5220 - val_loss: 1.5590\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4521 - loss: 1.7784 - val_accuracy: 0.5190 - val_loss: 1.5762\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4584 - loss: 1.7632 - val_accuracy: 0.5490 - val_loss: 1.5429\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4463 - loss: 1.7941 - val_accuracy: 0.5330 - val_loss: 1.5595\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4554 - loss: 1.7747 - val_accuracy: 0.5320 - val_loss: 1.5884\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4496 - loss: 1.7783 - val_accuracy: 0.5290 - val_loss: 1.5280\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4540 - loss: 1.7723 - val_accuracy: 0.5450 - val_loss: 1.5112\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4555 - loss: 1.7875 - val_accuracy: 0.5370 - val_loss: 1.5277\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4553 - loss: 1.7741 - val_accuracy: 0.5440 - val_loss: 1.5463\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4618 - loss: 1.7533 - val_accuracy: 0.5240 - val_loss: 1.5324\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4576 - loss: 1.7827 - val_accuracy: 0.5450 - val_loss: 1.5042\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4671 - loss: 1.7556 - val_accuracy: 0.5170 - val_loss: 1.5673\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4563 - loss: 1.7657 - val_accuracy: 0.5290 - val_loss: 1.5146\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4481 - loss: 1.7855 - val_accuracy: 0.5120 - val_loss: 1.5600\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4623 - loss: 1.7676 - val_accuracy: 0.5480 - val_loss: 1.5034\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4663 - loss: 1.7533 - val_accuracy: 0.5460 - val_loss: 1.4818\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4565 - loss: 1.7714 - val_accuracy: 0.5290 - val_loss: 1.5472\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4675 - loss: 1.7543 - val_accuracy: 0.5420 - val_loss: 1.5002\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4681 - loss: 1.7590 - val_accuracy: 0.5110 - val_loss: 1.5577\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4502 - loss: 1.7818 - val_accuracy: 0.5350 - val_loss: 1.5388\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4432 - loss: 1.7951 - val_accuracy: 0.5200 - val_loss: 1.5108\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4537 - loss: 1.7731 - val_accuracy: 0.5220 - val_loss: 1.5441\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4663 - loss: 1.7541 - val_accuracy: 0.5100 - val_loss: 1.5364\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4560 - loss: 1.7652 - val_accuracy: 0.5530 - val_loss: 1.4796\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4624 - loss: 1.7579 - val_accuracy: 0.5070 - val_loss: 1.5158\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4646 - loss: 1.7538 - val_accuracy: 0.4910 - val_loss: 1.5910\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4640 - loss: 1.7649 - val_accuracy: 0.5590 - val_loss: 1.5076\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4623 - loss: 1.7576 - val_accuracy: 0.5380 - val_loss: 1.4935\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4739 - loss: 1.7382 - val_accuracy: 0.5300 - val_loss: 1.5044\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4650 - loss: 1.7481 - val_accuracy: 0.5450 - val_loss: 1.4849\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4579 - loss: 1.7694 - val_accuracy: 0.5400 - val_loss: 1.4992\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4674 - loss: 1.7492 - val_accuracy: 0.5140 - val_loss: 1.5247\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4666 - loss: 1.7430 - val_accuracy: 0.5150 - val_loss: 1.5679\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4601 - loss: 1.7481 - val_accuracy: 0.5390 - val_loss: 1.5184\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 1.7247 - val_accuracy: 0.5090 - val_loss: 1.5677\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4615 - loss: 1.7633 - val_accuracy: 0.5460 - val_loss: 1.5015\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4694 - loss: 1.7291 - val_accuracy: 0.5020 - val_loss: 1.5227\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4612 - loss: 1.7581 - val_accuracy: 0.5370 - val_loss: 1.5156\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4687 - loss: 1.7430 - val_accuracy: 0.5120 - val_loss: 1.5367\n",
      "Accuracy: 0.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.2590 - loss: 2.5867 - val_accuracy: 0.4050 - val_loss: 2.0441\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3693 - loss: 2.0626 - val_accuracy: 0.4590 - val_loss: 1.7887\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3900 - loss: 1.9966 - val_accuracy: 0.4670 - val_loss: 1.7061\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3834 - loss: 1.9814 - val_accuracy: 0.4730 - val_loss: 1.7064\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3984 - loss: 1.9594 - val_accuracy: 0.4820 - val_loss: 1.6895\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3962 - loss: 1.9577 - val_accuracy: 0.4920 - val_loss: 1.7058\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4008 - loss: 1.9580 - val_accuracy: 0.4890 - val_loss: 1.6260\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3981 - loss: 1.9451 - val_accuracy: 0.4910 - val_loss: 1.6575\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4024 - loss: 1.9526 - val_accuracy: 0.4380 - val_loss: 1.7291\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4036 - loss: 1.9378 - val_accuracy: 0.4930 - val_loss: 1.6519\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4054 - loss: 1.9372 - val_accuracy: 0.5140 - val_loss: 1.6350\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4104 - loss: 1.9229 - val_accuracy: 0.5000 - val_loss: 1.6164\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4019 - loss: 1.9171 - val_accuracy: 0.4910 - val_loss: 1.6210\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4080 - loss: 1.9232 - val_accuracy: 0.5120 - val_loss: 1.6035\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4048 - loss: 1.9307 - val_accuracy: 0.4960 - val_loss: 1.6991\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4033 - loss: 1.9314 - val_accuracy: 0.4990 - val_loss: 1.6297\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4088 - loss: 1.9037 - val_accuracy: 0.5220 - val_loss: 1.5954\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4068 - loss: 1.9296 - val_accuracy: 0.5080 - val_loss: 1.6095\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4151 - loss: 1.8988 - val_accuracy: 0.5210 - val_loss: 1.5895\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4056 - loss: 1.9128 - val_accuracy: 0.5040 - val_loss: 1.6264\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4145 - loss: 1.9127 - val_accuracy: 0.5240 - val_loss: 1.6007\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4163 - loss: 1.9119 - val_accuracy: 0.4920 - val_loss: 1.6337\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4116 - loss: 1.9290 - val_accuracy: 0.5230 - val_loss: 1.6097\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4149 - loss: 1.9039 - val_accuracy: 0.4930 - val_loss: 1.6562\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4133 - loss: 1.9055 - val_accuracy: 0.5000 - val_loss: 1.6514\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4065 - loss: 1.9166 - val_accuracy: 0.5310 - val_loss: 1.6179\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4167 - loss: 1.9027 - val_accuracy: 0.5170 - val_loss: 1.6047\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4191 - loss: 1.8923 - val_accuracy: 0.4950 - val_loss: 1.6427\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4260 - loss: 1.8936 - val_accuracy: 0.5360 - val_loss: 1.5807\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4214 - loss: 1.8883 - val_accuracy: 0.4870 - val_loss: 1.6226\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4122 - loss: 1.9045 - val_accuracy: 0.4820 - val_loss: 1.6275\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4200 - loss: 1.8908 - val_accuracy: 0.5160 - val_loss: 1.6097\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4245 - loss: 1.8887 - val_accuracy: 0.5150 - val_loss: 1.6086\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4218 - loss: 1.8991 - val_accuracy: 0.5180 - val_loss: 1.6017\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4156 - loss: 1.9032 - val_accuracy: 0.4920 - val_loss: 1.6002\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4100 - loss: 1.9120 - val_accuracy: 0.5210 - val_loss: 1.6285\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4154 - loss: 1.9272 - val_accuracy: 0.5210 - val_loss: 1.6133\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4223 - loss: 1.8804 - val_accuracy: 0.5240 - val_loss: 1.5875\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4080 - loss: 1.9080 - val_accuracy: 0.5190 - val_loss: 1.6043\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4239 - loss: 1.8985 - val_accuracy: 0.5360 - val_loss: 1.5904\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4240 - loss: 1.8936 - val_accuracy: 0.5050 - val_loss: 1.6198\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4159 - loss: 1.9029 - val_accuracy: 0.4840 - val_loss: 1.5993\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4223 - loss: 1.8841 - val_accuracy: 0.5010 - val_loss: 1.5878\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4232 - loss: 1.8830 - val_accuracy: 0.4890 - val_loss: 1.6258\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4096 - loss: 1.9054 - val_accuracy: 0.5040 - val_loss: 1.5890\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4080 - loss: 1.9030 - val_accuracy: 0.4970 - val_loss: 1.6115\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4189 - loss: 1.8891 - val_accuracy: 0.5300 - val_loss: 1.5671\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4173 - loss: 1.8966 - val_accuracy: 0.5020 - val_loss: 1.6187\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4197 - loss: 1.8844 - val_accuracy: 0.5100 - val_loss: 1.5936\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4208 - loss: 1.8682 - val_accuracy: 0.5110 - val_loss: 1.6067\n",
      "Accuracy: 0.5050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_24               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_25               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_26               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_24               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_25               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_26               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2039 - loss: 2.8946 - val_accuracy: 0.2780 - val_loss: 2.4542\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2376 - loss: 2.6955 - val_accuracy: 0.2610 - val_loss: 2.5933\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2367 - loss: 2.6850 - val_accuracy: 0.2730 - val_loss: 2.5700\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2466 - loss: 2.6887 - val_accuracy: 0.3140 - val_loss: 2.4853\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2541 - loss: 2.7061 - val_accuracy: 0.2380 - val_loss: 2.7066\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2570 - loss: 2.6809 - val_accuracy: 0.2870 - val_loss: 2.4605\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2635 - loss: 2.6425 - val_accuracy: 0.3010 - val_loss: 2.5495\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2601 - loss: 2.6665 - val_accuracy: 0.2680 - val_loss: 2.5816\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2660 - loss: 2.6405 - val_accuracy: 0.2790 - val_loss: 2.5599\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2720 - loss: 2.6438 - val_accuracy: 0.3310 - val_loss: 2.4081\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2639 - loss: 2.6573 - val_accuracy: 0.3290 - val_loss: 2.3469\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2666 - loss: 2.6371 - val_accuracy: 0.3070 - val_loss: 2.5017\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2621 - loss: 2.6546 - val_accuracy: 0.3270 - val_loss: 2.4571\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2715 - loss: 2.6172 - val_accuracy: 0.3410 - val_loss: 2.4183\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2831 - loss: 2.6189 - val_accuracy: 0.3260 - val_loss: 2.3576\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2784 - loss: 2.6186 - val_accuracy: 0.2490 - val_loss: 2.4451\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2730 - loss: 2.6097 - val_accuracy: 0.2790 - val_loss: 2.6806\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2734 - loss: 2.6409 - val_accuracy: 0.2650 - val_loss: 2.5940\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2729 - loss: 2.6537 - val_accuracy: 0.2710 - val_loss: 2.6608\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2658 - loss: 2.6364 - val_accuracy: 0.3540 - val_loss: 2.4057\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2808 - loss: 2.6096 - val_accuracy: 0.2840 - val_loss: 2.4585\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2763 - loss: 2.6293 - val_accuracy: 0.3110 - val_loss: 2.4058\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2689 - loss: 2.6483 - val_accuracy: 0.3380 - val_loss: 2.4972\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2746 - loss: 2.6307 - val_accuracy: 0.2700 - val_loss: 2.4531\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2667 - loss: 2.6401 - val_accuracy: 0.3020 - val_loss: 2.4772\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2719 - loss: 2.6404 - val_accuracy: 0.2620 - val_loss: 2.4850\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2751 - loss: 2.6128 - val_accuracy: 0.2850 - val_loss: 2.4983\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2796 - loss: 2.6179 - val_accuracy: 0.3300 - val_loss: 2.4257\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2702 - loss: 2.6309 - val_accuracy: 0.3860 - val_loss: 2.3137\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2794 - loss: 2.6202 - val_accuracy: 0.2240 - val_loss: 2.7486\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2867 - loss: 2.6378 - val_accuracy: 0.3320 - val_loss: 2.5236\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2854 - loss: 2.6037 - val_accuracy: 0.2800 - val_loss: 2.4323\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2687 - loss: 2.6364 - val_accuracy: 0.2610 - val_loss: 2.4245\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2721 - loss: 2.6090 - val_accuracy: 0.3200 - val_loss: 2.4318\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2786 - loss: 2.6239 - val_accuracy: 0.3380 - val_loss: 2.4154\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2850 - loss: 2.5868 - val_accuracy: 0.3860 - val_loss: 2.2973\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2760 - loss: 2.6239 - val_accuracy: 0.3970 - val_loss: 2.2532\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2692 - loss: 2.6429 - val_accuracy: 0.2520 - val_loss: 2.5514\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2736 - loss: 2.6444 - val_accuracy: 0.3460 - val_loss: 2.4039\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2730 - loss: 2.6402 - val_accuracy: 0.2990 - val_loss: 2.5381\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2849 - loss: 2.5955 - val_accuracy: 0.3140 - val_loss: 2.6130\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2730 - loss: 2.6241 - val_accuracy: 0.3020 - val_loss: 2.5193\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2736 - loss: 2.6160 - val_accuracy: 0.3520 - val_loss: 2.2877\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2743 - loss: 2.6031 - val_accuracy: 0.3240 - val_loss: 2.5387\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2710 - loss: 2.6466 - val_accuracy: 0.3540 - val_loss: 2.3695\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2649 - loss: 2.6508 - val_accuracy: 0.3480 - val_loss: 2.4364\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2749 - loss: 2.6355 - val_accuracy: 0.3600 - val_loss: 2.4095\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2833 - loss: 2.6267 - val_accuracy: 0.3500 - val_loss: 2.3756\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2860 - loss: 2.6080 - val_accuracy: 0.3500 - val_loss: 2.3556\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2812 - loss: 2.6059 - val_accuracy: 0.3030 - val_loss: 2.6480\n",
      "Accuracy: 0.2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_28               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_29               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_36 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_37 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_28               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_29               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1874 - loss: 2.9843 - val_accuracy: 0.2540 - val_loss: 2.4878\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1921 - loss: 2.8272 - val_accuracy: 0.2740 - val_loss: 2.5103\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2117 - loss: 2.8117 - val_accuracy: 0.2860 - val_loss: 2.4389\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2148 - loss: 2.7919 - val_accuracy: 0.2670 - val_loss: 2.6379\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2127 - loss: 2.7952 - val_accuracy: 0.1860 - val_loss: 2.7019\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2114 - loss: 2.8068 - val_accuracy: 0.2790 - val_loss: 2.5248\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2146 - loss: 2.8101 - val_accuracy: 0.2340 - val_loss: 2.6990\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2150 - loss: 2.7975 - val_accuracy: 0.2640 - val_loss: 2.7727\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2264 - loss: 2.7663 - val_accuracy: 0.2780 - val_loss: 2.5478\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2220 - loss: 2.7746 - val_accuracy: 0.2600 - val_loss: 2.6255\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2190 - loss: 2.7971 - val_accuracy: 0.2740 - val_loss: 2.5771\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2270 - loss: 2.7578 - val_accuracy: 0.2410 - val_loss: 2.6736\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2170 - loss: 2.7996 - val_accuracy: 0.2700 - val_loss: 2.6077\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2269 - loss: 2.7889 - val_accuracy: 0.2100 - val_loss: 2.6570\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2273 - loss: 2.7837 - val_accuracy: 0.2270 - val_loss: 2.7814\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2224 - loss: 2.7825 - val_accuracy: 0.2730 - val_loss: 2.5719\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2332 - loss: 2.7713 - val_accuracy: 0.2370 - val_loss: 2.6690\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2337 - loss: 2.7759 - val_accuracy: 0.2980 - val_loss: 2.6052\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2304 - loss: 2.7737 - val_accuracy: 0.3100 - val_loss: 2.5453\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2343 - loss: 2.7609 - val_accuracy: 0.2950 - val_loss: 2.4627\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2361 - loss: 2.7457 - val_accuracy: 0.2890 - val_loss: 2.6032\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2380 - loss: 2.7695 - val_accuracy: 0.2570 - val_loss: 2.6267\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2277 - loss: 2.7733 - val_accuracy: 0.3180 - val_loss: 2.5219\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2371 - loss: 2.7505 - val_accuracy: 0.2210 - val_loss: 2.9500\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2274 - loss: 2.7820 - val_accuracy: 0.3210 - val_loss: 2.4746\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2380 - loss: 2.7490 - val_accuracy: 0.2820 - val_loss: 2.7082\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2336 - loss: 2.7668 - val_accuracy: 0.2680 - val_loss: 2.5925\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2340 - loss: 2.7508 - val_accuracy: 0.2710 - val_loss: 2.7224\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2322 - loss: 2.7693 - val_accuracy: 0.3750 - val_loss: 2.4601\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2296 - loss: 2.7801 - val_accuracy: 0.2500 - val_loss: 2.5642\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2272 - loss: 2.7879 - val_accuracy: 0.2950 - val_loss: 2.5988\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2397 - loss: 2.7578 - val_accuracy: 0.3140 - val_loss: 2.5654\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2386 - loss: 2.7637 - val_accuracy: 0.2490 - val_loss: 2.6134\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2326 - loss: 2.7586 - val_accuracy: 0.3070 - val_loss: 2.5028\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2404 - loss: 2.7518 - val_accuracy: 0.2660 - val_loss: 2.5248\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2243 - loss: 2.7916 - val_accuracy: 0.3150 - val_loss: 2.4228\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2457 - loss: 2.7281 - val_accuracy: 0.2730 - val_loss: 2.6005\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2273 - loss: 2.7750 - val_accuracy: 0.3110 - val_loss: 2.5181\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2333 - loss: 2.7619 - val_accuracy: 0.2780 - val_loss: 2.6720\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2429 - loss: 2.7584 - val_accuracy: 0.2650 - val_loss: 2.4843\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2329 - loss: 2.7799 - val_accuracy: 0.3230 - val_loss: 2.5149\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2435 - loss: 2.7581 - val_accuracy: 0.2730 - val_loss: 2.4996\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2352 - loss: 2.7745 - val_accuracy: 0.2220 - val_loss: 2.6920\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2404 - loss: 2.7603 - val_accuracy: 0.2830 - val_loss: 2.5264\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2398 - loss: 2.7412 - val_accuracy: 0.3040 - val_loss: 2.5909\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2428 - loss: 2.7566 - val_accuracy: 0.2510 - val_loss: 2.6826\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2343 - loss: 2.7553 - val_accuracy: 0.3430 - val_loss: 2.4751\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2305 - loss: 2.7818 - val_accuracy: 0.2700 - val_loss: 2.6099\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 2.7522 - val_accuracy: 0.2780 - val_loss: 2.5800\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2436 - loss: 2.7613 - val_accuracy: 0.2710 - val_loss: 2.5340\n",
      "Accuracy: 0.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_30               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_30               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_32 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2477 - loss: 2.7351 - val_accuracy: 0.2500 - val_loss: 2.5362\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2845 - loss: 2.5206 - val_accuracy: 0.3480 - val_loss: 2.3775\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3032 - loss: 2.4626 - val_accuracy: 0.3440 - val_loss: 2.3317\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3102 - loss: 2.4479 - val_accuracy: 0.3090 - val_loss: 2.3887\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3001 - loss: 2.4552 - val_accuracy: 0.3870 - val_loss: 2.1987\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3006 - loss: 2.4749 - val_accuracy: 0.3000 - val_loss: 2.4069\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3119 - loss: 2.4373 - val_accuracy: 0.3280 - val_loss: 2.3295\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3180 - loss: 2.4270 - val_accuracy: 0.3590 - val_loss: 2.2177\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3157 - loss: 2.4290 - val_accuracy: 0.3440 - val_loss: 2.4158\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3157 - loss: 2.4187 - val_accuracy: 0.2960 - val_loss: 2.4045\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3179 - loss: 2.4183 - val_accuracy: 0.3330 - val_loss: 2.4213\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3116 - loss: 2.4493 - val_accuracy: 0.3810 - val_loss: 2.2185\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3199 - loss: 2.4085 - val_accuracy: 0.3720 - val_loss: 2.2758\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3292 - loss: 2.4165 - val_accuracy: 0.3410 - val_loss: 2.2242\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3180 - loss: 2.4345 - val_accuracy: 0.3670 - val_loss: 2.3247\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3262 - loss: 2.4317 - val_accuracy: 0.3730 - val_loss: 2.2035\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3258 - loss: 2.3953 - val_accuracy: 0.3650 - val_loss: 2.2873\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3344 - loss: 2.3816 - val_accuracy: 0.3880 - val_loss: 2.2130\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3264 - loss: 2.3819 - val_accuracy: 0.3770 - val_loss: 2.3236\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3239 - loss: 2.4261 - val_accuracy: 0.3300 - val_loss: 2.4563\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3181 - loss: 2.4217 - val_accuracy: 0.3460 - val_loss: 2.3602\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3263 - loss: 2.4198 - val_accuracy: 0.3380 - val_loss: 2.3225\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3306 - loss: 2.4035 - val_accuracy: 0.3500 - val_loss: 2.2391\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3297 - loss: 2.3916 - val_accuracy: 0.3460 - val_loss: 2.2275\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3264 - loss: 2.3736 - val_accuracy: 0.2880 - val_loss: 2.5266\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3248 - loss: 2.4328 - val_accuracy: 0.3620 - val_loss: 2.3643\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3267 - loss: 2.3957 - val_accuracy: 0.3610 - val_loss: 2.3261\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3303 - loss: 2.3796 - val_accuracy: 0.4240 - val_loss: 2.2016\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3295 - loss: 2.4039 - val_accuracy: 0.3400 - val_loss: 2.3241\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3310 - loss: 2.3879 - val_accuracy: 0.4150 - val_loss: 2.1654\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3378 - loss: 2.3685 - val_accuracy: 0.3960 - val_loss: 2.2619\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3311 - loss: 2.4027 - val_accuracy: 0.3630 - val_loss: 2.2037\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3195 - loss: 2.4160 - val_accuracy: 0.3420 - val_loss: 2.2759\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3341 - loss: 2.3804 - val_accuracy: 0.4200 - val_loss: 2.1623\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3407 - loss: 2.3877 - val_accuracy: 0.3580 - val_loss: 2.3530\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3391 - loss: 2.3772 - val_accuracy: 0.3890 - val_loss: 2.2293\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3352 - loss: 2.3950 - val_accuracy: 0.3960 - val_loss: 2.2445\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3297 - loss: 2.3993 - val_accuracy: 0.3990 - val_loss: 2.2017\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3407 - loss: 2.4008 - val_accuracy: 0.3870 - val_loss: 2.2296\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3426 - loss: 2.3815 - val_accuracy: 0.4180 - val_loss: 2.2214\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3449 - loss: 2.3565 - val_accuracy: 0.3190 - val_loss: 2.4161\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3348 - loss: 2.3977 - val_accuracy: 0.3090 - val_loss: 2.4745\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3377 - loss: 2.3998 - val_accuracy: 0.3960 - val_loss: 2.2321\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3289 - loss: 2.4219 - val_accuracy: 0.3310 - val_loss: 2.4435\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3416 - loss: 2.3995 - val_accuracy: 0.4230 - val_loss: 2.1697\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3466 - loss: 2.3745 - val_accuracy: 0.3400 - val_loss: 2.4382\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3359 - loss: 2.4237 - val_accuracy: 0.4010 - val_loss: 2.1884\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3368 - loss: 2.3951 - val_accuracy: 0.3470 - val_loss: 2.3362\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3348 - loss: 2.3752 - val_accuracy: 0.3730 - val_loss: 2.2790\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3286 - loss: 2.4287 - val_accuracy: 0.3100 - val_loss: 2.4017\n",
      "Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_33               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_34               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_35               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m704\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_33               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_34               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_34 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_35               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m340\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,100</span> (16.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,100\u001b[0m (16.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,876</span> (15.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,876\u001b[0m (15.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1866 - loss: 2.8724 - val_accuracy: 0.2990 - val_loss: 2.5401\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2392 - loss: 2.6440 - val_accuracy: 0.3100 - val_loss: 2.4303\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2460 - loss: 2.6078 - val_accuracy: 0.2320 - val_loss: 2.5482\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2545 - loss: 2.5872 - val_accuracy: 0.2650 - val_loss: 2.6068\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2586 - loss: 2.5874 - val_accuracy: 0.2080 - val_loss: 2.4833\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2652 - loss: 2.5872 - val_accuracy: 0.2580 - val_loss: 2.5956\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2650 - loss: 2.5930 - val_accuracy: 0.2600 - val_loss: 2.6549\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2677 - loss: 2.5942 - val_accuracy: 0.2740 - val_loss: 2.4427\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2769 - loss: 2.5704 - val_accuracy: 0.2940 - val_loss: 2.5535\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2732 - loss: 2.5621 - val_accuracy: 0.3170 - val_loss: 2.3514\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2699 - loss: 2.5715 - val_accuracy: 0.3440 - val_loss: 2.3544\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2794 - loss: 2.5654 - val_accuracy: 0.3220 - val_loss: 2.3402\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2719 - loss: 2.5497 - val_accuracy: 0.3310 - val_loss: 2.4776\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2755 - loss: 2.5574 - val_accuracy: 0.2590 - val_loss: 2.5057\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2610 - loss: 2.6072 - val_accuracy: 0.3230 - val_loss: 2.3982\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2625 - loss: 2.5887 - val_accuracy: 0.3410 - val_loss: 2.2929\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2871 - loss: 2.5459 - val_accuracy: 0.2860 - val_loss: 2.4631\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2752 - loss: 2.5684 - val_accuracy: 0.3430 - val_loss: 2.2433\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2765 - loss: 2.5703 - val_accuracy: 0.3570 - val_loss: 2.3063\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2817 - loss: 2.5696 - val_accuracy: 0.3180 - val_loss: 2.3903\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2767 - loss: 2.5507 - val_accuracy: 0.3150 - val_loss: 2.3505\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2724 - loss: 2.5632 - val_accuracy: 0.3320 - val_loss: 2.3225\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2695 - loss: 2.5842 - val_accuracy: 0.3320 - val_loss: 2.3743\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2835 - loss: 2.5197 - val_accuracy: 0.3370 - val_loss: 2.2883\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2786 - loss: 2.5605 - val_accuracy: 0.2760 - val_loss: 2.4381\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2793 - loss: 2.5651 - val_accuracy: 0.3420 - val_loss: 2.3890\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2853 - loss: 2.5640 - val_accuracy: 0.3030 - val_loss: 2.4058\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2691 - loss: 2.5670 - val_accuracy: 0.3010 - val_loss: 2.4319\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2775 - loss: 2.5666 - val_accuracy: 0.3330 - val_loss: 2.4557\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2805 - loss: 2.5709 - val_accuracy: 0.2940 - val_loss: 2.3877\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2807 - loss: 2.5284 - val_accuracy: 0.2770 - val_loss: 2.3529\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2777 - loss: 2.5445 - val_accuracy: 0.3180 - val_loss: 2.3842\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2906 - loss: 2.5347 - val_accuracy: 0.3350 - val_loss: 2.3148\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2879 - loss: 2.5244 - val_accuracy: 0.2550 - val_loss: 2.6949\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2837 - loss: 2.5546 - val_accuracy: 0.3540 - val_loss: 2.4304\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2834 - loss: 2.5671 - val_accuracy: 0.3370 - val_loss: 2.4305\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2905 - loss: 2.5689 - val_accuracy: 0.3120 - val_loss: 2.5242\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2886 - loss: 2.5472 - val_accuracy: 0.3490 - val_loss: 2.3298\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2822 - loss: 2.5686 - val_accuracy: 0.2790 - val_loss: 2.4505\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2772 - loss: 2.5633 - val_accuracy: 0.3100 - val_loss: 2.3917\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2794 - loss: 2.5334 - val_accuracy: 0.3240 - val_loss: 2.3657\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2792 - loss: 2.5624 - val_accuracy: 0.3370 - val_loss: 2.4021\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3015 - loss: 2.5305 - val_accuracy: 0.3020 - val_loss: 2.4348\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2878 - loss: 2.5435 - val_accuracy: 0.3590 - val_loss: 2.3192\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2821 - loss: 2.5647 - val_accuracy: 0.3530 - val_loss: 2.3327\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2729 - loss: 2.5642 - val_accuracy: 0.3520 - val_loss: 2.3220\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2757 - loss: 2.5678 - val_accuracy: 0.3530 - val_loss: 2.4151\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2869 - loss: 2.5667 - val_accuracy: 0.2960 - val_loss: 2.4436\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2911 - loss: 2.5429 - val_accuracy: 0.3500 - val_loss: 2.3190\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2889 - loss: 2.5373 - val_accuracy: 0.3230 - val_loss: 2.3578\n",
      "Accuracy: 0.3170\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'learning_rate': 0.001, 'batch_size': 64, 'dropout': 0.2}\n",
      "Best Accuracy: 0.5740\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [32, 64]\n",
    "dropout = [0.2,0.3]\n",
    "best_accuracy = 0\n",
    "input_shape = X_train.shape[1:]\n",
    "best_history = None\n",
    "best_model = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        for d in dropout:\n",
    "            model = Four_Layer_NN()\n",
    "            config = {\n",
    "                        'input_shape': input_shape,\n",
    "                        'epochs': 50,\n",
    "                        'dropout': d,\n",
    "                        'batch_size': batch,\n",
    "                        'lr': lr\n",
    "                    }\n",
    "            model.build_model(config)\n",
    "            history = model.train(X_train, y_train, X_valid, y_valid, config)\n",
    "            loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_model = model\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'learning_rate': lr, 'batch_size': batch, 'dropout': d}\n",
    "                best_history = history\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "51qYPRaONJ5b",
    "outputId": "70ad2534-c3c4-4414-d63c-684232200f5c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(best_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['loss'], label='Training Loss')\n",
    "plt.plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBCsRQQ_ShTZ",
    "outputId": "1cb0c858-64a8-49a5-ebf2-bdcacf65d0b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5773 - loss: 1.3965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3894131183624268, 0.5740000009536743]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv06LtUAMD9Y"
   },
   "source": [
    "### 6 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2EH713pOD0w_",
    "outputId": "dcd8bdee-94ae-4e67-b764-c02ad8c2e2cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_36               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_37               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_38               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_39               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_40               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_36               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_37               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_38               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_39               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_40               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_40 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_53 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.1728 - loss: 3.1767 - val_accuracy: 0.4760 - val_loss: 1.9919\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3832 - loss: 2.2027 - val_accuracy: 0.5140 - val_loss: 1.7549\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4171 - loss: 2.0012 - val_accuracy: 0.5250 - val_loss: 1.6284\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4518 - loss: 1.8686 - val_accuracy: 0.5540 - val_loss: 1.5688\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4622 - loss: 1.8054 - val_accuracy: 0.5430 - val_loss: 1.5236\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4661 - loss: 1.7732 - val_accuracy: 0.5600 - val_loss: 1.4839\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4709 - loss: 1.7483 - val_accuracy: 0.5610 - val_loss: 1.4734\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 1.7248 - val_accuracy: 0.5560 - val_loss: 1.4500\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4798 - loss: 1.6951 - val_accuracy: 0.5630 - val_loss: 1.4161\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4798 - loss: 1.6841 - val_accuracy: 0.5730 - val_loss: 1.4094\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4921 - loss: 1.6530 - val_accuracy: 0.5690 - val_loss: 1.3993\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 1.6210 - val_accuracy: 0.5830 - val_loss: 1.3720\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 1.6468 - val_accuracy: 0.5700 - val_loss: 1.3972\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4983 - loss: 1.6153 - val_accuracy: 0.5720 - val_loss: 1.3650\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4948 - loss: 1.6286 - val_accuracy: 0.5790 - val_loss: 1.3359\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5001 - loss: 1.6063 - val_accuracy: 0.5820 - val_loss: 1.3365\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4939 - loss: 1.6107 - val_accuracy: 0.5830 - val_loss: 1.3488\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5067 - loss: 1.5957 - val_accuracy: 0.5880 - val_loss: 1.3131\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5017 - loss: 1.5910 - val_accuracy: 0.5880 - val_loss: 1.3158\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5040 - loss: 1.5936 - val_accuracy: 0.5990 - val_loss: 1.2954\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5157 - loss: 1.5720 - val_accuracy: 0.5940 - val_loss: 1.3014\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5115 - loss: 1.5623 - val_accuracy: 0.5840 - val_loss: 1.3052\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5082 - loss: 1.5662 - val_accuracy: 0.5900 - val_loss: 1.3023\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5102 - loss: 1.5562 - val_accuracy: 0.5900 - val_loss: 1.2866\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5096 - loss: 1.5678 - val_accuracy: 0.5980 - val_loss: 1.2887\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5123 - loss: 1.5561 - val_accuracy: 0.5980 - val_loss: 1.2792\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: 1.5560 - val_accuracy: 0.6000 - val_loss: 1.2864\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5073 - loss: 1.5624 - val_accuracy: 0.5910 - val_loss: 1.3030\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5069 - loss: 1.5643 - val_accuracy: 0.5990 - val_loss: 1.2670\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5134 - loss: 1.5611 - val_accuracy: 0.5990 - val_loss: 1.2743\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5150 - loss: 1.5526 - val_accuracy: 0.6020 - val_loss: 1.2816\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 1.5503 - val_accuracy: 0.5860 - val_loss: 1.2906\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: 1.5455 - val_accuracy: 0.6090 - val_loss: 1.2615\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5155 - loss: 1.5419 - val_accuracy: 0.5910 - val_loss: 1.2904\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5167 - loss: 1.5485 - val_accuracy: 0.6040 - val_loss: 1.2680\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5216 - loss: 1.5250 - val_accuracy: 0.6020 - val_loss: 1.2783\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5180 - loss: 1.5207 - val_accuracy: 0.5940 - val_loss: 1.2515\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5201 - loss: 1.5235 - val_accuracy: 0.5960 - val_loss: 1.2687\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5249 - loss: 1.5069 - val_accuracy: 0.6110 - val_loss: 1.2476\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5253 - loss: 1.5244 - val_accuracy: 0.5900 - val_loss: 1.2621\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5087 - loss: 1.5458 - val_accuracy: 0.6100 - val_loss: 1.2608\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5233 - loss: 1.5273 - val_accuracy: 0.5990 - val_loss: 1.2457\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5286 - loss: 1.5287 - val_accuracy: 0.5960 - val_loss: 1.2589\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5107 - loss: 1.5364 - val_accuracy: 0.5980 - val_loss: 1.2446\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5183 - loss: 1.5199 - val_accuracy: 0.6080 - val_loss: 1.2530\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5261 - loss: 1.5084 - val_accuracy: 0.6100 - val_loss: 1.2457\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 1.5024 - val_accuracy: 0.6190 - val_loss: 1.2321\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5219 - loss: 1.5141 - val_accuracy: 0.6090 - val_loss: 1.2561\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5305 - loss: 1.4878 - val_accuracy: 0.6110 - val_loss: 1.2461\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5190 - loss: 1.5207 - val_accuracy: 0.6170 - val_loss: 1.2292\n",
      "Accuracy: 0.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_41               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_42               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_43               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_44               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_45               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_41               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_41 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_42               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_43               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_43 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_44               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_44 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_45               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_45 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.1133 - loss: 3.3656 - val_accuracy: 0.4180 - val_loss: 2.2183\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2737 - loss: 2.4675 - val_accuracy: 0.4400 - val_loss: 1.9275\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3263 - loss: 2.2238 - val_accuracy: 0.4820 - val_loss: 1.7790\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3628 - loss: 2.0941 - val_accuracy: 0.4840 - val_loss: 1.7022\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3866 - loss: 2.0151 - val_accuracy: 0.4990 - val_loss: 1.6378\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3972 - loss: 1.9724 - val_accuracy: 0.5090 - val_loss: 1.6038\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4001 - loss: 1.9422 - val_accuracy: 0.4950 - val_loss: 1.5861\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4004 - loss: 1.9239 - val_accuracy: 0.5060 - val_loss: 1.5472\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4082 - loss: 1.8993 - val_accuracy: 0.5320 - val_loss: 1.5423\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4230 - loss: 1.8779 - val_accuracy: 0.5240 - val_loss: 1.5125\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4263 - loss: 1.8508 - val_accuracy: 0.5130 - val_loss: 1.5297\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4290 - loss: 1.8428 - val_accuracy: 0.5400 - val_loss: 1.4900\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4386 - loss: 1.8261 - val_accuracy: 0.5270 - val_loss: 1.4934\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4252 - loss: 1.8415 - val_accuracy: 0.5340 - val_loss: 1.4796\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4378 - loss: 1.8085 - val_accuracy: 0.5430 - val_loss: 1.4599\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4469 - loss: 1.7906 - val_accuracy: 0.5370 - val_loss: 1.4661\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4480 - loss: 1.7877 - val_accuracy: 0.5410 - val_loss: 1.4600\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4531 - loss: 1.7842 - val_accuracy: 0.5290 - val_loss: 1.4540\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4514 - loss: 1.7643 - val_accuracy: 0.5320 - val_loss: 1.4511\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4520 - loss: 1.7546 - val_accuracy: 0.5510 - val_loss: 1.4347\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4548 - loss: 1.7522 - val_accuracy: 0.5460 - val_loss: 1.4288\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4542 - loss: 1.7804 - val_accuracy: 0.5460 - val_loss: 1.4239\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4480 - loss: 1.7783 - val_accuracy: 0.5490 - val_loss: 1.4285\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4571 - loss: 1.7594 - val_accuracy: 0.5550 - val_loss: 1.4273\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4603 - loss: 1.7458 - val_accuracy: 0.5490 - val_loss: 1.4228\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4568 - loss: 1.7480 - val_accuracy: 0.5330 - val_loss: 1.4128\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4577 - loss: 1.7219 - val_accuracy: 0.5530 - val_loss: 1.4118\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4533 - loss: 1.7572 - val_accuracy: 0.5580 - val_loss: 1.4034\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4591 - loss: 1.7421 - val_accuracy: 0.5670 - val_loss: 1.3910\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4574 - loss: 1.7404 - val_accuracy: 0.5710 - val_loss: 1.3875\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4620 - loss: 1.7287 - val_accuracy: 0.5570 - val_loss: 1.3924\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4550 - loss: 1.7481 - val_accuracy: 0.5600 - val_loss: 1.3844\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4598 - loss: 1.7244 - val_accuracy: 0.5560 - val_loss: 1.3756\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4650 - loss: 1.7214 - val_accuracy: 0.5720 - val_loss: 1.3900\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4619 - loss: 1.7336 - val_accuracy: 0.5590 - val_loss: 1.3828\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4635 - loss: 1.7127 - val_accuracy: 0.5660 - val_loss: 1.3736\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4672 - loss: 1.7201 - val_accuracy: 0.5620 - val_loss: 1.3778\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4703 - loss: 1.6934 - val_accuracy: 0.5680 - val_loss: 1.3694\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4574 - loss: 1.7265 - val_accuracy: 0.5680 - val_loss: 1.3633\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4692 - loss: 1.6910 - val_accuracy: 0.5710 - val_loss: 1.3610\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4664 - loss: 1.7051 - val_accuracy: 0.5640 - val_loss: 1.3939\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4712 - loss: 1.7118 - val_accuracy: 0.5650 - val_loss: 1.3553\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4604 - loss: 1.7151 - val_accuracy: 0.5740 - val_loss: 1.3590\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4668 - loss: 1.7068 - val_accuracy: 0.5760 - val_loss: 1.3554\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4727 - loss: 1.6923 - val_accuracy: 0.5760 - val_loss: 1.3612\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4725 - loss: 1.6913 - val_accuracy: 0.5750 - val_loss: 1.3541\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4610 - loss: 1.6965 - val_accuracy: 0.5790 - val_loss: 1.3370\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4690 - loss: 1.6901 - val_accuracy: 0.5730 - val_loss: 1.3391\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4649 - loss: 1.6992 - val_accuracy: 0.5620 - val_loss: 1.3614\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4717 - loss: 1.6920 - val_accuracy: 0.5670 - val_loss: 1.3556\n",
      "Accuracy: 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_46               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_47               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_48               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_49               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_50               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_60 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_46               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_46 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_61 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_47               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_47 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_48               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_48 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_49               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_49 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_64 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_50               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_50 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_65 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.0905 - loss: 3.5267 - val_accuracy: 0.3750 - val_loss: 2.4199\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2122 - loss: 2.6798 - val_accuracy: 0.4120 - val_loss: 2.1326\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2660 - loss: 2.4104 - val_accuracy: 0.4310 - val_loss: 1.9700\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3000 - loss: 2.2771 - val_accuracy: 0.4540 - val_loss: 1.8616\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3130 - loss: 2.1935 - val_accuracy: 0.4720 - val_loss: 1.7844\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3324 - loss: 2.1359 - val_accuracy: 0.4790 - val_loss: 1.7513\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3362 - loss: 2.1085 - val_accuracy: 0.4830 - val_loss: 1.7175\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3445 - loss: 2.0779 - val_accuracy: 0.4750 - val_loss: 1.6989\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3535 - loss: 2.0606 - val_accuracy: 0.4690 - val_loss: 1.6808\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3542 - loss: 2.0462 - val_accuracy: 0.4800 - val_loss: 1.6597\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3572 - loss: 2.0280 - val_accuracy: 0.4890 - val_loss: 1.6267\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3696 - loss: 2.0015 - val_accuracy: 0.4880 - val_loss: 1.6339\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3720 - loss: 1.9900 - val_accuracy: 0.4840 - val_loss: 1.6205\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3786 - loss: 1.9806 - val_accuracy: 0.4850 - val_loss: 1.6077\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3724 - loss: 1.9797 - val_accuracy: 0.4800 - val_loss: 1.6123\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3762 - loss: 1.9869 - val_accuracy: 0.4830 - val_loss: 1.5905\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3822 - loss: 1.9642 - val_accuracy: 0.4970 - val_loss: 1.5964\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3835 - loss: 1.9519 - val_accuracy: 0.5040 - val_loss: 1.5847\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3790 - loss: 1.9564 - val_accuracy: 0.4880 - val_loss: 1.5959\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3847 - loss: 1.9356 - val_accuracy: 0.4870 - val_loss: 1.5785\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3861 - loss: 1.9282 - val_accuracy: 0.4950 - val_loss: 1.5748\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3881 - loss: 1.9257 - val_accuracy: 0.5020 - val_loss: 1.5707\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3957 - loss: 1.9367 - val_accuracy: 0.5050 - val_loss: 1.5563\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3965 - loss: 1.9160 - val_accuracy: 0.5000 - val_loss: 1.5606\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3982 - loss: 1.8990 - val_accuracy: 0.5110 - val_loss: 1.5554\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3946 - loss: 1.9259 - val_accuracy: 0.4970 - val_loss: 1.5474\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3938 - loss: 1.9232 - val_accuracy: 0.5120 - val_loss: 1.5549\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3943 - loss: 1.9179 - val_accuracy: 0.5270 - val_loss: 1.5394\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4058 - loss: 1.9104 - val_accuracy: 0.5190 - val_loss: 1.5432\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3979 - loss: 1.9106 - val_accuracy: 0.5050 - val_loss: 1.5475\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3953 - loss: 1.9214 - val_accuracy: 0.5190 - val_loss: 1.5238\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4036 - loss: 1.8932 - val_accuracy: 0.5060 - val_loss: 1.5217\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3995 - loss: 1.8997 - val_accuracy: 0.5270 - val_loss: 1.5295\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4097 - loss: 1.8928 - val_accuracy: 0.5260 - val_loss: 1.5147\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4115 - loss: 1.8829 - val_accuracy: 0.5170 - val_loss: 1.5158\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4023 - loss: 1.8896 - val_accuracy: 0.5340 - val_loss: 1.5295\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4054 - loss: 1.8669 - val_accuracy: 0.5120 - val_loss: 1.5122\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4052 - loss: 1.8985 - val_accuracy: 0.5150 - val_loss: 1.5095\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4026 - loss: 1.8832 - val_accuracy: 0.5050 - val_loss: 1.5220\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4021 - loss: 1.8806 - val_accuracy: 0.5220 - val_loss: 1.5176\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4032 - loss: 1.8687 - val_accuracy: 0.5330 - val_loss: 1.5070\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4121 - loss: 1.8787 - val_accuracy: 0.5310 - val_loss: 1.5143\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4118 - loss: 1.8720 - val_accuracy: 0.5140 - val_loss: 1.5114\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4159 - loss: 1.8825 - val_accuracy: 0.5230 - val_loss: 1.4943\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4093 - loss: 1.8807 - val_accuracy: 0.5210 - val_loss: 1.5199\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4135 - loss: 1.8721 - val_accuracy: 0.5200 - val_loss: 1.5102\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4120 - loss: 1.8814 - val_accuracy: 0.5230 - val_loss: 1.4820\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4061 - loss: 1.8726 - val_accuracy: 0.5110 - val_loss: 1.5068\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4073 - loss: 1.8895 - val_accuracy: 0.5140 - val_loss: 1.5039\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4055 - loss: 1.8884 - val_accuracy: 0.5100 - val_loss: 1.5018\n",
      "Accuracy: 0.5335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_51               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_52               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_53               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_54               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_55               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_51               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_52               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_68 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_53               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_53 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_69 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_54               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_70 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_55               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1526 - loss: 3.2465 - val_accuracy: 0.4210 - val_loss: 2.2212\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3418 - loss: 2.3274 - val_accuracy: 0.5030 - val_loss: 1.8427\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4129 - loss: 2.0592 - val_accuracy: 0.5220 - val_loss: 1.6936\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4421 - loss: 1.9251 - val_accuracy: 0.5310 - val_loss: 1.6186\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4697 - loss: 1.8221 - val_accuracy: 0.5520 - val_loss: 1.5512\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4760 - loss: 1.7814 - val_accuracy: 0.5620 - val_loss: 1.5109\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4797 - loss: 1.7375 - val_accuracy: 0.5620 - val_loss: 1.4833\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4928 - loss: 1.7032 - val_accuracy: 0.5730 - val_loss: 1.4616\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4937 - loss: 1.6667 - val_accuracy: 0.5680 - val_loss: 1.4327\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4880 - loss: 1.6706 - val_accuracy: 0.5660 - val_loss: 1.4150\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5053 - loss: 1.6289 - val_accuracy: 0.5690 - val_loss: 1.3976\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5075 - loss: 1.6145 - val_accuracy: 0.5720 - val_loss: 1.3887\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5058 - loss: 1.6078 - val_accuracy: 0.5880 - val_loss: 1.3756\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5138 - loss: 1.5922 - val_accuracy: 0.5560 - val_loss: 1.3739\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5105 - loss: 1.5930 - val_accuracy: 0.5860 - val_loss: 1.3387\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5096 - loss: 1.5796 - val_accuracy: 0.5750 - val_loss: 1.3423\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5204 - loss: 1.5708 - val_accuracy: 0.5820 - val_loss: 1.3390\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5140 - loss: 1.5658 - val_accuracy: 0.5720 - val_loss: 1.3363\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5152 - loss: 1.5509 - val_accuracy: 0.5900 - val_loss: 1.3311\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5179 - loss: 1.5448 - val_accuracy: 0.5880 - val_loss: 1.3120\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5256 - loss: 1.5297 - val_accuracy: 0.5890 - val_loss: 1.3089\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5030 - loss: 1.5681 - val_accuracy: 0.5850 - val_loss: 1.3088\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5262 - loss: 1.5245 - val_accuracy: 0.5850 - val_loss: 1.3067\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5179 - loss: 1.5333 - val_accuracy: 0.5940 - val_loss: 1.3065\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5346 - loss: 1.5026 - val_accuracy: 0.6020 - val_loss: 1.2902\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5319 - loss: 1.5058 - val_accuracy: 0.5930 - val_loss: 1.2858\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5261 - loss: 1.5168 - val_accuracy: 0.6100 - val_loss: 1.2744\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5383 - loss: 1.4835 - val_accuracy: 0.6050 - val_loss: 1.2702\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5297 - loss: 1.5024 - val_accuracy: 0.5950 - val_loss: 1.2743\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5284 - loss: 1.4919 - val_accuracy: 0.5990 - val_loss: 1.2883\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 1.4979 - val_accuracy: 0.6070 - val_loss: 1.2710\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5231 - loss: 1.5000 - val_accuracy: 0.6030 - val_loss: 1.2664\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5372 - loss: 1.4927 - val_accuracy: 0.6000 - val_loss: 1.2739\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5364 - loss: 1.4784 - val_accuracy: 0.6060 - val_loss: 1.2585\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5406 - loss: 1.4627 - val_accuracy: 0.6030 - val_loss: 1.2561\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5364 - loss: 1.4813 - val_accuracy: 0.6110 - val_loss: 1.2510\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5339 - loss: 1.4883 - val_accuracy: 0.6140 - val_loss: 1.2457\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5347 - loss: 1.4799 - val_accuracy: 0.6090 - val_loss: 1.2360\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5393 - loss: 1.4630 - val_accuracy: 0.6040 - val_loss: 1.2499\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5376 - loss: 1.4648 - val_accuracy: 0.6130 - val_loss: 1.2423\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5381 - loss: 1.4660 - val_accuracy: 0.6120 - val_loss: 1.2497\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5327 - loss: 1.4832 - val_accuracy: 0.6040 - val_loss: 1.2431\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5329 - loss: 1.4675 - val_accuracy: 0.5960 - val_loss: 1.2356\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5374 - loss: 1.4689 - val_accuracy: 0.5980 - val_loss: 1.2455\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5332 - loss: 1.4700 - val_accuracy: 0.6050 - val_loss: 1.2322\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5461 - loss: 1.4451 - val_accuracy: 0.6050 - val_loss: 1.2404\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5404 - loss: 1.4614 - val_accuracy: 0.6150 - val_loss: 1.2096\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5543 - loss: 1.4359 - val_accuracy: 0.5980 - val_loss: 1.2318\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5421 - loss: 1.4487 - val_accuracy: 0.6050 - val_loss: 1.2304\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5466 - loss: 1.4390 - val_accuracy: 0.6090 - val_loss: 1.2198\n",
      "Accuracy: 0.6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_56               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_57               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_58               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_60 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_72 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_56               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_57               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_58               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_58 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_59               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_59 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_76 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_60               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_60 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_77 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.1087 - loss: 3.4148 - val_accuracy: 0.3770 - val_loss: 2.3422\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2675 - loss: 2.5476 - val_accuracy: 0.4360 - val_loss: 2.0126\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3304 - loss: 2.2788 - val_accuracy: 0.4900 - val_loss: 1.8436\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3590 - loss: 2.1385 - val_accuracy: 0.5010 - val_loss: 1.7534\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3876 - loss: 2.0366 - val_accuracy: 0.5030 - val_loss: 1.6913\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3962 - loss: 1.9705 - val_accuracy: 0.5050 - val_loss: 1.6440\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4091 - loss: 1.9502 - val_accuracy: 0.5230 - val_loss: 1.6051\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4262 - loss: 1.8945 - val_accuracy: 0.5180 - val_loss: 1.5825\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4311 - loss: 1.8761 - val_accuracy: 0.5440 - val_loss: 1.5432\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4365 - loss: 1.8515 - val_accuracy: 0.5380 - val_loss: 1.5267\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4453 - loss: 1.8291 - val_accuracy: 0.5410 - val_loss: 1.5254\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4445 - loss: 1.8106 - val_accuracy: 0.5340 - val_loss: 1.5079\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4258 - loss: 1.8300 - val_accuracy: 0.5380 - val_loss: 1.4944\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4418 - loss: 1.8096 - val_accuracy: 0.5490 - val_loss: 1.4744\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4548 - loss: 1.7678 - val_accuracy: 0.5490 - val_loss: 1.4691\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4440 - loss: 1.7803 - val_accuracy: 0.5400 - val_loss: 1.4631\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4473 - loss: 1.7648 - val_accuracy: 0.5430 - val_loss: 1.4615\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4506 - loss: 1.7707 - val_accuracy: 0.5490 - val_loss: 1.4513\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4612 - loss: 1.7255 - val_accuracy: 0.5480 - val_loss: 1.4422\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4564 - loss: 1.7536 - val_accuracy: 0.5510 - val_loss: 1.4414\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4575 - loss: 1.7342 - val_accuracy: 0.5670 - val_loss: 1.4311\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4530 - loss: 1.7320 - val_accuracy: 0.5530 - val_loss: 1.4303\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4671 - loss: 1.7297 - val_accuracy: 0.5420 - val_loss: 1.4411\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4594 - loss: 1.7280 - val_accuracy: 0.5640 - val_loss: 1.4086\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4726 - loss: 1.7143 - val_accuracy: 0.5640 - val_loss: 1.4110\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4641 - loss: 1.7201 - val_accuracy: 0.5500 - val_loss: 1.4059\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4660 - loss: 1.7228 - val_accuracy: 0.5700 - val_loss: 1.4009\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4641 - loss: 1.6975 - val_accuracy: 0.5620 - val_loss: 1.3919\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4730 - loss: 1.6837 - val_accuracy: 0.5500 - val_loss: 1.3908\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4598 - loss: 1.7138 - val_accuracy: 0.5590 - val_loss: 1.3905\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 1.7008 - val_accuracy: 0.5680 - val_loss: 1.3847\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4684 - loss: 1.7012 - val_accuracy: 0.5740 - val_loss: 1.3766\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4761 - loss: 1.6828 - val_accuracy: 0.5750 - val_loss: 1.3740\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4653 - loss: 1.6984 - val_accuracy: 0.5670 - val_loss: 1.3610\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4703 - loss: 1.6768 - val_accuracy: 0.5740 - val_loss: 1.3636\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4658 - loss: 1.7037 - val_accuracy: 0.5590 - val_loss: 1.3764\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4727 - loss: 1.6802 - val_accuracy: 0.5490 - val_loss: 1.3745\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4807 - loss: 1.6589 - val_accuracy: 0.5730 - val_loss: 1.3699\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4819 - loss: 1.6623 - val_accuracy: 0.5660 - val_loss: 1.3590\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4753 - loss: 1.6728 - val_accuracy: 0.5820 - val_loss: 1.3521\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4771 - loss: 1.6648 - val_accuracy: 0.5860 - val_loss: 1.3432\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4804 - loss: 1.6653 - val_accuracy: 0.5700 - val_loss: 1.3514\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4777 - loss: 1.6649 - val_accuracy: 0.5840 - val_loss: 1.3469\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4747 - loss: 1.6575 - val_accuracy: 0.5840 - val_loss: 1.3426\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4708 - loss: 1.6833 - val_accuracy: 0.5760 - val_loss: 1.3515\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4848 - loss: 1.6399 - val_accuracy: 0.5750 - val_loss: 1.3410\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4754 - loss: 1.6596 - val_accuracy: 0.5660 - val_loss: 1.3354\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4824 - loss: 1.6548 - val_accuracy: 0.5770 - val_loss: 1.3406\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4724 - loss: 1.6571 - val_accuracy: 0.5780 - val_loss: 1.3303\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4958 - loss: 1.6334 - val_accuracy: 0.5750 - val_loss: 1.3312\n",
      "Accuracy: 0.5760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_61               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_62               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_63               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_64               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_65               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_78 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_61               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_61 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_79 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_62               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_62 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_80 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_63               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_63 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_64               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_64 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_65               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_65 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0885 - loss: 3.5926 - val_accuracy: 0.3470 - val_loss: 2.5711\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1887 - loss: 2.7979 - val_accuracy: 0.4050 - val_loss: 2.2326\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2444 - loss: 2.5173 - val_accuracy: 0.4110 - val_loss: 2.0707\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2846 - loss: 2.3594 - val_accuracy: 0.4240 - val_loss: 1.9597\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3081 - loss: 2.2377 - val_accuracy: 0.4440 - val_loss: 1.8785\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3217 - loss: 2.1771 - val_accuracy: 0.4430 - val_loss: 1.8194\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3174 - loss: 2.1667 - val_accuracy: 0.4490 - val_loss: 1.7673\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3459 - loss: 2.0899 - val_accuracy: 0.4750 - val_loss: 1.7423\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3449 - loss: 2.0859 - val_accuracy: 0.4780 - val_loss: 1.7126\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3547 - loss: 2.0476 - val_accuracy: 0.4770 - val_loss: 1.6932\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3597 - loss: 2.0409 - val_accuracy: 0.4810 - val_loss: 1.6883\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3640 - loss: 2.0106 - val_accuracy: 0.4890 - val_loss: 1.6627\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3670 - loss: 2.0021 - val_accuracy: 0.4970 - val_loss: 1.6410\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3758 - loss: 1.9585 - val_accuracy: 0.5000 - val_loss: 1.6306\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3706 - loss: 1.9775 - val_accuracy: 0.4930 - val_loss: 1.6147\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3816 - loss: 1.9487 - val_accuracy: 0.5010 - val_loss: 1.6073\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3960 - loss: 1.9303 - val_accuracy: 0.4950 - val_loss: 1.5926\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3817 - loss: 1.9329 - val_accuracy: 0.5120 - val_loss: 1.5857\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3825 - loss: 1.9437 - val_accuracy: 0.5010 - val_loss: 1.5829\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3858 - loss: 1.9318 - val_accuracy: 0.5090 - val_loss: 1.5768\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3937 - loss: 1.9324 - val_accuracy: 0.5050 - val_loss: 1.5755\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3902 - loss: 1.9223 - val_accuracy: 0.4930 - val_loss: 1.5711\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3948 - loss: 1.9134 - val_accuracy: 0.5110 - val_loss: 1.5618\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3940 - loss: 1.8951 - val_accuracy: 0.5210 - val_loss: 1.5471\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4028 - loss: 1.8935 - val_accuracy: 0.5070 - val_loss: 1.5454\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4042 - loss: 1.8850 - val_accuracy: 0.5220 - val_loss: 1.5318\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4067 - loss: 1.8961 - val_accuracy: 0.5160 - val_loss: 1.5389\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4054 - loss: 1.8833 - val_accuracy: 0.5220 - val_loss: 1.5406\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4040 - loss: 1.8829 - val_accuracy: 0.5160 - val_loss: 1.5248\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4105 - loss: 1.8556 - val_accuracy: 0.5270 - val_loss: 1.5318\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4155 - loss: 1.8642 - val_accuracy: 0.5330 - val_loss: 1.5216\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4134 - loss: 1.8698 - val_accuracy: 0.5180 - val_loss: 1.5220\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4162 - loss: 1.8522 - val_accuracy: 0.5190 - val_loss: 1.5138\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4157 - loss: 1.8526 - val_accuracy: 0.5330 - val_loss: 1.5207\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4164 - loss: 1.8455 - val_accuracy: 0.5300 - val_loss: 1.5060\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4193 - loss: 1.8613 - val_accuracy: 0.5360 - val_loss: 1.5131\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4213 - loss: 1.8466 - val_accuracy: 0.5350 - val_loss: 1.4955\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4060 - loss: 1.8542 - val_accuracy: 0.5270 - val_loss: 1.4872\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4224 - loss: 1.8457 - val_accuracy: 0.5070 - val_loss: 1.4993\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4198 - loss: 1.8366 - val_accuracy: 0.5200 - val_loss: 1.4867\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4173 - loss: 1.8581 - val_accuracy: 0.5250 - val_loss: 1.4912\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4266 - loss: 1.8325 - val_accuracy: 0.5270 - val_loss: 1.4954\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4210 - loss: 1.8393 - val_accuracy: 0.5340 - val_loss: 1.4938\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4210 - loss: 1.8448 - val_accuracy: 0.5310 - val_loss: 1.4770\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4245 - loss: 1.8364 - val_accuracy: 0.5240 - val_loss: 1.4789\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 1.8251 - val_accuracy: 0.5390 - val_loss: 1.4816\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4268 - loss: 1.8189 - val_accuracy: 0.5250 - val_loss: 1.4778\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4223 - loss: 1.8365 - val_accuracy: 0.5320 - val_loss: 1.4700\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4216 - loss: 1.8317 - val_accuracy: 0.5360 - val_loss: 1.4732\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4239 - loss: 1.8183 - val_accuracy: 0.5370 - val_loss: 1.4758\n",
      "Accuracy: 0.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_18\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_18\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_66               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_67               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_68               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_69               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_70               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_66               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_67               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_67 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_68               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_68 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_69               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_69 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_70               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_70 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3016 - loss: 2.4531 - val_accuracy: 0.4510 - val_loss: 1.7561\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4129 - loss: 1.9578 - val_accuracy: 0.5080 - val_loss: 1.6296\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4339 - loss: 1.8939 - val_accuracy: 0.4950 - val_loss: 1.6867\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4489 - loss: 1.8600 - val_accuracy: 0.5050 - val_loss: 1.6738\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4326 - loss: 1.8810 - val_accuracy: 0.4980 - val_loss: 1.6693\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4374 - loss: 1.8523 - val_accuracy: 0.5090 - val_loss: 1.6183\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4498 - loss: 1.8305 - val_accuracy: 0.5180 - val_loss: 1.6048\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4586 - loss: 1.8163 - val_accuracy: 0.5290 - val_loss: 1.6116\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4581 - loss: 1.8291 - val_accuracy: 0.5110 - val_loss: 1.6391\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4562 - loss: 1.8195 - val_accuracy: 0.5190 - val_loss: 1.5747\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4521 - loss: 1.8299 - val_accuracy: 0.5320 - val_loss: 1.5630\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4665 - loss: 1.7856 - val_accuracy: 0.5390 - val_loss: 1.5802\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4564 - loss: 1.8062 - val_accuracy: 0.5380 - val_loss: 1.5359\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4650 - loss: 1.8030 - val_accuracy: 0.5120 - val_loss: 1.5999\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4652 - loss: 1.8044 - val_accuracy: 0.5220 - val_loss: 1.5927\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4557 - loss: 1.8051 - val_accuracy: 0.5120 - val_loss: 1.5640\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4604 - loss: 1.8004 - val_accuracy: 0.5360 - val_loss: 1.5530\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4721 - loss: 1.7704 - val_accuracy: 0.5530 - val_loss: 1.5421\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4743 - loss: 1.7658 - val_accuracy: 0.5190 - val_loss: 1.5873\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4642 - loss: 1.7862 - val_accuracy: 0.5680 - val_loss: 1.5026\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4617 - loss: 1.8121 - val_accuracy: 0.5320 - val_loss: 1.5468\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4704 - loss: 1.7828 - val_accuracy: 0.5210 - val_loss: 1.5963\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4671 - loss: 1.7790 - val_accuracy: 0.5470 - val_loss: 1.5177\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4824 - loss: 1.7498 - val_accuracy: 0.5290 - val_loss: 1.5597\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4697 - loss: 1.7681 - val_accuracy: 0.5440 - val_loss: 1.5155\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4809 - loss: 1.7471 - val_accuracy: 0.5480 - val_loss: 1.5197\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4663 - loss: 1.7984 - val_accuracy: 0.5290 - val_loss: 1.5564\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4735 - loss: 1.7728 - val_accuracy: 0.5450 - val_loss: 1.5360\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4724 - loss: 1.7507 - val_accuracy: 0.5310 - val_loss: 1.5894\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4764 - loss: 1.7615 - val_accuracy: 0.5520 - val_loss: 1.5227\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4766 - loss: 1.7818 - val_accuracy: 0.5560 - val_loss: 1.4908\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4807 - loss: 1.7683 - val_accuracy: 0.5360 - val_loss: 1.5476\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4866 - loss: 1.7438 - val_accuracy: 0.5170 - val_loss: 1.5479\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4839 - loss: 1.7395 - val_accuracy: 0.5430 - val_loss: 1.5663\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4769 - loss: 1.7680 - val_accuracy: 0.5430 - val_loss: 1.5407\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4785 - loss: 1.7465 - val_accuracy: 0.5330 - val_loss: 1.5527\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4707 - loss: 1.7734 - val_accuracy: 0.5600 - val_loss: 1.4829\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4803 - loss: 1.7418 - val_accuracy: 0.5280 - val_loss: 1.5610\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4786 - loss: 1.7602 - val_accuracy: 0.5470 - val_loss: 1.5185\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4757 - loss: 1.7582 - val_accuracy: 0.5680 - val_loss: 1.4763\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4818 - loss: 1.7374 - val_accuracy: 0.5630 - val_loss: 1.5108\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4800 - loss: 1.7497 - val_accuracy: 0.5390 - val_loss: 1.5169\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4822 - loss: 1.7521 - val_accuracy: 0.5550 - val_loss: 1.4953\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4747 - loss: 1.7566 - val_accuracy: 0.5350 - val_loss: 1.4961\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4666 - loss: 1.7764 - val_accuracy: 0.5520 - val_loss: 1.5006\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4867 - loss: 1.7337 - val_accuracy: 0.5490 - val_loss: 1.5016\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4777 - loss: 1.7585 - val_accuracy: 0.5550 - val_loss: 1.4943\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4860 - loss: 1.7344 - val_accuracy: 0.5270 - val_loss: 1.5738\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4868 - loss: 1.7207 - val_accuracy: 0.5420 - val_loss: 1.4889\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4877 - loss: 1.7174 - val_accuracy: 0.5590 - val_loss: 1.4976\n",
      "Accuracy: 0.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_71               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_72               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_73               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_74               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_75               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_90 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_71               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_71 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_91 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_72               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_72 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_92 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_73               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_73 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_93 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_74               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_74 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_94 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_75               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_75 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_95 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2560 - loss: 2.5913 - val_accuracy: 0.4330 - val_loss: 1.8655\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3518 - loss: 2.1158 - val_accuracy: 0.4730 - val_loss: 1.7731\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3752 - loss: 2.0664 - val_accuracy: 0.4670 - val_loss: 1.7502\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3836 - loss: 2.0380 - val_accuracy: 0.5010 - val_loss: 1.7214\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3919 - loss: 2.0086 - val_accuracy: 0.4700 - val_loss: 1.7416\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3911 - loss: 2.0128 - val_accuracy: 0.4640 - val_loss: 1.7582\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3879 - loss: 2.0119 - val_accuracy: 0.4780 - val_loss: 1.7408\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3916 - loss: 1.9995 - val_accuracy: 0.4620 - val_loss: 1.7775\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3945 - loss: 2.0076 - val_accuracy: 0.5150 - val_loss: 1.6631\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4090 - loss: 1.9802 - val_accuracy: 0.4990 - val_loss: 1.6532\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4006 - loss: 1.9789 - val_accuracy: 0.4870 - val_loss: 1.7255\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4068 - loss: 1.9821 - val_accuracy: 0.5020 - val_loss: 1.6575\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4135 - loss: 1.9545 - val_accuracy: 0.5130 - val_loss: 1.6373\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4088 - loss: 1.9620 - val_accuracy: 0.4750 - val_loss: 1.7108\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4059 - loss: 1.9662 - val_accuracy: 0.5200 - val_loss: 1.6346\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4095 - loss: 1.9705 - val_accuracy: 0.4800 - val_loss: 1.6885\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4166 - loss: 1.9415 - val_accuracy: 0.4930 - val_loss: 1.6843\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4199 - loss: 1.9417 - val_accuracy: 0.4890 - val_loss: 1.6584\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4094 - loss: 1.9614 - val_accuracy: 0.5060 - val_loss: 1.6587\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4160 - loss: 1.9546 - val_accuracy: 0.4790 - val_loss: 1.7300\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4191 - loss: 1.9475 - val_accuracy: 0.5040 - val_loss: 1.6992\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4217 - loss: 1.9390 - val_accuracy: 0.5280 - val_loss: 1.6152\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4279 - loss: 1.9234 - val_accuracy: 0.5150 - val_loss: 1.6383\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4186 - loss: 1.9374 - val_accuracy: 0.4890 - val_loss: 1.7182\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4171 - loss: 1.9360 - val_accuracy: 0.5170 - val_loss: 1.6645\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4254 - loss: 1.9215 - val_accuracy: 0.5020 - val_loss: 1.6632\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4213 - loss: 1.9408 - val_accuracy: 0.4990 - val_loss: 1.6759\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4203 - loss: 1.9296 - val_accuracy: 0.5140 - val_loss: 1.6472\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4331 - loss: 1.9131 - val_accuracy: 0.5140 - val_loss: 1.6434\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4304 - loss: 1.9258 - val_accuracy: 0.4520 - val_loss: 1.7705\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4284 - loss: 1.9310 - val_accuracy: 0.4910 - val_loss: 1.6432\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4258 - loss: 1.9144 - val_accuracy: 0.4910 - val_loss: 1.6727\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4216 - loss: 1.9456 - val_accuracy: 0.5140 - val_loss: 1.6891\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4295 - loss: 1.9359 - val_accuracy: 0.5130 - val_loss: 1.6319\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4197 - loss: 1.9311 - val_accuracy: 0.4960 - val_loss: 1.6567\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4288 - loss: 1.9163 - val_accuracy: 0.5000 - val_loss: 1.6191\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4224 - loss: 1.9211 - val_accuracy: 0.4990 - val_loss: 1.6086\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4302 - loss: 1.9178 - val_accuracy: 0.5220 - val_loss: 1.6115\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4274 - loss: 1.9233 - val_accuracy: 0.5140 - val_loss: 1.5991\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4268 - loss: 1.9268 - val_accuracy: 0.4940 - val_loss: 1.6281\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4234 - loss: 1.9285 - val_accuracy: 0.5320 - val_loss: 1.6254\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4194 - loss: 1.9563 - val_accuracy: 0.5120 - val_loss: 1.6479\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4318 - loss: 1.9367 - val_accuracy: 0.5210 - val_loss: 1.6301\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4342 - loss: 1.9086 - val_accuracy: 0.5190 - val_loss: 1.6340\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4319 - loss: 1.9160 - val_accuracy: 0.5120 - val_loss: 1.6186\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4274 - loss: 1.9246 - val_accuracy: 0.5230 - val_loss: 1.6004\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4256 - loss: 1.9227 - val_accuracy: 0.5340 - val_loss: 1.6046\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4253 - loss: 1.9236 - val_accuracy: 0.5140 - val_loss: 1.6274\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4276 - loss: 1.9289 - val_accuracy: 0.5100 - val_loss: 1.6090\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4320 - loss: 1.9063 - val_accuracy: 0.5060 - val_loss: 1.6379\n",
      "Accuracy: 0.4935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_76               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_77               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_78               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_79               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_80               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_96 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_76               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_76 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_97 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_77               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_77 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_98 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_78               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_78 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_99 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_79               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_79 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_100 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_80               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_80 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_101 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2062 - loss: 2.7636 - val_accuracy: 0.3640 - val_loss: 1.9408\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2874 - loss: 2.2622 - val_accuracy: 0.3870 - val_loss: 1.9629\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3001 - loss: 2.2265 - val_accuracy: 0.4020 - val_loss: 1.8722\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3103 - loss: 2.2073 - val_accuracy: 0.3940 - val_loss: 1.8504\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3130 - loss: 2.2117 - val_accuracy: 0.4280 - val_loss: 1.8256\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3237 - loss: 2.1738 - val_accuracy: 0.4380 - val_loss: 1.8687\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3198 - loss: 2.1756 - val_accuracy: 0.4260 - val_loss: 1.8493\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3215 - loss: 2.1804 - val_accuracy: 0.4070 - val_loss: 1.8723\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3295 - loss: 2.1706 - val_accuracy: 0.4440 - val_loss: 1.8105\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3382 - loss: 2.1465 - val_accuracy: 0.4480 - val_loss: 1.7869\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3312 - loss: 2.1652 - val_accuracy: 0.4690 - val_loss: 1.7585\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3595 - loss: 2.1071 - val_accuracy: 0.4260 - val_loss: 1.8432\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3449 - loss: 2.1481 - val_accuracy: 0.4810 - val_loss: 1.7903\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3449 - loss: 2.1337 - val_accuracy: 0.4440 - val_loss: 1.8028\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3428 - loss: 2.1355 - val_accuracy: 0.4660 - val_loss: 1.7803\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3445 - loss: 2.1272 - val_accuracy: 0.4490 - val_loss: 1.7778\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3457 - loss: 2.1370 - val_accuracy: 0.4630 - val_loss: 1.7768\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3513 - loss: 2.1203 - val_accuracy: 0.4410 - val_loss: 1.8624\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3514 - loss: 2.1271 - val_accuracy: 0.4360 - val_loss: 1.7834\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3480 - loss: 2.1380 - val_accuracy: 0.4590 - val_loss: 1.7599\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3446 - loss: 2.1256 - val_accuracy: 0.4370 - val_loss: 1.7977\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3579 - loss: 2.1003 - val_accuracy: 0.4520 - val_loss: 1.7803\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3592 - loss: 2.1146 - val_accuracy: 0.4770 - val_loss: 1.7356\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3570 - loss: 2.1059 - val_accuracy: 0.4820 - val_loss: 1.7442\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3636 - loss: 2.1112 - val_accuracy: 0.4610 - val_loss: 1.7814\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3559 - loss: 2.1171 - val_accuracy: 0.4660 - val_loss: 1.7557\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3478 - loss: 2.1263 - val_accuracy: 0.4550 - val_loss: 1.7504\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3608 - loss: 2.1071 - val_accuracy: 0.4520 - val_loss: 1.7841\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3485 - loss: 2.1080 - val_accuracy: 0.4830 - val_loss: 1.7268\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3493 - loss: 2.1112 - val_accuracy: 0.4420 - val_loss: 1.7674\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3656 - loss: 2.1046 - val_accuracy: 0.4710 - val_loss: 1.7636\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3606 - loss: 2.0962 - val_accuracy: 0.4680 - val_loss: 1.7659\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3605 - loss: 2.1120 - val_accuracy: 0.4820 - val_loss: 1.7253\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3604 - loss: 2.1067 - val_accuracy: 0.4900 - val_loss: 1.7554\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3588 - loss: 2.0893 - val_accuracy: 0.4870 - val_loss: 1.7450\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3563 - loss: 2.1023 - val_accuracy: 0.4670 - val_loss: 1.7990\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3639 - loss: 2.0981 - val_accuracy: 0.4470 - val_loss: 1.7917\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3616 - loss: 2.1021 - val_accuracy: 0.4690 - val_loss: 1.7881\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3652 - loss: 2.1046 - val_accuracy: 0.4810 - val_loss: 1.7384\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3634 - loss: 2.0833 - val_accuracy: 0.4340 - val_loss: 1.8657\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3579 - loss: 2.1085 - val_accuracy: 0.4760 - val_loss: 1.7468\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3647 - loss: 2.1023 - val_accuracy: 0.4390 - val_loss: 1.7921\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3632 - loss: 2.0933 - val_accuracy: 0.4920 - val_loss: 1.7339\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3649 - loss: 2.1019 - val_accuracy: 0.4580 - val_loss: 1.7405\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3657 - loss: 2.0897 - val_accuracy: 0.4670 - val_loss: 1.7347\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3636 - loss: 2.0902 - val_accuracy: 0.4620 - val_loss: 1.7698\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3605 - loss: 2.0896 - val_accuracy: 0.4790 - val_loss: 1.7375\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3707 - loss: 2.1024 - val_accuracy: 0.4830 - val_loss: 1.7532\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3669 - loss: 2.0913 - val_accuracy: 0.4960 - val_loss: 1.7371\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3583 - loss: 2.1213 - val_accuracy: 0.4830 - val_loss: 1.7561\n",
      "Accuracy: 0.5035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_21\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_21\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_81               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_82               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_83               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_84               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_85               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_102 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_81               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_81 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_103 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_82               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_82 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_104 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_83               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_83 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_105 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_84               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_84 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_106 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_85               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_85 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_107 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.3094 - loss: 2.4743 - val_accuracy: 0.5000 - val_loss: 1.7378\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4396 - loss: 1.8542 - val_accuracy: 0.5090 - val_loss: 1.6173\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4577 - loss: 1.7918 - val_accuracy: 0.4980 - val_loss: 1.6341\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4643 - loss: 1.7528 - val_accuracy: 0.5290 - val_loss: 1.5102\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4749 - loss: 1.7245 - val_accuracy: 0.5100 - val_loss: 1.5633\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4735 - loss: 1.7341 - val_accuracy: 0.5320 - val_loss: 1.4940\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4810 - loss: 1.7010 - val_accuracy: 0.5360 - val_loss: 1.5221\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4818 - loss: 1.7065 - val_accuracy: 0.5270 - val_loss: 1.5406\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4841 - loss: 1.6945 - val_accuracy: 0.5640 - val_loss: 1.4697\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4874 - loss: 1.6935 - val_accuracy: 0.5380 - val_loss: 1.4830\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4996 - loss: 1.6612 - val_accuracy: 0.5490 - val_loss: 1.4892\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5002 - loss: 1.6584 - val_accuracy: 0.5140 - val_loss: 1.5760\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4869 - loss: 1.6813 - val_accuracy: 0.5560 - val_loss: 1.4445\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4954 - loss: 1.6587 - val_accuracy: 0.5520 - val_loss: 1.4527\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 1.6412 - val_accuracy: 0.5430 - val_loss: 1.5250\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4967 - loss: 1.6532 - val_accuracy: 0.5550 - val_loss: 1.4629\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4955 - loss: 1.6573 - val_accuracy: 0.5530 - val_loss: 1.4624\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5143 - loss: 1.6276 - val_accuracy: 0.5410 - val_loss: 1.4539\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5008 - loss: 1.6429 - val_accuracy: 0.5500 - val_loss: 1.4509\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5102 - loss: 1.6150 - val_accuracy: 0.5410 - val_loss: 1.5098\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5019 - loss: 1.6522 - val_accuracy: 0.5550 - val_loss: 1.5013\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5059 - loss: 1.6241 - val_accuracy: 0.5400 - val_loss: 1.4955\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5052 - loss: 1.6379 - val_accuracy: 0.5560 - val_loss: 1.4697\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.6220 - val_accuracy: 0.5690 - val_loss: 1.4291\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5035 - loss: 1.6254 - val_accuracy: 0.5770 - val_loss: 1.4204\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5039 - loss: 1.6255 - val_accuracy: 0.5420 - val_loss: 1.4771\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5094 - loss: 1.6374 - val_accuracy: 0.5610 - val_loss: 1.4178\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5082 - loss: 1.6341 - val_accuracy: 0.5460 - val_loss: 1.4675\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5008 - loss: 1.6406 - val_accuracy: 0.5700 - val_loss: 1.4429\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5141 - loss: 1.6196 - val_accuracy: 0.5580 - val_loss: 1.4600\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5074 - loss: 1.6266 - val_accuracy: 0.5640 - val_loss: 1.4354\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5049 - loss: 1.6412 - val_accuracy: 0.5720 - val_loss: 1.4253\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5218 - loss: 1.6034 - val_accuracy: 0.5580 - val_loss: 1.4428\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5162 - loss: 1.6180 - val_accuracy: 0.5750 - val_loss: 1.3943\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5145 - loss: 1.6018 - val_accuracy: 0.5500 - val_loss: 1.4594\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5137 - loss: 1.6102 - val_accuracy: 0.5920 - val_loss: 1.4110\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5201 - loss: 1.5989 - val_accuracy: 0.5660 - val_loss: 1.3982\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 1.6110 - val_accuracy: 0.5680 - val_loss: 1.4342\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5234 - loss: 1.5905 - val_accuracy: 0.5930 - val_loss: 1.3864\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5101 - loss: 1.6073 - val_accuracy: 0.5800 - val_loss: 1.3889\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5177 - loss: 1.5915 - val_accuracy: 0.5860 - val_loss: 1.4431\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5104 - loss: 1.6163 - val_accuracy: 0.5470 - val_loss: 1.5467\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5083 - loss: 1.6090 - val_accuracy: 0.5660 - val_loss: 1.4332\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5216 - loss: 1.6128 - val_accuracy: 0.5720 - val_loss: 1.4201\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5152 - loss: 1.6189 - val_accuracy: 0.5560 - val_loss: 1.4385\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5265 - loss: 1.5868 - val_accuracy: 0.5920 - val_loss: 1.3979\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5204 - loss: 1.5963 - val_accuracy: 0.5670 - val_loss: 1.4480\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5170 - loss: 1.6157 - val_accuracy: 0.5690 - val_loss: 1.4257\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5162 - loss: 1.6036 - val_accuracy: 0.5520 - val_loss: 1.4598\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5158 - loss: 1.6065 - val_accuracy: 0.5830 - val_loss: 1.3977\n",
      "Accuracy: 0.5790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_86               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_87               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_88               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_89               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_90               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_108 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_86               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_86 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_109 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_87               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_87 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_88               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_88 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_111 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_89               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_89 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_112 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_90               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_90 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_113 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2456 - loss: 2.6776 - val_accuracy: 0.4410 - val_loss: 1.8231\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3797 - loss: 2.0396 - val_accuracy: 0.4590 - val_loss: 1.7551\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3862 - loss: 1.9852 - val_accuracy: 0.4970 - val_loss: 1.6644\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4097 - loss: 1.9332 - val_accuracy: 0.4710 - val_loss: 1.7036\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4095 - loss: 1.9258 - val_accuracy: 0.4910 - val_loss: 1.6522\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4185 - loss: 1.9071 - val_accuracy: 0.5010 - val_loss: 1.6370\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4114 - loss: 1.9051 - val_accuracy: 0.4850 - val_loss: 1.6461\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4164 - loss: 1.8934 - val_accuracy: 0.5010 - val_loss: 1.6349\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4273 - loss: 1.8991 - val_accuracy: 0.4960 - val_loss: 1.6248\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4270 - loss: 1.8827 - val_accuracy: 0.5010 - val_loss: 1.6717\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4296 - loss: 1.8664 - val_accuracy: 0.5070 - val_loss: 1.5899\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4306 - loss: 1.8665 - val_accuracy: 0.4910 - val_loss: 1.6642\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4307 - loss: 1.8742 - val_accuracy: 0.5030 - val_loss: 1.5830\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4303 - loss: 1.8775 - val_accuracy: 0.5070 - val_loss: 1.6152\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4255 - loss: 1.8762 - val_accuracy: 0.5240 - val_loss: 1.5761\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4381 - loss: 1.8669 - val_accuracy: 0.4890 - val_loss: 1.6751\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4435 - loss: 1.8472 - val_accuracy: 0.5390 - val_loss: 1.5551\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4390 - loss: 1.8470 - val_accuracy: 0.5120 - val_loss: 1.5998\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4431 - loss: 1.8456 - val_accuracy: 0.5110 - val_loss: 1.6193\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4373 - loss: 1.8623 - val_accuracy: 0.5210 - val_loss: 1.5818\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4371 - loss: 1.8422 - val_accuracy: 0.4910 - val_loss: 1.6064\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4503 - loss: 1.8286 - val_accuracy: 0.5320 - val_loss: 1.5426\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4455 - loss: 1.8385 - val_accuracy: 0.5340 - val_loss: 1.5577\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4490 - loss: 1.8267 - val_accuracy: 0.5120 - val_loss: 1.5889\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4551 - loss: 1.8282 - val_accuracy: 0.5420 - val_loss: 1.5386\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4466 - loss: 1.8230 - val_accuracy: 0.5010 - val_loss: 1.6170\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4439 - loss: 1.8393 - val_accuracy: 0.5340 - val_loss: 1.5345\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4491 - loss: 1.8280 - val_accuracy: 0.5340 - val_loss: 1.5748\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4526 - loss: 1.8178 - val_accuracy: 0.5270 - val_loss: 1.5717\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4563 - loss: 1.8218 - val_accuracy: 0.5370 - val_loss: 1.5444\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4532 - loss: 1.8164 - val_accuracy: 0.5100 - val_loss: 1.6085\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4514 - loss: 1.8225 - val_accuracy: 0.5310 - val_loss: 1.5720\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4589 - loss: 1.7861 - val_accuracy: 0.5430 - val_loss: 1.5060\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4590 - loss: 1.7949 - val_accuracy: 0.5250 - val_loss: 1.5369\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4539 - loss: 1.8173 - val_accuracy: 0.5220 - val_loss: 1.5607\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4434 - loss: 1.8415 - val_accuracy: 0.5410 - val_loss: 1.5387\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4459 - loss: 1.8406 - val_accuracy: 0.5070 - val_loss: 1.6151\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4393 - loss: 1.8474 - val_accuracy: 0.5170 - val_loss: 1.5787\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4445 - loss: 1.8490 - val_accuracy: 0.5100 - val_loss: 1.6026\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4477 - loss: 1.8441 - val_accuracy: 0.5320 - val_loss: 1.5620\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4529 - loss: 1.8315 - val_accuracy: 0.5110 - val_loss: 1.5788\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4598 - loss: 1.8114 - val_accuracy: 0.5460 - val_loss: 1.5305\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4548 - loss: 1.8137 - val_accuracy: 0.5150 - val_loss: 1.5552\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4548 - loss: 1.8103 - val_accuracy: 0.5330 - val_loss: 1.5462\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4543 - loss: 1.8270 - val_accuracy: 0.5390 - val_loss: 1.5281\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4536 - loss: 1.8038 - val_accuracy: 0.5320 - val_loss: 1.5471\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4604 - loss: 1.8142 - val_accuracy: 0.5340 - val_loss: 1.5241\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4544 - loss: 1.8007 - val_accuracy: 0.5420 - val_loss: 1.5106\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4496 - loss: 1.8077 - val_accuracy: 0.5120 - val_loss: 1.6086\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4464 - loss: 1.8107 - val_accuracy: 0.5510 - val_loss: 1.5231\n",
      "Accuracy: 0.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_91               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_91 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_92               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_92 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_93               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_93 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_94               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_94 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_95               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_91               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_91 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_115 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_92               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_92 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_116 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_93               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_93 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_117 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_94               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_94 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_118 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_95               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_95 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_119 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.1923 - loss: 2.8364 - val_accuracy: 0.3300 - val_loss: 2.0708\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3158 - loss: 2.1831 - val_accuracy: 0.4280 - val_loss: 1.8199\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3247 - loss: 2.1383 - val_accuracy: 0.4090 - val_loss: 1.8908\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3481 - loss: 2.0785 - val_accuracy: 0.4230 - val_loss: 1.8233\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3412 - loss: 2.1026 - val_accuracy: 0.4440 - val_loss: 1.7394\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3468 - loss: 2.0898 - val_accuracy: 0.4490 - val_loss: 1.7702\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3534 - loss: 2.0660 - val_accuracy: 0.4340 - val_loss: 1.7457\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3596 - loss: 2.0447 - val_accuracy: 0.4070 - val_loss: 1.8521\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3660 - loss: 2.0439 - val_accuracy: 0.4280 - val_loss: 1.7859\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3607 - loss: 2.0435 - val_accuracy: 0.4970 - val_loss: 1.7171\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3711 - loss: 2.0511 - val_accuracy: 0.4680 - val_loss: 1.7345\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3721 - loss: 2.0146 - val_accuracy: 0.4890 - val_loss: 1.7290\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3719 - loss: 2.0227 - val_accuracy: 0.4680 - val_loss: 1.7273\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3704 - loss: 2.0365 - val_accuracy: 0.4610 - val_loss: 1.7155\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3737 - loss: 2.0228 - val_accuracy: 0.4450 - val_loss: 1.6990\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3743 - loss: 2.0182 - val_accuracy: 0.4710 - val_loss: 1.7001\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3763 - loss: 2.0064 - val_accuracy: 0.4880 - val_loss: 1.6834\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3911 - loss: 1.9914 - val_accuracy: 0.4760 - val_loss: 1.7011\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3871 - loss: 2.0133 - val_accuracy: 0.4760 - val_loss: 1.7117\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3813 - loss: 2.0089 - val_accuracy: 0.5100 - val_loss: 1.6713\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3811 - loss: 2.0156 - val_accuracy: 0.4990 - val_loss: 1.6443\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3889 - loss: 1.9863 - val_accuracy: 0.4930 - val_loss: 1.6732\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3861 - loss: 2.0129 - val_accuracy: 0.4900 - val_loss: 1.6847\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3870 - loss: 2.0152 - val_accuracy: 0.5020 - val_loss: 1.6579\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3859 - loss: 1.9961 - val_accuracy: 0.5000 - val_loss: 1.6603\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3760 - loss: 2.0070 - val_accuracy: 0.4950 - val_loss: 1.6331\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3929 - loss: 1.9767 - val_accuracy: 0.4940 - val_loss: 1.6625\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3936 - loss: 2.0074 - val_accuracy: 0.5030 - val_loss: 1.6837\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3938 - loss: 2.0106 - val_accuracy: 0.4720 - val_loss: 1.7028\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3880 - loss: 2.0039 - val_accuracy: 0.4830 - val_loss: 1.6686\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3913 - loss: 1.9759 - val_accuracy: 0.4930 - val_loss: 1.6712\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3878 - loss: 1.9857 - val_accuracy: 0.4860 - val_loss: 1.6777\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3942 - loss: 1.9759 - val_accuracy: 0.5020 - val_loss: 1.6348\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3893 - loss: 1.9848 - val_accuracy: 0.4770 - val_loss: 1.6690\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3896 - loss: 1.9950 - val_accuracy: 0.4510 - val_loss: 1.7804\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3905 - loss: 1.9812 - val_accuracy: 0.4960 - val_loss: 1.6694\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3986 - loss: 1.9663 - val_accuracy: 0.4900 - val_loss: 1.7026\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3887 - loss: 1.9915 - val_accuracy: 0.5100 - val_loss: 1.6312\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3891 - loss: 1.9826 - val_accuracy: 0.4920 - val_loss: 1.6858\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3935 - loss: 1.9930 - val_accuracy: 0.4930 - val_loss: 1.6730\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3932 - loss: 1.9857 - val_accuracy: 0.5310 - val_loss: 1.6105\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3986 - loss: 1.9836 - val_accuracy: 0.4940 - val_loss: 1.6595\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3927 - loss: 1.9852 - val_accuracy: 0.5100 - val_loss: 1.6198\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4012 - loss: 1.9783 - val_accuracy: 0.4930 - val_loss: 1.6393\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3957 - loss: 1.9816 - val_accuracy: 0.5190 - val_loss: 1.6342\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3955 - loss: 1.9681 - val_accuracy: 0.4720 - val_loss: 1.7627\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3932 - loss: 1.9797 - val_accuracy: 0.5090 - val_loss: 1.6208\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4008 - loss: 1.9839 - val_accuracy: 0.4810 - val_loss: 1.6820\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4054 - loss: 1.9799 - val_accuracy: 0.4930 - val_loss: 1.6646\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3898 - loss: 1.9920 - val_accuracy: 0.4750 - val_loss: 1.6658\n",
      "Accuracy: 0.4765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_24\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_24\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_96               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_97               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_98               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_99               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_100              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_120 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_96               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_96 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_121 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_97               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_97 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_98               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_98 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_99               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_99 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_100              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_100 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_125 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.2030 - loss: 2.9183 - val_accuracy: 0.2700 - val_loss: 2.6851\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2518 - loss: 2.6439 - val_accuracy: 0.2480 - val_loss: 3.0796\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2563 - loss: 2.6213 - val_accuracy: 0.3070 - val_loss: 2.4564\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2611 - loss: 2.6251 - val_accuracy: 0.3110 - val_loss: 2.5836\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2590 - loss: 2.6363 - val_accuracy: 0.3100 - val_loss: 2.3537\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2703 - loss: 2.5881 - val_accuracy: 0.3030 - val_loss: 2.4828\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2747 - loss: 2.5845 - val_accuracy: 0.2790 - val_loss: 2.6345\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2691 - loss: 2.5899 - val_accuracy: 0.3180 - val_loss: 2.3821\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2802 - loss: 2.5647 - val_accuracy: 0.2030 - val_loss: 2.7130\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2697 - loss: 2.6048 - val_accuracy: 0.3460 - val_loss: 2.3695\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2744 - loss: 2.5940 - val_accuracy: 0.3850 - val_loss: 2.2354\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2838 - loss: 2.5760 - val_accuracy: 0.3110 - val_loss: 2.4397\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2848 - loss: 2.5543 - val_accuracy: 0.3610 - val_loss: 2.3982\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2850 - loss: 2.5456 - val_accuracy: 0.3690 - val_loss: 2.3089\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2827 - loss: 2.5529 - val_accuracy: 0.3610 - val_loss: 2.2491\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2818 - loss: 2.5812 - val_accuracy: 0.3510 - val_loss: 2.3922\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2879 - loss: 2.5897 - val_accuracy: 0.2990 - val_loss: 2.4215\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2916 - loss: 2.5580 - val_accuracy: 0.3440 - val_loss: 2.3545\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2962 - loss: 2.5586 - val_accuracy: 0.3390 - val_loss: 2.3270\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2891 - loss: 2.5636 - val_accuracy: 0.3410 - val_loss: 2.4011\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2879 - loss: 2.6038 - val_accuracy: 0.3140 - val_loss: 2.4954\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2889 - loss: 2.5681 - val_accuracy: 0.3540 - val_loss: 2.3866\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2896 - loss: 2.5476 - val_accuracy: 0.2460 - val_loss: 2.7195\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3045 - loss: 2.5399 - val_accuracy: 0.3410 - val_loss: 2.3308\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3126 - loss: 2.5219 - val_accuracy: 0.3160 - val_loss: 2.3920\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2962 - loss: 2.5535 - val_accuracy: 0.3420 - val_loss: 2.4223\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3011 - loss: 2.5456 - val_accuracy: 0.3450 - val_loss: 2.4846\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3001 - loss: 2.5570 - val_accuracy: 0.3510 - val_loss: 2.3298\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3042 - loss: 2.5501 - val_accuracy: 0.3810 - val_loss: 2.2907\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3026 - loss: 2.5251 - val_accuracy: 0.3230 - val_loss: 2.4808\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3096 - loss: 2.5277 - val_accuracy: 0.3280 - val_loss: 2.4834\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2991 - loss: 2.5820 - val_accuracy: 0.3790 - val_loss: 2.2836\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3160 - loss: 2.5080 - val_accuracy: 0.3760 - val_loss: 2.2557\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3088 - loss: 2.5429 - val_accuracy: 0.3560 - val_loss: 2.2900\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3083 - loss: 2.5128 - val_accuracy: 0.3200 - val_loss: 2.4514\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3047 - loss: 2.5322 - val_accuracy: 0.3600 - val_loss: 2.3341\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3087 - loss: 2.5249 - val_accuracy: 0.3220 - val_loss: 2.3771\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3029 - loss: 2.5644 - val_accuracy: 0.4150 - val_loss: 2.1930\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3088 - loss: 2.5343 - val_accuracy: 0.3740 - val_loss: 2.3091\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3126 - loss: 2.5013 - val_accuracy: 0.3430 - val_loss: 2.3204\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.3020 - loss: 2.5624 - val_accuracy: 0.3600 - val_loss: 2.4088\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2992 - loss: 2.5575 - val_accuracy: 0.3480 - val_loss: 2.3813\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3112 - loss: 2.5178 - val_accuracy: 0.3400 - val_loss: 2.2587\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3037 - loss: 2.4964 - val_accuracy: 0.2030 - val_loss: 4.9167\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2536 - loss: 3.0536 - val_accuracy: 0.3480 - val_loss: 2.3119\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2799 - loss: 2.5655 - val_accuracy: 0.3360 - val_loss: 2.3020\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2914 - loss: 2.5600 - val_accuracy: 0.3120 - val_loss: 2.3728\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2915 - loss: 2.5668 - val_accuracy: 0.3480 - val_loss: 2.3326\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2882 - loss: 2.5421 - val_accuracy: 0.3400 - val_loss: 2.3009\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3034 - loss: 2.5152 - val_accuracy: 0.3590 - val_loss: 2.3918\n",
      "Accuracy: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_25\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_25\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_101              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_102              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_103              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_104              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_105              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_126 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_101              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_101 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_127 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_102              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_102 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_103              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_103 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_129 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_104              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_130 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_105              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_105 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_131 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1570 - loss: 3.0537 - val_accuracy: 0.2330 - val_loss: 3.0713\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1833 - loss: 2.8590 - val_accuracy: 0.2180 - val_loss: 2.6432\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.1960 - loss: 2.8106 - val_accuracy: 0.2550 - val_loss: 2.5600\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2064 - loss: 2.7980 - val_accuracy: 0.2380 - val_loss: 2.6965\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2119 - loss: 2.7844 - val_accuracy: 0.2610 - val_loss: 2.6448\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2156 - loss: 2.7946 - val_accuracy: 0.1800 - val_loss: 2.8366\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2113 - loss: 2.7849 - val_accuracy: 0.2600 - val_loss: 2.5250\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2223 - loss: 2.7857 - val_accuracy: 0.2760 - val_loss: 2.6236\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2143 - loss: 2.7751 - val_accuracy: 0.2500 - val_loss: 2.5852\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2153 - loss: 2.7846 - val_accuracy: 0.2410 - val_loss: 2.7535\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2164 - loss: 2.8093 - val_accuracy: 0.2800 - val_loss: 2.5779\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2240 - loss: 2.7748 - val_accuracy: 0.2450 - val_loss: 2.5965\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2249 - loss: 2.7762 - val_accuracy: 0.1660 - val_loss: 3.1267\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2168 - loss: 2.7983 - val_accuracy: 0.2950 - val_loss: 2.4817\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2282 - loss: 2.7737 - val_accuracy: 0.3080 - val_loss: 2.4264\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2229 - loss: 2.7824 - val_accuracy: 0.3020 - val_loss: 2.5755\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2354 - loss: 2.7638 - val_accuracy: 0.2910 - val_loss: 2.5163\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2297 - loss: 2.7655 - val_accuracy: 0.2980 - val_loss: 2.5310\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2275 - loss: 2.7679 - val_accuracy: 0.2760 - val_loss: 2.5928\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2439 - loss: 2.8091 - val_accuracy: 0.2680 - val_loss: 2.6327\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2259 - loss: 2.7721 - val_accuracy: 0.3300 - val_loss: 2.5752\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2286 - loss: 2.7638 - val_accuracy: 0.2610 - val_loss: 2.6692\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2370 - loss: 2.7441 - val_accuracy: 0.3000 - val_loss: 2.4661\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2358 - loss: 2.7630 - val_accuracy: 0.2460 - val_loss: 2.7314\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2322 - loss: 2.7954 - val_accuracy: 0.2090 - val_loss: 3.1587\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2424 - loss: 2.7704 - val_accuracy: 0.3180 - val_loss: 2.4919\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2466 - loss: 2.7352 - val_accuracy: 0.1870 - val_loss: 3.0536\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2445 - loss: 2.7693 - val_accuracy: 0.3300 - val_loss: 2.4954\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2321 - loss: 2.7620 - val_accuracy: 0.2870 - val_loss: 2.6344\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2507 - loss: 2.7263 - val_accuracy: 0.3070 - val_loss: 2.4443\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2378 - loss: 2.7606 - val_accuracy: 0.2800 - val_loss: 2.5969\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2285 - loss: 2.7744 - val_accuracy: 0.2420 - val_loss: 2.6201\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2321 - loss: 2.7621 - val_accuracy: 0.3220 - val_loss: 2.5079\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2496 - loss: 2.7433 - val_accuracy: 0.2390 - val_loss: 2.6413\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2479 - loss: 2.7607 - val_accuracy: 0.2850 - val_loss: 2.5022\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2462 - loss: 2.7460 - val_accuracy: 0.2930 - val_loss: 2.5975\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2456 - loss: 2.7661 - val_accuracy: 0.2880 - val_loss: 2.6529\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.2466 - loss: 2.7541 - val_accuracy: 0.3560 - val_loss: 2.3727\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2444 - loss: 2.7307 - val_accuracy: 0.3200 - val_loss: 2.3895\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2383 - loss: 2.7502 - val_accuracy: 0.3110 - val_loss: 2.3777\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2380 - loss: 2.7564 - val_accuracy: 0.3020 - val_loss: 2.5805\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2451 - loss: 2.7660 - val_accuracy: 0.2990 - val_loss: 2.6778\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2429 - loss: 2.7815 - val_accuracy: 0.2760 - val_loss: 2.5541\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2512 - loss: 2.7466 - val_accuracy: 0.3050 - val_loss: 2.7600\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2461 - loss: 2.7462 - val_accuracy: 0.3520 - val_loss: 2.5498\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2426 - loss: 2.7764 - val_accuracy: 0.3200 - val_loss: 2.4679\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2576 - loss: 2.7168 - val_accuracy: 0.2690 - val_loss: 2.5873\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.2511 - loss: 2.7409 - val_accuracy: 0.2170 - val_loss: 2.6775\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2482 - loss: 2.7366 - val_accuracy: 0.3000 - val_loss: 2.4586\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2504 - loss: 2.7608 - val_accuracy: 0.2800 - val_loss: 2.4422\n",
      "Accuracy: 0.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_26\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_26\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_106              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_107              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_108              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_108 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_109              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_110              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_132 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_106              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_133 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_107              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_134 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_108              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_108 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_135 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_109              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_109 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_136 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_110              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_110 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_137 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.1240 - loss: 3.1884 - val_accuracy: 0.1620 - val_loss: 2.9504\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1459 - loss: 2.9796 - val_accuracy: 0.1580 - val_loss: 2.9406\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1583 - loss: 2.9421 - val_accuracy: 0.1610 - val_loss: 2.9458\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1701 - loss: 2.9474 - val_accuracy: 0.2210 - val_loss: 2.7800\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1622 - loss: 2.9435 - val_accuracy: 0.1860 - val_loss: 2.6507\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1718 - loss: 2.9005 - val_accuracy: 0.2360 - val_loss: 2.8316\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1603 - loss: 2.9688 - val_accuracy: 0.2070 - val_loss: 2.6570\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1662 - loss: 2.9218 - val_accuracy: 0.2360 - val_loss: 2.8496\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1828 - loss: 2.9161 - val_accuracy: 0.2420 - val_loss: 2.6440\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1578 - loss: 2.9430 - val_accuracy: 0.2190 - val_loss: 2.7591\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1850 - loss: 2.9127 - val_accuracy: 0.1580 - val_loss: 3.1523\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1744 - loss: 2.9414 - val_accuracy: 0.2190 - val_loss: 2.7352\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1693 - loss: 2.9321 - val_accuracy: 0.2040 - val_loss: 2.7763\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1754 - loss: 2.8961 - val_accuracy: 0.2360 - val_loss: 2.8093\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1806 - loss: 2.9046 - val_accuracy: 0.1790 - val_loss: 2.8318\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1771 - loss: 2.9016 - val_accuracy: 0.1960 - val_loss: 2.6624\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1772 - loss: 2.9259 - val_accuracy: 0.1870 - val_loss: 2.6956\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1823 - loss: 2.8728 - val_accuracy: 0.2160 - val_loss: 2.7344\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1816 - loss: 2.8930 - val_accuracy: 0.2000 - val_loss: 2.7222\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1812 - loss: 2.8901 - val_accuracy: 0.1590 - val_loss: 2.8182\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 2.8854 - val_accuracy: 0.1790 - val_loss: 2.7502\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1877 - loss: 2.9186 - val_accuracy: 0.2590 - val_loss: 2.6049\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1848 - loss: 2.8884 - val_accuracy: 0.1790 - val_loss: 2.7586\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1833 - loss: 2.8865 - val_accuracy: 0.2100 - val_loss: 2.7569\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1834 - loss: 2.8866 - val_accuracy: 0.2290 - val_loss: 2.7080\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1852 - loss: 2.8902 - val_accuracy: 0.2080 - val_loss: 2.7786\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1843 - loss: 2.8926 - val_accuracy: 0.2470 - val_loss: 2.7874\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1929 - loss: 2.8965 - val_accuracy: 0.2210 - val_loss: 2.6287\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1814 - loss: 2.9015 - val_accuracy: 0.2410 - val_loss: 2.6714\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.1876 - loss: 2.8678 - val_accuracy: 0.2500 - val_loss: 2.6608\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1834 - loss: 2.8928 - val_accuracy: 0.1730 - val_loss: 2.8121\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1851 - loss: 2.8938 - val_accuracy: 0.2500 - val_loss: 2.6643\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1925 - loss: 2.8988 - val_accuracy: 0.1850 - val_loss: 2.7344\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1865 - loss: 2.8868 - val_accuracy: 0.2290 - val_loss: 2.7681\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1856 - loss: 2.9034 - val_accuracy: 0.2780 - val_loss: 2.6095\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.1946 - loss: 2.8714 - val_accuracy: 0.2340 - val_loss: 2.5943\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1907 - loss: 2.8846 - val_accuracy: 0.2360 - val_loss: 2.5711\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1879 - loss: 2.8905 - val_accuracy: 0.1870 - val_loss: 2.6698\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1836 - loss: 2.9101 - val_accuracy: 0.2740 - val_loss: 2.5841\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1908 - loss: 2.8830 - val_accuracy: 0.2220 - val_loss: 2.6095\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1866 - loss: 2.8893 - val_accuracy: 0.2490 - val_loss: 2.6282\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1925 - loss: 2.8883 - val_accuracy: 0.2030 - val_loss: 2.8606\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1802 - loss: 2.9154 - val_accuracy: 0.2290 - val_loss: 2.7916\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1913 - loss: 2.8806 - val_accuracy: 0.2230 - val_loss: 2.7096\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1879 - loss: 2.8952 - val_accuracy: 0.2370 - val_loss: 2.7714\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1840 - loss: 2.8852 - val_accuracy: 0.2120 - val_loss: 2.8639\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1936 - loss: 2.8791 - val_accuracy: 0.1950 - val_loss: 2.6539\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1930 - loss: 2.8846 - val_accuracy: 0.2330 - val_loss: 2.7570\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1868 - loss: 2.8914 - val_accuracy: 0.2110 - val_loss: 2.7564\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.1915 - loss: 2.8826 - val_accuracy: 0.2630 - val_loss: 2.5889\n",
      "Accuracy: 0.2530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_27\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_27\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_111              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_112              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_113              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_114              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_115              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_138 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_111              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_111 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_139 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_112              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_112 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_140 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_113              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_113 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_141 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_114              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_114 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_142 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_115              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_115 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_143 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2302 - loss: 2.7664 - val_accuracy: 0.3510 - val_loss: 2.8479\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2957 - loss: 2.4599 - val_accuracy: 0.3210 - val_loss: 2.6770\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3075 - loss: 2.4468 - val_accuracy: 0.3420 - val_loss: 2.3964\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3220 - loss: 2.3915 - val_accuracy: 0.3340 - val_loss: 2.4171\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3336 - loss: 2.3574 - val_accuracy: 0.3490 - val_loss: 2.3555\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3344 - loss: 2.3599 - val_accuracy: 0.3890 - val_loss: 2.2288\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3390 - loss: 2.3394 - val_accuracy: 0.3470 - val_loss: 2.4673\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3378 - loss: 2.3744 - val_accuracy: 0.3750 - val_loss: 2.3649\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3425 - loss: 2.3607 - val_accuracy: 0.3470 - val_loss: 2.3215\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3422 - loss: 2.3542 - val_accuracy: 0.3630 - val_loss: 2.3433\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3498 - loss: 2.3094 - val_accuracy: 0.3470 - val_loss: 2.1934\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 2.3675 - val_accuracy: 0.3980 - val_loss: 2.1586\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3533 - loss: 2.3222 - val_accuracy: 0.3380 - val_loss: 2.2812\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3571 - loss: 2.3072 - val_accuracy: 0.4030 - val_loss: 2.1962\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3538 - loss: 2.3131 - val_accuracy: 0.3850 - val_loss: 2.2756\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3622 - loss: 2.3002 - val_accuracy: 0.4110 - val_loss: 2.1164\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3618 - loss: 2.2929 - val_accuracy: 0.4160 - val_loss: 2.1845\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3620 - loss: 2.3163 - val_accuracy: 0.3770 - val_loss: 2.1955\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3690 - loss: 2.2982 - val_accuracy: 0.4380 - val_loss: 2.0555\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3620 - loss: 2.2954 - val_accuracy: 0.3880 - val_loss: 2.2467\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3604 - loss: 2.3128 - val_accuracy: 0.4460 - val_loss: 2.1156\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3752 - loss: 2.2702 - val_accuracy: 0.3390 - val_loss: 2.3660\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3652 - loss: 2.3096 - val_accuracy: 0.4080 - val_loss: 2.1688\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3675 - loss: 2.2926 - val_accuracy: 0.4050 - val_loss: 2.0701\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3737 - loss: 2.2506 - val_accuracy: 0.3560 - val_loss: 2.2885\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3679 - loss: 2.2991 - val_accuracy: 0.3680 - val_loss: 2.2519\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3667 - loss: 2.2928 - val_accuracy: 0.4370 - val_loss: 2.1143\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3596 - loss: 2.2965 - val_accuracy: 0.3890 - val_loss: 2.2290\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3742 - loss: 2.2998 - val_accuracy: 0.4170 - val_loss: 2.0911\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3709 - loss: 2.2903 - val_accuracy: 0.3600 - val_loss: 2.1725\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3676 - loss: 2.2878 - val_accuracy: 0.3080 - val_loss: 2.6122\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3798 - loss: 2.2670 - val_accuracy: 0.3540 - val_loss: 2.3831\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3697 - loss: 2.3140 - val_accuracy: 0.3680 - val_loss: 2.2788\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3664 - loss: 2.2858 - val_accuracy: 0.3980 - val_loss: 2.1663\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3698 - loss: 2.2636 - val_accuracy: 0.4680 - val_loss: 2.0312\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3761 - loss: 2.2705 - val_accuracy: 0.3980 - val_loss: 2.1627\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3787 - loss: 2.2559 - val_accuracy: 0.3920 - val_loss: 2.2693\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3792 - loss: 2.2676 - val_accuracy: 0.4150 - val_loss: 2.1272\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3703 - loss: 2.2904 - val_accuracy: 0.3770 - val_loss: 2.2312\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3757 - loss: 2.2707 - val_accuracy: 0.4220 - val_loss: 2.1716\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3841 - loss: 2.2496 - val_accuracy: 0.3540 - val_loss: 2.2061\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3745 - loss: 2.3014 - val_accuracy: 0.3640 - val_loss: 2.4481\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3859 - loss: 2.2607 - val_accuracy: 0.4260 - val_loss: 2.0817\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3680 - loss: 2.3017 - val_accuracy: 0.3700 - val_loss: 2.2178\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3859 - loss: 2.2731 - val_accuracy: 0.4260 - val_loss: 2.1190\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3807 - loss: 2.2782 - val_accuracy: 0.4360 - val_loss: 2.1410\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3833 - loss: 2.2482 - val_accuracy: 0.4110 - val_loss: 2.1867\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3754 - loss: 2.2779 - val_accuracy: 0.4270 - val_loss: 2.2209\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3862 - loss: 2.2469 - val_accuracy: 0.4170 - val_loss: 2.1086\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3882 - loss: 2.2385 - val_accuracy: 0.3960 - val_loss: 2.1624\n",
      "Accuracy: 0.4090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_116              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_117              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_118              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_118 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_119              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_119 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_120              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_120 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_144 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_116              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_116 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_145 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_117              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_117 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_146 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_118              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_118 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_147 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_119              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_119 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_148 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_120              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_120 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_149 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.1819 - loss: 2.9646 - val_accuracy: 0.2160 - val_loss: 2.9670\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2401 - loss: 2.6157 - val_accuracy: 0.2140 - val_loss: 2.7058\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2434 - loss: 2.6267 - val_accuracy: 0.2500 - val_loss: 2.6213\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2505 - loss: 2.6185 - val_accuracy: 0.3410 - val_loss: 2.4186\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2666 - loss: 2.5532 - val_accuracy: 0.3310 - val_loss: 2.4611\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2673 - loss: 2.5649 - val_accuracy: 0.3210 - val_loss: 2.3377\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2787 - loss: 2.5491 - val_accuracy: 0.3500 - val_loss: 2.3099\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2783 - loss: 2.5532 - val_accuracy: 0.3280 - val_loss: 2.3334\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2804 - loss: 2.5285 - val_accuracy: 0.3170 - val_loss: 2.4224\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2752 - loss: 2.5662 - val_accuracy: 0.3530 - val_loss: 2.3393\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2887 - loss: 2.5102 - val_accuracy: 0.3410 - val_loss: 2.3974\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2814 - loss: 2.5167 - val_accuracy: 0.3330 - val_loss: 2.4507\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2846 - loss: 2.5115 - val_accuracy: 0.3390 - val_loss: 2.3478\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2908 - loss: 2.5168 - val_accuracy: 0.3730 - val_loss: 2.3398\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2882 - loss: 2.5311 - val_accuracy: 0.2720 - val_loss: 2.7846\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2905 - loss: 2.5402 - val_accuracy: 0.3830 - val_loss: 2.2808\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2970 - loss: 2.5195 - val_accuracy: 0.2810 - val_loss: 2.4925\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2934 - loss: 2.5247 - val_accuracy: 0.3030 - val_loss: 2.3571\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2910 - loss: 2.5144 - val_accuracy: 0.3490 - val_loss: 2.4112\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2849 - loss: 2.5281 - val_accuracy: 0.3360 - val_loss: 2.3874\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2927 - loss: 2.5219 - val_accuracy: 0.3790 - val_loss: 2.1819\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3004 - loss: 2.4805 - val_accuracy: 0.3500 - val_loss: 2.3433\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2990 - loss: 2.5362 - val_accuracy: 0.2890 - val_loss: 2.5158\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3073 - loss: 2.4893 - val_accuracy: 0.3500 - val_loss: 2.2327\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3030 - loss: 2.4970 - val_accuracy: 0.3450 - val_loss: 2.3622\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2934 - loss: 2.5363 - val_accuracy: 0.3060 - val_loss: 2.3956\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2948 - loss: 2.5178 - val_accuracy: 0.3500 - val_loss: 2.3851\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2935 - loss: 2.5164 - val_accuracy: 0.2860 - val_loss: 2.6188\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3022 - loss: 2.5096 - val_accuracy: 0.3740 - val_loss: 2.3328\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3008 - loss: 2.5245 - val_accuracy: 0.3340 - val_loss: 2.3099\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3065 - loss: 2.5290 - val_accuracy: 0.4100 - val_loss: 2.1570\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2999 - loss: 2.5020 - val_accuracy: 0.3810 - val_loss: 2.2566\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3004 - loss: 2.5205 - val_accuracy: 0.3400 - val_loss: 2.4048\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2971 - loss: 2.5367 - val_accuracy: 0.3330 - val_loss: 2.3539\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2900 - loss: 2.5407 - val_accuracy: 0.3140 - val_loss: 2.5005\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3037 - loss: 2.5141 - val_accuracy: 0.3360 - val_loss: 2.3127\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2963 - loss: 2.4896 - val_accuracy: 0.3820 - val_loss: 2.2715\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3001 - loss: 2.4908 - val_accuracy: 0.3230 - val_loss: 2.4074\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2966 - loss: 2.5013 - val_accuracy: 0.3540 - val_loss: 2.3364\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3018 - loss: 2.5061 - val_accuracy: 0.3300 - val_loss: 2.3913\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3038 - loss: 2.5062 - val_accuracy: 0.3670 - val_loss: 2.2311\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3111 - loss: 2.4904 - val_accuracy: 0.3620 - val_loss: 2.2827\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3056 - loss: 2.5141 - val_accuracy: 0.3890 - val_loss: 2.2917\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3078 - loss: 2.5087 - val_accuracy: 0.3830 - val_loss: 2.2025\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3075 - loss: 2.4927 - val_accuracy: 0.3730 - val_loss: 2.2591\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3161 - loss: 2.4660 - val_accuracy: 0.3450 - val_loss: 2.3396\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3070 - loss: 2.5050 - val_accuracy: 0.3690 - val_loss: 2.3488\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3082 - loss: 2.5048 - val_accuracy: 0.4100 - val_loss: 2.2526\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3036 - loss: 2.5097 - val_accuracy: 0.3770 - val_loss: 2.3539\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3022 - loss: 2.5117 - val_accuracy: 0.3860 - val_loss: 2.3124\n",
      "Accuracy: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_29\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_29\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_121              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_122              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_123              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_124              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_125              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_125 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_150 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_121              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_121 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_151 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_122              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_122 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_152 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_123              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_123 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_153 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_124              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_124 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_154 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_125              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_125 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_155 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,980</span> (27.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,980\u001b[0m (27.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,628</span> (25.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,628\u001b[0m (25.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> (1.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m352\u001b[0m (1.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1458 - loss: 3.0668 - val_accuracy: 0.1870 - val_loss: 2.7679\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.1904 - loss: 2.7690 - val_accuracy: 0.2000 - val_loss: 2.6431\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2032 - loss: 2.7721 - val_accuracy: 0.2100 - val_loss: 2.7980\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1931 - loss: 2.7630 - val_accuracy: 0.2920 - val_loss: 2.6222\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2134 - loss: 2.7471 - val_accuracy: 0.2310 - val_loss: 2.5261\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2122 - loss: 2.7403 - val_accuracy: 0.2700 - val_loss: 2.4969\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2226 - loss: 2.6977 - val_accuracy: 0.3000 - val_loss: 2.3506\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2200 - loss: 2.7013 - val_accuracy: 0.2770 - val_loss: 2.4976\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2281 - loss: 2.7009 - val_accuracy: 0.2890 - val_loss: 2.5185\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2225 - loss: 2.7505 - val_accuracy: 0.2100 - val_loss: 2.5921\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2304 - loss: 2.6841 - val_accuracy: 0.2870 - val_loss: 2.5642\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2229 - loss: 2.7236 - val_accuracy: 0.2960 - val_loss: 2.4623\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2363 - loss: 2.6643 - val_accuracy: 0.2860 - val_loss: 2.4948\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2362 - loss: 2.7072 - val_accuracy: 0.2260 - val_loss: 2.5876\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2236 - loss: 2.7129 - val_accuracy: 0.2770 - val_loss: 2.5634\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2303 - loss: 2.6645 - val_accuracy: 0.2690 - val_loss: 2.6255\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2294 - loss: 2.6946 - val_accuracy: 0.2320 - val_loss: 2.6450\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2335 - loss: 2.6817 - val_accuracy: 0.2910 - val_loss: 2.3833\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2281 - loss: 2.7225 - val_accuracy: 0.2900 - val_loss: 2.5074\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2310 - loss: 2.6914 - val_accuracy: 0.2940 - val_loss: 2.4766\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2407 - loss: 2.6819 - val_accuracy: 0.2440 - val_loss: 2.4456\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2368 - loss: 2.6694 - val_accuracy: 0.2100 - val_loss: 2.4603\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2388 - loss: 2.6893 - val_accuracy: 0.3310 - val_loss: 2.3677\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2300 - loss: 2.6833 - val_accuracy: 0.2600 - val_loss: 2.6282\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2317 - loss: 2.7051 - val_accuracy: 0.2800 - val_loss: 2.4753\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2296 - loss: 2.7001 - val_accuracy: 0.3220 - val_loss: 2.4320\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2330 - loss: 2.6756 - val_accuracy: 0.2590 - val_loss: 2.5363\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2399 - loss: 2.6944 - val_accuracy: 0.2650 - val_loss: 2.5416\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2306 - loss: 2.6834 - val_accuracy: 0.2450 - val_loss: 2.4926\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2392 - loss: 2.6781 - val_accuracy: 0.2710 - val_loss: 2.5196\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2438 - loss: 2.6707 - val_accuracy: 0.3120 - val_loss: 2.5309\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2466 - loss: 2.6869 - val_accuracy: 0.3150 - val_loss: 2.4244\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2394 - loss: 2.6556 - val_accuracy: 0.2910 - val_loss: 2.4420\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2421 - loss: 2.6819 - val_accuracy: 0.2910 - val_loss: 2.4573\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2355 - loss: 2.6741 - val_accuracy: 0.3510 - val_loss: 2.3192\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2384 - loss: 2.6706 - val_accuracy: 0.2700 - val_loss: 2.5695\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2409 - loss: 2.6931 - val_accuracy: 0.3340 - val_loss: 2.4139\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2527 - loss: 2.6535 - val_accuracy: 0.3150 - val_loss: 2.4267\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2417 - loss: 2.6815 - val_accuracy: 0.2880 - val_loss: 2.5729\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2549 - loss: 2.6503 - val_accuracy: 0.2380 - val_loss: 2.5912\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2392 - loss: 2.6919 - val_accuracy: 0.2620 - val_loss: 2.5023\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2345 - loss: 2.6772 - val_accuracy: 0.2630 - val_loss: 2.4882\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2548 - loss: 2.6647 - val_accuracy: 0.2810 - val_loss: 2.4213\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2481 - loss: 2.6721 - val_accuracy: 0.2750 - val_loss: 2.4581\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2418 - loss: 2.6819 - val_accuracy: 0.2980 - val_loss: 2.4543\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2462 - loss: 2.6797 - val_accuracy: 0.2750 - val_loss: 2.4565\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2411 - loss: 2.6812 - val_accuracy: 0.3060 - val_loss: 2.4075\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2469 - loss: 2.6560 - val_accuracy: 0.2900 - val_loss: 2.4483\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2384 - loss: 2.6823 - val_accuracy: 0.3060 - val_loss: 2.4029\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2526 - loss: 2.6440 - val_accuracy: 0.3000 - val_loss: 2.4628\n",
      "Accuracy: 0.2825\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'learning_rate': 0.001, 'batch_size': 64, 'dropout': 0.1}\n",
      "Best Accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "batch_sizes = [32, 64]\n",
    "dropout = [0.1, 0.2, 0.3]\n",
    "best_accuracy = 0\n",
    "input_shape = X_train.shape[1:]\n",
    "best_history = None\n",
    "best_model = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        for d in dropout:\n",
    "            model = Six_Layer_NN()\n",
    "            config = {\n",
    "                        'input_shape': input_shape,\n",
    "                        'epochs': 50,\n",
    "                        'dropout': d,\n",
    "                        'batch_size': batch,\n",
    "                        'lr': lr\n",
    "                    }\n",
    "            model.build_model(config)\n",
    "            history = model.train(X_train, y_train, X_valid, y_valid, config)\n",
    "            loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_model = model\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'learning_rate': lr, 'batch_size': batch, 'dropout': d}\n",
    "                best_history = history\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "FmQTh1tOJgGf",
    "outputId": "e9fbd10e-76e7-492f-dec4-64fc164bd504"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGJCAYAAABcsOOZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrwklEQVR4nO3dd3wUZeLH8c+mbXrvEHrvSBORpijFQ6LYOBRQ0FPBE8ud8lMROE9s56l4h3oqHCqiKKBnAREBBaUX6QKG0BJKIJXU3fn9McnCEkr6pnzfr9e8dnf2mdlnh0C+PG0shmEYiIiIiFQxN1dXQEREROomhRARERFxCYUQERERcQmFEBEREXEJhRARERFxCYUQERERcQmFEBEREXEJhRARERFxCYUQERERcQmFEJEKNmbMGBo1alSmY6dMmYLFYqnYClUzBw4cwGKxMHv27Cr/bIvFwpQpUxyvZ8+ejcVi4cCBA5c9tlGjRowZM6ZC61OenxWR2kAhROoMi8VSom3FihWurmqd9+c//xmLxcK+ffsuWuapp57CYrHw66+/VmHNSu/o0aNMmTKFLVu2uLoqDkVB8JVXXnF1VaSO83B1BUSqygcffOD0es6cOSxdurTY/tatW5frc/7zn/9gt9vLdOzTTz/Nk08+Wa7Prw1GjhzJjBkzmDt3LpMnT75gmY8//pj27dvToUOHMn/OXXfdxR133IHVai3zOS7n6NGjTJ06lUaNGtGpUyen98rzsyJSGyiESJ1x5513Or1es2YNS5cuLbb/fGfOnMHX17fEn+Pp6Vmm+gF4eHjg4aG/lj169KBZs2Z8/PHHFwwhv/zyCwkJCbzwwgvl+hx3d3fc3d3LdY7yKM/PikhtoO4YkXP069ePdu3asXHjRvr06YOvry//93//B8AXX3zBDTfcQGxsLFarlaZNm/K3v/0Nm83mdI7z+/nPbfp+5513aNq0KVarlW7durF+/XqnYy80JsRisTBhwgQWLVpEu3btsFqttG3blsWLFxer/4oVK+jatSve3t40bdqUt99+u8TjTH766SduvfVWGjRogNVqJS4ujkceeYTs7Oxi38/f358jR44QHx+Pv78/ERERPP7448WuRWpqKmPGjCEoKIjg4GBGjx5NamrqZesCZmvI7t272bRpU7H35s6di8ViYcSIEeTl5TF58mS6dOlCUFAQfn5+9O7dm+XLl1/2My40JsQwDJ577jnq16+Pr68v/fv3Z8eOHcWOPXXqFI8//jjt27fH39+fwMBABg8ezNatWx1lVqxYQbdu3QC4++67HV1+ReNhLjQmJCsri8cee4y4uDisVistW7bklVde4fwbnpfm56Ksjh8/ztixY4mKisLb25uOHTvy3//+t1i5efPm0aVLFwICAggMDKR9+/a8/vrrjvfz8/OZOnUqzZs3x9vbm7CwMK6++mqWLl1aYXWVmkn/5RI5T0pKCoMHD+aOO+7gzjvvJCoqCjB/Yfn7+/Poo4/i7+/PDz/8wOTJk0lPT+fll1++7Hnnzp1LRkYGf/rTn7BYLLz00kvcfPPN/P7775f9H/GqVatYsGABDz74IAEBAbzxxhsMHz6cgwcPEhYWBsDmzZsZNGgQMTExTJ06FZvNxrRp04iIiCjR954/fz5nzpzhgQceICwsjHXr1jFjxgwOHz7M/PnzncrabDYGDhxIjx49eOWVV/j+++/5xz/+QdOmTXnggQcA85f5sGHDWLVqFffffz+tW7dm4cKFjB49ukT1GTlyJFOnTmXu3LlcccUVTp/96aef0rt3bxo0aMDJkyd59913GTFiBPfeey8ZGRm89957DBw4kHXr1hXrArmcyZMn89xzzzFkyBCGDBnCpk2buP7668nLy3Mq9/vvv7No0SJuvfVWGjduzLFjx3j77bfp27cvO3fuJDY2ltatWzNt2jQmT57MfffdR+/evQG46qqrLvjZhmFw4403snz5csaOHUunTp1YsmQJf/nLXzhy5Aj//Oc/ncqX5OeirLKzs+nXrx/79u1jwoQJNG7cmPnz5zNmzBhSU1N5+OGHAVi6dCkjRozg2muv5cUXXwRg165drF692lFmypQpTJ8+nXHjxtG9e3fS09PZsGEDmzZt4rrrritXPaWGM0TqqPHjxxvn/xXo27evARhvvfVWsfJnzpwptu9Pf/qT4evra+Tk5Dj2jR492mjYsKHjdUJCggEYYWFhxqlTpxz7v/jiCwMw/ve//zn2Pfvss8XqBBheXl7Gvn37HPu2bt1qAMaMGTMc+4YOHWr4+voaR44ccezbu3ev4eHhUeycF3Kh7zd9+nTDYrEYiYmJTt8PMKZNm+ZUtnPnzkaXLl0crxctWmQAxksvveTYV1BQYPTu3dsAjFmzZl22Tt26dTPq169v2Gw2x77FixcbgPH22287zpmbm+t03OnTp42oqCjjnnvucdoPGM8++6zj9axZswzASEhIMAzDMI4fP254eXkZN9xwg2G32x3l/u///s8AjNGjRzv25eTkONXLMMw/a6vV6nRt1q9ff9Hve/7PStE1e+6555zK3XLLLYbFYnH6GSjpz8WFFP1Mvvzyyxct89prrxmA8eGHHzr25eXlGT179jT8/f2N9PR0wzAM4+GHHzYCAwONgoKCi56rY8eOxg033HDJOkndpO4YkfNYrVbuvvvuYvt9fHwczzMyMjh58iS9e/fmzJkz7N69+7Lnvf322wkJCXG8Lvpf8e+//37ZYwcMGEDTpk0drzt06EBgYKDjWJvNxvfff098fDyxsbGOcs2aNWPw4MGXPT84f7+srCxOnjzJVVddhWEYbN68uVj5+++/3+l17969nb7LN998g4eHh6NlBMwxGA899FCJ6gPmOJ7Dhw/z448/OvbNnTsXLy8vbr31Vsc5vby8ALDb7Zw6dYqCggK6du16wa6cS/n+++/Jy8vjoYcecurCmjhxYrGyVqsVNzfzn1CbzUZKSgr+/v60bNmy1J9b5JtvvsHd3Z0///nPTvsfe+wxDMPg22+/ddp/uZ+L8vjmm2+Ijo5mxIgRjn2enp78+c9/JjMzk5UrVwIQHBxMVlbWJbtWgoOD2bFjB3v37i13vaR2UQgROU+9evUcv9TOtWPHDm666SaCgoIIDAwkIiLCMag1LS3tsudt0KCB0+uiQHL69OlSH1t0fNGxx48fJzs7m2bNmhUrd6F9F3Lw4EHGjBlDaGioY5xH3759geLfz9vbu1g3z7n1AUhMTCQmJgZ/f3+nci1btixRfQDuuOMO3N3dmTt3LgA5OTksXLiQwYMHOwW6//73v3To0MEx3iAiIoKvv/66RH8u50pMTASgefPmTvsjIiKcPg/MwPPPf/6T5s2bY7VaCQ8PJyIigl9//bXUn3vu58fGxhIQEOC0v2jGVlH9ilzu56I8EhMTad68uSNoXawuDz74IC1atGDw4MHUr1+fe+65p9i4lGnTppGamkqLFi1o3749f/nLX6r91GqpGgohIuc5t0WgSGpqKn379mXr1q1MmzaN//3vfyxdutTRB16SaZYXm4VhnDfgsKKPLQmbzcZ1113H119/zRNPPMGiRYtYunSpYwDl+d+vqmaUREZGct111/H555+Tn5/P//73PzIyMhg5cqSjzIcffsiYMWNo2rQp7733HosXL2bp0qVcc801lTr99fnnn+fRRx+lT58+fPjhhyxZsoSlS5fStm3bKpt2W9k/FyURGRnJli1b+PLLLx3jWQYPHuw09qdPnz7s37+f999/n3bt2vHuu+9yxRVX8O6771ZZPaV60sBUkRJYsWIFKSkpLFiwgD59+jj2JyQkuLBWZ0VGRuLt7X3Bxb0uteBXkW3btvHbb7/x3//+l1GjRjn2l2f2QsOGDVm2bBmZmZlOrSF79uwp1XlGjhzJ4sWL+fbbb5k7dy6BgYEMHTrU8f5nn31GkyZNWLBggVMXyrPPPlumOgPs3buXJk2aOPafOHGiWOvCZ599Rv/+/Xnvvfec9qemphIeHu54XZoVcBs2bMj3339PRkaGU2tIUXdfUf2qQsOGDfn111+x2+1OrSEXqouXlxdDhw5l6NCh2O12HnzwQd5++22eeeYZR0tcaGgod999N3fffTeZmZn06dOHKVOmMG7cuCr7TlL9qCVEpASK/sd57v8w8/Ly+Pe//+2qKjlxd3dnwIABLFq0iKNHjzr279u3r9g4gosdD87fzzAMp2mWpTVkyBAKCgqYOXOmY5/NZmPGjBmlOk98fDy+vr78+9//5ttvv+Xmm2/G29v7knVfu3Ytv/zyS6nrPGDAADw9PZkxY4bT+V577bViZd3d3Yu1OMyfP58jR4447fPz8wMo0dTkIUOGYLPZePPNN532//Of/8RisZR4fE9FGDJkCMnJyXzyySeOfQUFBcyYMQN/f39HV11KSorTcW5ubo4F5HJzcy9Yxt/fn2bNmjnel7pLLSEiJXDVVVcREhLC6NGjHUuKf/DBB1Xa7H05U6ZM4bvvvqNXr1488MADjl9m7dq1u+yS4a1ataJp06Y8/vjjHDlyhMDAQD7//PNyjS0YOnQovXr14sknn+TAgQO0adOGBQsWlHq8hL+/P/Hx8Y5xIed2xQD84Q9/YMGCBdx0003ccMMNJCQk8NZbb9GmTRsyMzNL9VlF651Mnz6dP/zhDwwZMoTNmzfz7bffOrVuFH3utGnTuPvuu7nqqqvYtm0bH330kVMLCkDTpk0JDg7mrbfeIiAgAD8/P3r06EHjxo2Lff7QoUPp378/Tz31FAcOHKBjx4589913fPHFF0ycONFpEGpFWLZsGTk5OcX2x8fHc9999/H2228zZswYNm7cSKNGjfjss89YvXo1r732mqOlZty4cZw6dYprrrmG+vXrk5iYyIwZM+jUqZNj/EibNm3o168fXbp0ITQ0lA0bNvDZZ58xYcKECv0+UgO5ZlKOiOtdbIpu27ZtL1h+9erVxpVXXmn4+PgYsbGxxl//+ldjyZIlBmAsX77cUe5iU3QvNB2S86aMXmyK7vjx44sd27BhQ6cpo4ZhGMuWLTM6d+5seHl5GU2bNjXeffdd47HHHjO8vb0vchXO2rlzpzFgwADD39/fCA8PN+69917HlM9zp5eOHj3a8PPzK3b8heqekpJi3HXXXUZgYKARFBRk3HXXXcbmzZtLPEW3yNdff20ARkxMTLFpsXa73Xj++eeNhg0bGlar1ejcubPx1VdfFftzMIzLT9E1DMOw2WzG1KlTjZiYGMPHx8fo16+fsX379mLXOycnx3jssccc5Xr16mX88ssvRt++fY2+ffs6fe4XX3xhtGnTxjFduui7X6iOGRkZxiOPPGLExsYanp6eRvPmzY2XX37Zacpw0Xcp6c/F+Yp+Ji+2ffDBB4ZhGMaxY8eMu+++2wgPDze8vLyM9u3bF/tz++yzz4zrr7/eiIyMNLy8vIwGDRoYf/rTn4ykpCRHmeeee87o3r27ERwcbPj4+BitWrUy/v73vxt5eXmXrKfUfhbDqEb/lRORChcfH6/pkSJSLWlMiEgtcv4S63v37uWbb76hX79+rqmQiMglqCVEpBaJiYlhzJgxNGnShMTERGbOnElubi6bN28utvaFiIiraWCqSC0yaNAgPv74Y5KTk7FarfTs2ZPnn39eAUREqiW1hIiIiIhLaEyIiIiIuIRCiIiIiLiExoRcgN1u5+jRowQEBJRqyWUREZG6zjAMMjIyiI2NLXYDxPMphFzA0aNHiYuLc3U1REREaqxDhw5Rv379S5ZRCLmAouWIDx06RGBgoItrIyIiUnOkp6cTFxfndBPGi1EIuYCiLpjAwECFEBERkTIoyXAGDUwVERERl1AIEREREZdQCBERERGX0JgQEZFaymazkZ+f7+pqSC3j7u6Oh4dHhSxhoRAiIlILZWZmcvjwYXRnDqkMvr6+xMTE4OXlVa7zKISIiNQyNpuNw4cP4+vrS0REhBZdlApjGAZ5eXmcOHGChIQEmjdvftkFyS5FIUREpJbJz8/HMAwiIiLw8fFxdXWklvHx8cHT05PExETy8vLw9vYu87k0MFVEpJZSC4hUlvK0fjidp0LOIiIiIlJKCiFVZPW+kyzafISMHI1UFxERAYWQKvPwvC1M/GQLiSlnXF0VEZE6o1GjRrz22mslLr9ixQosFgupqamVVic5SyGkioT7m9OYTmXlubgmIiLVj8ViueQ2ZcqUMp13/fr13HfffSUuf9VVV5GUlERQUFCZPq+kFHZMmh1TRUL9FEJERC4mKSnJ8fyTTz5h8uTJ7Nmzx7HP39/f8dwwDGw2Gx4el/8VFhERUap6eHl5ER0dXapjpOzUElJFikJIikKIiFQxwzA4k1fgkq2ki6VFR0c7tqCgICwWi+P17t27CQgI4Ntvv6VLly5YrVZWrVrF/v37GTZsGFFRUfj7+9OtWze+//57p/Oe3x1jsVh49913uemmm/D19aV58+Z8+eWXjvfPb6GYPXs2wcHBLFmyhNatW+Pv78+gQYOcQlNBQQF//vOfCQ4OJiwsjCeeeILRo0cTHx9f5j+z06dPM2rUKEJCQvD19WXw4MHs3bvX8X5iYiJDhw4lJCQEPz8/2rZtyzfffOM4duTIkY4p2s2bN2fWrFllrktlUktIFQlztITkurgmIlLXZOfbaDN5iUs+e+e0gfh6VcyvmieffJJXXnmFJk2aEBISwqFDhxgyZAh///vfsVqtzJkzh6FDh7Jnzx4aNGhw0fNMnTqVl156iZdffpkZM2YwcuRIEhMTCQ0NvWD5M2fO8Morr/DBBx/g5ubGnXfeyeOPP85HH30EwIsvvshHH33ErFmzaN26Na+//jqLFi2if//+Zf6uY8aMYe/evXz55ZcEBgbyxBNPMGTIEHbu3Imnpyfjx48nLy+PH3/8ET8/P3bu3OloLXrmmWfYuXMn3377LeHh4ezbt4/s7Owy16UyKYRUkVA/KwApmWoJEREpi2nTpnHdddc5XoeGhtKxY0fH67/97W8sXLiQL7/8kgkTJlz0PGPGjGHEiBEAPP/887zxxhusW7eOQYMGXbB8fn4+b731Fk2bNgVgwoQJTJs2zfH+jBkzmDRpEjfddBMAb775pqNVoiyKwsfq1au56qqrAPjoo4+Ii4tj0aJF3HrrrRw8eJDhw4fTvn17AJo0aeI4/uDBg3Tu3JmuXbsCZmtQdaUQUkVC/dUdIyKu4ePpzs5pA1322RWl6JdqkczMTKZMmcLXX39NUlISBQUFZGdnc/DgwUuep0OHDo7nfn5+BAYGcvz48YuW9/X1dQQQgJiYGEf5tLQ0jh07Rvfu3R3vu7u706VLF+x2e6m+X5Fdu3bh4eFBjx49HPvCwsJo2bIlu3btAuDPf/4zDzzwAN999x0DBgxg+PDhju/1wAMPMHz4cDZt2sT1119PfHy8I8xUNxoTUkXCNDBVRFzEYrHg6+Xhkq0iV2318/Nzev3444+zcOFCnn/+eX766Se2bNlC+/btycu79L+znp6exa7PpQLDhcq7+saA48aN4/fff+euu+5i27ZtdO3alRkzZgAwePBgEhMTeeSRRzh69CjXXnstjz/+uEvrezEKIVVEs2NERCrW6tWrGTNmDDfddBPt27cnOjqaAwcOVGkdgoKCiIqKYv369Y59NpuNTZs2lfmcrVu3pqCggLVr1zr2paSksGfPHtq0aePYFxcXx/3338+CBQt47LHH+M9//uN4LyIigtGjR/Phhx/y2muv8c4775S5PpVJ3TFVpKglJCVTA1NFRCpC8+bNWbBgAUOHDsVisfDMM8+UuQukPB566CGmT59Os2bNaNWqFTNmzOD06dMlagXatm0bAQEBjtcWi4WOHTsybNgw7r33Xt5++20CAgJ48sknqVevHsOGDQNg4sSJDB48mBYtWnD69GmWL19O69atAZg8eTJdunShbdu25Obm8tVXXzneq24UQqpImL85MDU9p4B8mx1PdzVCiYiUx6uvvso999zDVVddRXh4OE888QTp6elVXo8nnniC5ORkRo0ahbu7O/fddx8DBw7E3f3y42H69Onj9Nrd3Z2CggJmzZrFww8/zB/+8Afy8vLo06cP33zzjaNryGazMX78eA4fPkxgYCCDBg3in//8J2CudTJp0iQOHDiAj48PvXv3Zt68eRX/xSuAxXB1x1Y1lJ6eTlBQEGlpaQQGBlbIOe12g2ZPfYPdgHX/dy2RgWW/9bGIyKXk5OSQkJBA48aNy3WbdSkbu91O69atue222/jb3/7m6upUikv9jJXmd6haQqqIm5uFEF8vUrLySMnKUwgREaklEhMT+e677+jbty+5ubm8+eabJCQk8Mc//tHVVav21CdQhTQ4VUSk9nFzc2P27Nl069aNXr16sW3bNr7//vtqOw6jOlFLSBUqCiEnNThVRKTWiIuLY/Xq1a6uRo3k0paQ6dOn061bNwICAoiMjCQ+Pt7phkUX0q9fvwveYfGGG25wlBkzZkyx9y+2El5VCtOddEVERBxc2hKycuVKxo8fT7du3SgoKOD//u//uP7669m5c2exRWmKLFiwwGkhmpSUFDp27Mitt97qVG7QoEFON+yxWq2V8yVKQd0xIiIiZ7k0hCxevNjp9ezZs4mMjGTjxo3Fpi0VOf8GQ/PmzcPX17dYCLFardXudsyO+8cohIiIiFSvgalpaWlA8aBxKe+99x533HFHsZaTFStWEBkZScuWLXnggQdISUm56Dlyc3NJT0932ipDeFF3jG5iJyIiUn1CiN1uZ+LEifTq1Yt27dqV6Jh169axfft2xo0b57R/0KBBzJkzh2XLlvHiiy+ycuVKBg8ejM1mu+B5pk+fTlBQkGOLi4sr9/e5EHXHiIiInFVtZseMHz+e7du3s2rVqhIf895779G+fXunuxcC3HHHHY7n7du3p0OHDjRt2pQVK1Zw7bXXFjvPpEmTePTRRx2v09PTKyWIFIWQlCzNjhEREakWLSETJkzgq6++Yvny5dSvX79Ex2RlZTFv3jzGjh172bJNmjQhPDycffv2XfB9q9VKYGCg01YZwgrHhKglRESkcvTr14+JEyc6Xjdq1IjXXnvtksdYLBYWLVpU7s+uqPPUJS4NIYZhMGHCBBYuXMgPP/xA48aNS3zs/Pnzyc3N5c4777xs2cOHD5OSkkJMTEx5qltuRS0hqdn5FNiq/iZLIiLV1dChQy+6lMJPP/2ExWLh119/LfV5169fz3333Vfe6jmZMmUKnTp1KrY/KSmJwYMHV+hnnW/27NkEBwdX6mdUJZeGkPHjx/Phhx8yd+5cAgICSE5OJjk5mezsbEeZUaNGMWnSpGLHvvfee8THxxMWFua0PzMzk7/85S+sWbOGAwcOsGzZMoYNG0azZs0YOHBgpX+nSwnxNW88ZBhw+ky+S+siIlKdjB07lqVLl3L48OFi782aNYuuXbvSoUOHUp83IiICX1/fiqjiZUVHR1eL5SBqEpeGkJkzZ5KWlka/fv2IiYlxbJ988omjzMGDB0lKSnI6bs+ePaxateqCXTHu7u78+uuv3HjjjbRo0YKxY8fSpUsXfvrpJ5f/cHi4uxFcGETUJSMiVcYwIC/LNVsJ75H6hz/8gYiICGbPnu20PzMzk/nz5zN27FhSUlIYMWIE9erVw9fXl/bt2/Pxxx9f8rznd8fs3buXPn364O3tTZs2bVi6dGmxY5544glatGiBr68vTZo04ZlnniE/3/yP4+zZs5k6dSpbt251LIZZVOfzu2O2bdvGNddcg4+PD2FhYdx3331kZmY63h8zZgzx8fG88sorxMTEEBYWxvjx4x2fVRYHDx5k2LBh+Pv7ExgYyG233caxY8cc72/dupX+/fsTEBBAYGAgXbp0YcOGDYB5D5yhQ4cSEhKCn58fbdu25ZtvvilzXUrCpQNTS3ID3xUrVhTb17Jly4se6+Pjw5IlS8pbtUoT6udF6pn8wsGpAa6ujojUBfln4PlY13z2/x0FrwsvPnkuDw8PRo0axezZs3nqqaewWCyA2fVus9kYMWIEmZmZdOnShSeeeILAwEC+/vpr7rrrLpo2bVpsgsKF2O12br75ZqKioli7di1paWlO40eKBAQEMHv2bGJjY9m2bRv33nsvAQEB/PWvf+X2229n+/btLF68mO+//x6AoKCgYufIyspi4MCB9OzZk/Xr13P8+HHGjRvHhAkTnILW8uXLiYmJYfny5ezbt4/bb7+dTp06ce+99172+1zo+xUFkJUrV1JQUMD48eO5/fbbHb9LR44cSefOnZk5cybu7u5s2bIFT0/zP8fjx48nLy+PH3/8ET8/P3bu3Im/v3+p61Ea1WZ2TF0R5ufF7yey1BIiInKee+65h5dffpmVK1fSr18/wOyKGT58uGMJhccff9xR/qGHHmLJkiV8+umnJQoh33//Pbt372bJkiXExpqh7Pnnny82juPpp592PG/UqBGPP/448+bN469//Ss+Pj74+/vj4eFxyQUx586dS05ODnPmzHGsY/Xmm28ydOhQXnzxRaKiogAICQnhzTffxN3dnVatWnHDDTewbNmyMoWQZcuWsW3bNhISEhwzPOfMmUPbtm1Zv3493bp14+DBg/zlL3+hVatWADRv3txx/MGDBxk+fDjt27cHzEkdlU0hpIpphoyIVDlPX7NFwlWfXUKtWrXiqquu4v3336dfv37s27ePn376iWnTpgFgs9l4/vnn+fTTTzly5Ah5eXnk5uaWeMzHrl27iIuLcwQQgJ49exYr98knn/DGG2+wf/9+MjMzKSgoKPWsyV27dtGxY0enhTR79eqF3W5nz549jhDStm1b3N3dHWViYmLYtm1bqT7r3M+Mi4tzWmKiTZs2BAcHs2vXLrp168ajjz7KuHHj+OCDDxgwYAC33norTZs2BeDPf/4zDzzwAN999x0DBgxg+PDhZRqHUxrVYopuXRJauGpqilZNFZGqYrGYXSKu2Aq7VUpq7NixfP7552RkZDBr1iyaNm1K3759AXj55Zd5/fXXeeKJJ1i+fDlbtmxh4MCBTvcTK69ffvmFkSNHMmTIEL766is2b97MU089VaGfca6irpAiFosFu73yZk9OmTKFHTt2cMMNN/DDDz/Qpk0bFi5cCMC4ceP4/fffueuuu9i2bRtdu3ZlxowZlVYXUAipcmFaNVVE5KJuu+023NzcmDt3LnPmzOGee+5xjA9ZvXo1w4YN484776Rjx440adKE3377rcTnbt26NYcOHXKa7LBmzRqnMj///DMNGzbkqaeeomvXrjRv3pzExESnMl5eXhddgfvcz9q6dStZWVmOfatXr8bNzY2WLVuWuM6lUfT9Dh065Ni3c+dOUlNTadOmjWNfixYteOSRR/juu++4+eabnW72GhcXx/3338+CBQt47LHH+M9//lMpdS2iEFLFtHS7iMjF+fv7c/vttzNp0iSSkpIYM2aM473mzZuzdOlSfv75Z3bt2sWf/vQnp5kflzNgwABatGjB6NGj2bp1Kz/99BNPPfWUU5nmzZtz8OBB5s2bx/79+3njjTccLQVFGjVqREJCAlu2bOHkyZPk5hZfBXvkyJF4e3szevRotm/fzvLly3nooYe46667HF0xZWWz2diyZYvTtmvXLgYMGED79u0ZOXIkmzZtYt26dYwaNYq+ffvStWtXsrOzmTBhAitWrCAxMZHVq1ezfv16WrduDcDEiRNZsmQJCQkJbNq0ieXLlzveqywKIVVMS7eLiFza2LFjOX36NAMHDnQav/H0009zxRVXMHDgQPr160d0dDTx8fElPq+bmxsLFy4kOzub7t27M27cOP7+9787lbnxxht55JFHmDBhAp06deLnn3/mmWeecSozfPhwBg0aRP/+/YmIiLjgNGFfX1+WLFnCqVOn6NatG7fccgvXXnstb775ZukuxgVkZmbSuXNnp23o0KFYLBa++OILQkJC6NOnDwMGDKBJkyaOZS/c3d1JSUlh1KhRtGjRgttuu43BgwczdepUwAw348ePp3Xr1gwaNIgWLVrw73//u9z1vRSLUZJ5snVMeno6QUFBpKWlVfgS7qv2nuTO99bSIsqf7x7pW6HnFhEByMnJISEhgcaNG+Pt7e3q6kgtdKmfsdL8DlVLSBVztIRoYKqIiNRxCiFVLKxwdszpM3nY7WqEEhGRukshpIqF+JohxG6YN7ITERGpqxRCqpiXhxuB3uYacac0OFVEROowhRAXCPM3V03VuBARqUyadyCVpaJ+thRCXEBrhYhIZSpaBryyVvkUOXPmDFB8xdfS0r1jXODsWiH6B0JEKp6Hhwe+vr6cOHECT09P3Nz0/02pGIZhcObMGY4fP05wcLDTfW/KQiHEBbR0u4hUJovFQkxMDAkJCcWWHBepCMHBwZe8i3BJKYS4gLpjRKSyeXl50bx5c3XJSIXz9PQsdwtIEYUQFygKISczNTtGRCqPm5ubVkyVak0dhS5QtGCZWkJERKQuUwhxgVA/c4quQoiIiNRlCiEuEKbZMSIiIgohruC4f0xWnhYTEhGROkshxAWKBqYW2A3SswtcXBsRERHXUAhxAauHO/5Wc2JSiu4fIyIidZRCiItorRAREanrFEJcREu3i4hIXacQ4iKOGTK6k66IiNRRCiEucrY7RmNCRESkblIIcZFQf3XHiIhI3aYQ4iLhWjVVRETqOIUQF9HsGBERqesUQlzE0R2jgakiIlJHuTSETJ8+nW7duhEQEEBkZCTx8fHs2bPnksfMnj0bi8XitJ1/q2rDMJg8eTIxMTH4+PgwYMAA9u7dW5lfpdTC1BIiIiJ1nEtDyMqVKxk/fjxr1qxh6dKl5Ofnc/3115OVlXXJ4wIDA0lKSnJsiYmJTu+/9NJLvPHGG7z11lusXbsWPz8/Bg4cSE5OTmV+nVI5tztG948REZG6yMOVH7548WKn17NnzyYyMpKNGzfSp0+fix5nsViIjo6+4HuGYfDaa6/x9NNPM2zYMADmzJlDVFQUixYt4o477qi4L1AOYYUDU/NsdjJzCwjw9nRxjURERKpWtRoTkpaWBkBoaOgly2VmZtKwYUPi4uIYNmwYO3bscLyXkJBAcnIyAwYMcOwLCgqiR48e/PLLLxc8X25uLunp6U5bZfPxcsfH0x3QuBAREambqk0IsdvtTJw4kV69etGuXbuLlmvZsiXvv/8+X3zxBR9++CF2u52rrrqKw4cPA5CcnAxAVFSU03FRUVGO9843ffp0goKCHFtcXFwFfatL09LtIiJSl1WbEDJ+/Hi2b9/OvHnzLlmuZ8+ejBo1ik6dOtG3b18WLFhAREQEb7/9dpk/e9KkSaSlpTm2Q4cOlflcpRHmr8GpIiJSd7l0TEiRCRMm8NVXX/Hjjz9Sv379Uh3r6elJ586d2bdvH4BjrMixY8eIiYlxlDt27BidOnW64DmsVitWq7VslS+HMC3dLiIidZhLW0IMw2DChAksXLiQH374gcaNG5f6HDabjW3btjkCR+PGjYmOjmbZsmWOMunp6axdu5aePXtWWN0rQmjh4FR1x4iISF3k0paQ8ePHM3fuXL744gsCAgIcYzaCgoLw8fEBYNSoUdSrV4/p06cDMG3aNK688kqaNWtGamoqL7/8MomJiYwbNw4wZ85MnDiR5557jubNm9O4cWOeeeYZYmNjiY+Pd8n3vBhHd4wGpoqISB3k0hAyc+ZMAPr16+e0f9asWYwZMwaAgwcP4uZ2tsHm9OnT3HvvvSQnJxMSEkKXLl34+eefadOmjaPMX//6V7KysrjvvvtITU3l6quvZvHixcUWNXM1Ld0uIiJ1mcXQSlnFpKenExQURFpaGoGBgZX2OZ9uOMRfP/uVvi0i+O893Svtc0RERKpKaX6HVpvZMXWRlm4XEZG6TCHEhRzrhGRqdoyIiNQ9CiEuFHbO7Bj1iomISF2jEOJCoYWzY3IL7JzJs7m4NiIiIlVLIcSF/LzcsXqYfwQaFyIiInWNQogLWSwWx+BULVgmIiJ1jUKIi4X6a+l2ERGpmxRCXMyxdLtWTRURkTpGIcTFtFaIiIjUVQohLqal20VEpK5SCHGxohByUt0xIiJSxyiEuNjZ7hgNTBURkbpFIcTF1B0jIiJ1lUKIi4X5n126XUREpC5RCHExzY4REZG6SiHExYoWKzuTZyMnX/ePERGRukMhxMUCrB54ulsAdcmIiEjdohDiYhaL5ezgVE3TFRGROkQhpBpwLN2uaboiIlKHKIRUAxqcKiIidZFCSDVQ1B2jm9iJiEhdohBSDThCiFpCRESkDlEIqQbC/bV0u4iI1D0KIdVA0cBUjQkREZG6RCGkGlB3jIiI1EUKIdVAmL9mx4iISN2jEFINaLEyERGpixRCqoGidUIycgvILdD9Y0REpG5QCKkGAr09cXcz7x9zOivfxbURERGpGgoh1YCbm4UQX7M15GSmpumKiEjdoBBSTYRrcKqIiNQxCiHVRKjuHyMiInWMS0PI9OnT6datGwEBAURGRhIfH8+ePXsuecx//vMfevfuTUhICCEhIQwYMIB169Y5lRkzZgwWi8VpGzRoUGV+lXLTWiEiIlLXuDSErFy5kvHjx7NmzRqWLl1Kfn4+119/PVlZWRc9ZsWKFYwYMYLly5fzyy+/EBcXx/XXX8+RI0ecyg0aNIikpCTH9vHHH1f21ymXs3fS1ZgQERGpGzxc+eGLFy92ej179mwiIyPZuHEjffr0ueAxH330kdPrd999l88//5xly5YxatQox36r1Up0dHTFV7qSaOl2ERGpa6rVmJC0tDQAQkNDS3zMmTNnyM/PL3bMihUriIyMpGXLljzwwAOkpKRc9By5ubmkp6c7bVUttHBgaooWLBMRkTqi2oQQu93OxIkT6dWrF+3atSvxcU888QSxsbEMGDDAsW/QoEHMmTOHZcuW8eKLL7Jy5UoGDx6MzXbhhcCmT59OUFCQY4uLiyv39ymtMA1MFRGROsal3THnGj9+PNu3b2fVqlUlPuaFF15g3rx5rFixAm9vb8f+O+64w/G8ffv2dOjQgaZNm7JixQquvfbaYueZNGkSjz76qON1enp6lQeRqECzO+bgqTMYhoHFYqnSzxcREalq1aIlZMKECXz11VcsX76c+vXrl+iYV155hRdeeIHvvvuODh06XLJskyZNCA8PZ9++fRd832q1EhgY6LRVtTYxQXi6Wziekcvh09lV/vkiIiJVzaUhxDAMJkyYwMKFC/nhhx9o3LhxiY576aWX+Nvf/sbixYvp2rXrZcsfPnyYlJQUYmJiylvlsjEMOLAaNn8EeRee+ePj5U67ekEArD9wqiprJyIi4hIuDSHjx4/nww8/ZO7cuQQEBJCcnExycjLZ2WdbAkaNGsWkSZMcr1988UWeeeYZ3n//fRo1auQ4JjMzE4DMzEz+8pe/sGbNGg4cOMCyZcsYNmwYzZo1Y+DAgVX+HQGwWOCTO+GLB+HU7xct1q2RObh2/YHTVVUzERERl3FpCJk5cyZpaWn069ePmJgYx/bJJ584yhw8eJCkpCSnY/Ly8rjlllucjnnllVcAcHd359dff+XGG2+kRYsWjB07li5duvDTTz9htVqr/Ds6hBa28pxKuGiRrg1DALWEiIhI3eDSgamGYVy2zIoVK5xeHzhw4JLlfXx8WLJkSTlqVUlCGsGRjXD6wEWLdCkMIfuOZ3IqK8+xiqqIiEhtVC0GptYJIY3Mx0uEkDB/K00j/ADYmKguGRERqd0UQqpKSGF3zCVCCJwdF7JBXTIiIlLLKYRUFUdLyMXHhMC5g1MVQkREpHZTCKkqRSEk9SDYL7xyK5wNIduOpJGTf/FyIiIiNZ1CSFUJjAV3L7AXQPqRixaLC/UhMsBKvs1g66HUqqufiIhIFVMIqSpu7hDcwHx+iWm6Fovl7LgQDU4VEZFaTCGkKpVghgxA10ZaL0RERGo/hZCqVMoZMhsTT2OzX34tFRERkZpIIaQqlXCGTKvoAPy83MnIKWBPckbl10tERMQFFEKqUgm7Yzzc3biicPXUDYnqkhERkdpJIaQqlTCEAHRtqJvZiYhI7aYQUpWKQkj2achOvWTRbkWDUxNOlegeOyIiIjWNQkhVsvqDX4T5/DKtIZ0aBOPuZiE5PYcjqdmVXzcREZEqphBS1UrYJePr5UG72EAANqhLRkREaiGFkKpWwmm6oPvIiIhI7aYQUtVKOE0XoKvjjrpqCRERkdpHIaSqlWaGTOHg1D3HMkg7k195dRIREXEBhZCqFlry7phwfytNwv0ArRciIiK1T5lCyKFDhzh8+LDj9bp165g4cSLvvPNOhVWs1ipqCUk9BLbLt26cvY+MumRERKR2KVMI+eMf/8jy5csBSE5O5rrrrmPdunU89dRTTJs2rUIrWOv4R4O7FQwbpB2+bPGz40LUEiIiIrVLmULI9u3b6d69OwCffvop7dq14+eff+ajjz5i9uzZFVm/2sfNrVTjQopmyPx6OI2cfFvl1UtERKSKlSmE5OfnY7VaAfj++++58cYbAWjVqhVJSUkVV7vaqhQzZBqF+RLu70Wezc62I2mVWy8REZEqVKYQ0rZtW9566y1++uknli5dyqBBgwA4evQoYWFhFVrBWqkULSEWi+Wc+8ioS0ZERGqPMoWQF198kbfffpt+/foxYsQIOnbsCMCXX37p6KaRSyjFDBk4OzhV64WIiEht4lGWg/r168fJkydJT08nJCTEsf++++7D19e3wipXa5WiJQTOjgvZcOAUdruBm5ulcuolIiJShcrUEpKdnU1ubq4jgCQmJvLaa6+xZ88eIiMjK7SCtVJRCDl1AEpwh9y2sYH4ermTnlPA3uOZlVo1ERGRqlKmEDJs2DDmzJkDQGpqKj169OAf//gH8fHxzJw5s0IrWCsFNzQfc9Mg+/JdLB7ubnRuEAxoXIiIiNQeZQohmzZtonfv3gB89tlnREVFkZiYyJw5c3jjjTcqtIK1kpevuV4IlHxciAaniohILVOmEHLmzBkCAgIA+O6777j55ptxc3PjyiuvJDExsUIrWGuVYpounDsuRINTRUSkdihTCGnWrBmLFi3i0KFDLFmyhOuvvx6A48ePExgYWKEVrLVKOTi1U4Ng3N0sHEnN5khqdqVVS0REpKqUKYRMnjyZxx9/nEaNGtG9e3d69uwJmK0inTt3rtAK1lqlnKbrb/WgTYwZ8NYnqEtGRERqvjKFkFtuuYWDBw+yYcMGlixZ4th/7bXX8s9//rPE55k+fTrdunUjICCAyMhI4uPj2bNnz2WPmz9/Pq1atcLb25v27dvzzTffOL1vGAaTJ08mJiYGHx8fBgwYwN69e0v+BauCY4ZMybpjAHo1Cwdg4eYjlVAhERGRqlWmEAIQHR1N586dOXr0qOOOut27d6dVq1YlPsfKlSsZP348a9asYenSpeTn53P99deTlZV10WN+/vlnRowYwdixY9m8eTPx8fHEx8ezfft2R5mXXnqJN954g7feeou1a9fi5+fHwIEDycnJKevXrXiO7piSj6EZ0T0OiwVW/naChJMXv0YiIiI1gcUwSrBQxXnsdjvPPfcc//jHP8jMNNetCAgI4LHHHuOpp57Cza1s2ebEiRNERkaycuVK+vTpc8Eyt99+O1lZWXz11VeOfVdeeSWdOnXirbfewjAMYmNjeeyxx3j88ccBSEtLIyoqitmzZ3PHHXdcth7p6ekEBQWRlpZWeWNcMo7BP1qAxQ2eOgYeXiU6bMysdazYc4KxVzfmmT+0qZy6iYiIlFFpfoeWKS089dRTvPnmm7zwwgts3ryZzZs38/zzzzNjxgyeeeaZMlUazLAAEBoaetEyv/zyCwMGDHDaN3DgQH755RcAEhISSE5OdioTFBREjx49HGXOl5ubS3p6utNW6fwjwcMHDDukHSrxYaN6mmuMzN9wiOw83VVXRERqrjKFkP/+97+8++67PPDAA3To0IEOHTrw4IMP8p///IfZs2eXqSJ2u52JEyfSq1cv2rVrd9FyycnJREVFOe2LiooiOTnZ8X7RvouVOd/06dMJCgpybHFxcWX6DqVisZR6mi5A3xaRNAj1JT2ngC+2aGyIiIjUXGUKIadOnbrg2I9WrVpx6lTZZm6MHz+e7du3M2/evDIdXx6TJk0iLS3NsR06VPKWiXIp5QwZAHc3C3de2QCAOb8kUobeNBERkWqhTCGkY8eOvPnmm8X2v/nmm3To0KHU55swYQJfffUVy5cvp379+pcsGx0dzbFjx5z2HTt2jOjoaMf7RfsuVuZ8VquVwMBAp61KlHKtkCK3dY3D6uHGzqR0NiZq8TIREamZyhRCXnrpJd5//33atGnD2LFjGTt2LG3atGH27Nm88sorJT6PYRhMmDCBhQsX8sMPP9C4cePLHtOzZ0+WLVvmtG/p0qWOtUoaN25MdHS0U5n09HTWrl3rKFNtlGGaLkCwrxc3dowFzNYQERGRmqhMIaRv37789ttv3HTTTaSmppKamsrNN9/Mjh07+OCDD0p8nvHjx/Phhx8yd+5cAgICSE5OJjk5mezssyuCjho1ikmTJjleP/zwwyxevJh//OMf7N69mylTprBhwwYmTJgAgMViYeLEiTz33HN8+eWXbNu2jVGjRhEbG0t8fHxZvm7lCSnqjil9kBh9VSMAvt2exImM3AqslIiISNUo0xTdi9m6dStXXHEFNlvJZm1YLJYL7p81axZjxowBoF+/fjRq1MhpwOv8+fN5+umnOXDgAM2bN+ell15iyJAhjvcNw+DZZ5/lnXfeITU1lauvvpp///vftGjRokT1qpIpugAnfoN/dQOvAJh0yBysWgo3/Xs1mw+m8th1LXjo2uaVVEkREZGSK83vUJeGkOqqykJIfg78vXAWz1/2g194qQ5fuPkwj3yylehAb1Y90R8P9zKvPSciIlIhKn2dEKkgnt4QYI7tKO3gVIAh7WMI8/MiOT2HpTuPXf4AERGRakQhxNXKME23iNXDnTu6m2uaaICqiIjUNB6lKXzzzTdf8v3U1NTy1KVuCmkEiatLPUOmyB97NGTmiv388nsKe49l0DwqoGLrJyIiUklK1RJy7qqiF9oaNmzIqFGjKquutVMZ1wopUi/YhwGtzXElH6xRa4iIiNQcpWoJmTVrVmXVo+4KKXt3TJFRPRvx3c5jfL7xMH8Z2JIAb8+KqZuIiEgl0pgQVytnSwhAr2ZhNInwIyvPxsLNup+MiIjUDAohrlYUQtKPQEHZFh2zWCyMutK8u67uJyMiIjWFQoir+YWDlz9gQOrBMp/m5i718fVyZ9/xTH75PaXi6iciIlJJFEJczWKpkC6ZQG9PbupcD4APNF1XRERqAIWQ6qCMN7I736ie5nm+23mMfcczy1cnERGRSqYQUh1UQEsIQMvoAAa0jsRmN/jbVzs1NkRERKo1hZDqoIJCCMBTN7TB093Cyt9OsHzP8XKfT0REpLIohFQHjrVCytcdA9A43I97rjbP97evdpFXYC/3OUVERCqDQkh1cO79YyqgC2VC/2aE+1tJOJnFrNXlDzYiIiKVQSGkOgiKAyyQfwayTpT7dAHenjwxqCUAM37Yx/GMnHKfU0REpKIphFQHHl4QVN98Xs4ZMkWGX1GfjvWDyMwt4OXFeyrknCIiIhVJIaS6qMDBqQBubhaevbEtAPM3HmbrodQKOa+IiEhFUQipLio4hABc0SCEmwsXMJv6vx2asisiItWKQkh1UQkhBOCJwa3w9XJn08FUvthytELPLSIiUh4KIdWFY9XU3yv0tFGB3ozv3wyA6d/uIiu3oELPLyIiUlYKIdVFdHvz8egmyE6t0FOPvboxDUJ9OZaey8wV+yv03CIiImWlEFJdRLSEiFZgy4M931Toqb093XnqhtYAvPPT7xxMOVOh5xcRESkLhZDqpO3N5uP2BRV+6uvbRHF1s3DyCuz8/ZudFX5+ERGR0lIIqU7aFYaQ35fDmVMVemqLxcLkoW1wd7OwZMcxVu09WaHnFxERKS2FkOokvLk5NsReALv+V+GnbxEVwF1XNgTgwY82svb3lAr/DBERkZJSCKluHF0yn1fK6R+7vgVdGoaQnlPAXe+t46tfNW1XRERcQyGkuml7k/l44CfIPF7hpw/w9uSjcT0Y1DaaPJudCXM38+5Pv2shMxERqXIKIdVNaGOIvQIMO+z8olI+wtvTnX+NvIIxVzUC4LmvdzHtq53Y7AoiIiJSdRRCqqOiAao7FlbaR7i7WXh2aBueGmJO3Z21+gAT5m4iJ99WaZ8pIiJyLoWQ6qioSybxZ0ivvDEbFouFe/s04Y0RnfFyd+Pb7cnc+e5aTmflVdpnioiIFFEIqY6C6kPclYABOxZV+sfd2DGWOWO7E+jtwYbE0wx/62cOndKCZiIiUrkUQqorR5dMxS9cdiFXNgnjsweuIjbIm99PZHHTv39mXULFrlUiIiJyLpeGkB9//JGhQ4cSGxuLxWJh0aJFlyw/ZswYLBZLsa1t27aOMlOmTCn2fqtWrSr5m1SCNsMACxxeD6kHq+QjW0QFsHB8L1rHBHIyM5cR/1nDzBX7sWvAqoiIVAKXhpCsrCw6duzIv/71rxKVf/3110lKSnJshw4dIjQ0lFtvvdWpXNu2bZ3KrVq1qjKqX7kCoqHR1ebzShyger6oQG8+u78n8Z1isdkNXly8m3FzNmiciIiIVDgPV3744MGDGTx4cInLBwUFERQU5Hi9aNEiTp8+zd133+1UzsPDg+jo6Aqrp8u0vclcL2T7Auj1cJV9rJ/Vg3/e3okeTcJ49ssd/LD7OH+YsYoZf+zMFQ1CqqweIiJSu9XoMSHvvfceAwYMoGHDhk779+7dS2xsLE2aNGHkyJEcPHjp7ozc3FzS09OdtmqhzTCwuEPSFkjZX6UfbbFYGNG9AQsfvIpGYb4cSc3mtrd+4b1VCVrYTEREKkSNDSFHjx7l22+/Zdy4cU77e/TowezZs1m8eDEzZ84kISGB3r17k5GRcdFzTZ8+3dHKEhQURFxcXGVXv2T8wqFJX/N5FQ1QPV/b2CD+99DV3NA+hgK7wd++2sn9H24kLTvfJfUREZHao8aGkP/+978EBwcTHx/vtH/w4MHceuutdOjQgYEDB/LNN9+QmprKp59+etFzTZo0ibS0NMd26NChSq59KTjuJVN140LOF+DtyZt/7My0YW3xdDfvwvuHGT+x7XCay+okIiI1X40MIYZh8P7773PXXXfh5eV1ybLBwcG0aNGCffv2XbSM1WolMDDQaas2Wv8B3Dzh+A44scdl1bBYLIzq2YjPH7iK+iE+HDqVzfCZPzNrtbpnRESkbGpkCFm5ciX79u1j7Nixly2bmZnJ/v37iYmJqYKaVQKfEGh6jfl8u2u6ZM7VoX4wXz/Um+vbRJFnszP1fzu574ONpJ7R7BkRESkdl4aQzMxMtmzZwpYtWwBISEhgy5YtjoGkkyZNYtSoUcWOe++99+jRowft2rUr9t7jjz/OypUrOXDgAD///DM33XQT7u7ujBgxolK/S6U6d+GyatDqEOTrydt3dWHK0DZ4ubuxdOcxhrz+ExsTtbiZiIiUnEtDyIYNG+jcuTOdO3cG4NFHH6Vz585MnjwZgKSkpGIzW9LS0vj8888v2gpy+PBhRowYQcuWLbntttsICwtjzZo1REREVO6XqUwth4C7FU7+Bse2u7o2gNk9M6ZXYxYUzp45mpbDbW+v4V/L92lxMxERKRGLoQ79YtLT0wkKCiItLa36jA+ZNxJ2fwVXPwoDnnV1bZxk5hbw1MJtfLHFvNle7+bhvHpbJyICrC6umYiIVLXS/A6tkWNC6qRq1iVzLn+rB6/d3omXhnfA29ONn/aeZMgbP7F630lXV01ERKoxhZCaosUg8PSF0wfg6GZX16YYi8XCbd3i+HLC1bSI8udERi53vreW6d/sIiff5urqiYhINaQQUlN4+UHLwiXuf/hbtWsNKdIiKoAvxl/NiO5xGAa8/ePv3PDGT2w+eNrVVRMRkWpGIaQm6TcJPLxh/w+wcZara3NRPl7uTL+5A/8Z1ZWIACv7T2QxfObPvPDtbrWKiIiIg0JITRLeHK41Zw6x5Gmza6Yau65NFEsf6UN8p1jsBry1cj9DZ6xi66FUV1dNRESqAYWQmqbHA9DgKsjPgkXjwW53dY0uKdjXi9fu6Mzbd3Uh3N/K3uOZ3DzzZ15avJvcArWKiIjUZQohNY2bG8T/yxykmrgK1r3j6hqVyMC20Sx9pA83dozFZjf49wqzVWRj4mkt+y4iUkdpnZALqJbrhJxv3X/gm8fBwwfuXwXhzVxdoxJbvD2Jpxdt52SmudR7qJ8XVzQIpnODELo0DKFD/SB8vTxcXEsRESmL0vwOVQi5gBoRQux2+CAeElZC/e5wz2Jwc3d1rUrsVFYef/tqJ1//mkSezblLyd3NQuuYAK5oEMIVDULoGBdMw1Bf3NwsLqqtiIiUlEJIOdWIEAKQegj+3RPyMuC6adDrYVfXqNRyC2zsOJrOpsTTbDp4mk2JqSSn5xQr52/1oE1MIG3rBdIuNoi29QJpFuGPh7t6FEVEqhOFkHKqMSEEYNMc+PIh894yf/oRIlu5ukbldjQ12xFINh08za6kdHILig/AtXq40So6gHb1ghjQJoqrm4XjqVAiIuJSCiHlVKNCiGHA3Ntg73cQ2xnGfg/utWs8RYHNzv4TWWw/ksaOo+lsP5rGzqPpZOYWOJUL8fVkULsYhnaMoUfjMNzVfSMiUuUUQsqpRoUQgPQk+PeVkJMK/Z+Gvn9xdY0qnd1ucPDUGbYfTWPt76f4dnuSY6ArQESAlRvaxzC0YyxXNAjGYlEgERGpCgoh5VTjQgjAr5/CgnvBzRPuWw7R7V1doypVYLOz5vdT/G/rURbvSCYtO9/xXr1gHwa2jaZHk1C6NQol1M/LhTUVEandFELKqUaGEMOAT+6E3V9BVDsYtww8vV1dK5fIK7Czat8J/rc1ie92JJOV57woWvNIf7o1DqV7o1C6Nw4lNtjHRTUVEal9FELKqUaGEIDME/DvHnAmBbqNgxv+4eoauVxOvo0Ve47z096TrD9wit+OZRYrUy/Yh+6NQ7m6WTh9W0YQ7m91QU1FRGoHhZByqrEhBGDv9/DRcPP5Le9Du+GurU81cyorjw0HTrEu4RTrD5xi+9F0bPazfwUsFuhQL4h+LSPp3yqSDvWCtD6JiEgpKISUU40OIQDLpsFP/wCvAPjTSghr6uoaVVtZuQVsOniaNb+nsGLPCXYcTXd6P8zPi74tI+jfMpKrmoYR6uelQa4iIpegEFJONT6E2ApgzjDz3jJR7WHcUvDUuIeSOJaew8o9J1he2IVz/jRgNwsEeHsS6ONBoLenuRU+D/D2JCbIm1YxAbSKDiQiQN06IlL3KISUU40PIWBO233rajhzErqMgaGvu7pGNU5egZ2NiadZsec4y/ccv+B4kksJ8/OiVUwALaMCC4NJAM0jA/DxqjnL64uIlJZCSDnVihACsP8H+OBmwICb34UOt7q6RjVaTr6N9Ox80nPyScsuID0nn4ycgnP25XMw5Qx7kjNISMniQn+z3N0sDGgdyX19mtClYWjVfwkRkUqmEFJOtSaEAPzwd/jxJfD0g/tWQEQLV9eoTsjOs7H3eAa7kzLYnZzB7uR0didncCrr7IJqnRsEM+7qJgxsG6V74IhIraEQUk61KoTYbeb4kAM/QWQbc/0QL19X16pOMgyDvcczee+nBBZuPuK4e3BcqA/39GrMbV3j8LPWriX3RaTuUQgpp1oVQgAyjpnjQ7KOQ+c7Ydi/XF2jOu9ERi4f/HKAD9YkcvqMubproLcHf+zRkFu61MPT3Q2b3cBmNygofDz3eYHNTn7Ro81Ovs0g32anwGaQZ7Pj5e7GdW2iCNHqsCJSxRRCyqnWhRCA31fCB/Fg2CH+Leg0wtU1Esxum883Hea9VQkknMyq0HP7Wz0Ye3VjxvZuTKC3Z4WeW0TkYhRCyqlWhhCAFS/CiufB0xfu/QEiW7u6RlLIbjf4ftcx3l2VwK+HU3G3WHB3s+Dh7oabxYKHm/m6aPN0t+Dh5oanhxuebhY83d3wcLfgVfh44OQZ9hzLACDIx5M/9W3CmKsa4eul7h4RqVwKIeVUa0OI3QYf3gy/rwCfULh1NjTp6+paSSWw2w0W70jm1aW/se+4ObU43N+LB/o1Y2SPBnh7lm+asM1ucPpMHvk2O9GB3lrATUQcFELKqdaGEICsk2YQSdoKFje4bhr0nGCuVy61js1u8OXWI/xz6V4OnjoDQHSgNw9d24xbutTHZjfIyrWRlVtAVl4BZ/IKnxfuS8nKIyUzl5OZuZzMzCt8zOVUVh5Fq93XC/ahT4sI+rYIp2fTcIJ81PUjUpcphJRTrQ4hAPnZ8NUjsPVj83W74XDjDPDyc229pNLk2+x8tvEwbyzbS1JaToWc02IBN4vF6d477m4WOsUF07t5OH1aRNCxfjDuuveOSJ2iEFJOtT6EABgGrPsPLJkE9gKIbAt3fAihTVxdM6lEOfk25q07yJvL93MyM9ex38/LHT+rB35WD3y93PHz8sDX6k6orxfhAVbC/LwI97cSHmAl3N+LCH8roX5e5NnsrP39FCt/O8GPe0/w+wnnwbWB3h50jAumfogP9YJ9qBfiQ71gX2KDvYkO9Nb6KCK1kEJIOdWJEFIk8Wf4dBRknQDvIBj+PjQf4OpaSSUrsNk5fSYfP6s73h7uFXan4MOnz/DT3pP8+NsJVu07SUZOwUXLurtZiA70pl6ID21jA+naMJSujUKICvSukLqcKyu3gEOnz9Aswl/BR6SS1ZgQ8uOPP/Lyyy+zceNGkpKSWLhwIfHx8Rctv2LFCvr3719sf1JSEtHR0Y7X//rXv3j55ZdJTk6mY8eOzJgxg+7du5e4XnUqhACkH4VP7oIjGwALXPM09H5M40SkXApsdn49ksa+45kcOZ3NkdRsjqaaj0mpOY7F2s5XP8SHrg1D6NIolK4NQ2gRFVDqLp0Cm52th9NYve8kq/adZPPB0+TbDGKDvPljjwbc3q2BbjAoUklK8zvUpfP1srKy6NixI/fccw8333xziY/bs2eP0xeLjIx0PP/kk0949NFHeeutt+jRowevvfYaAwcOZM+ePU7l5ByBsXD3N/DtX2HjbPjhb3B0M9zwKgREubp2UkN5uLtxRYMQrmgQUuw9u93gZGYuh1OzSUzJYvPBVDYcOM3u5HQOn87m8OlsFm05CkCA1YO29QKJDvQmIsDq2CIDCl/7Wwny8eT3k1mO0LFmfwoZ590B2cvDjaNpObzy3W+8vmwvg9vFMKpnQ7o0DNHsHhEXqTbdMRaLpcQtIadPnyY4OPiCZXr06EG3bt148803AbDb7cTFxfHQQw/x5JNPlqguda4l5FwbZ8M3fwFbnnm/mV5/NmfPWP1dXTOpAzJy8tlyyAwkGxNPs/ngabLybJc9zt3NeYAsmOuj9GoWRq9m4VzdLJzoIG++2ZbEnF8S2Xww1VGudUwgd13ZkPjOsRddR6XAZiczt4DM3AICrJ4E+ngouIhcRI3pjjlXaUJIw4YNyc3NpV27dkyZMoVevXoBkJeXh6+vL5999pnTeUaPHk1qaipffPHFBc+bm5tLbu7ZQXrp6enExcXVzRACcGQjfP04HN1kvvaLhH5PwhWjwF3TL6XqFNjs7E7OYO/xDE5k5HIiI5fjhY8nMnI5kZlLauGy914ebnRrFOIIHW1jgy7ajbP9SBof/JLIF1uPkJNvdgsFeHvQo3EYOfk2MnILyMjJJzOngIycArLznYOQl7ubOUC3sFUm3P9sC02wrxdFH3vuv67n/kMb4utJy6gAIgKsCjNS69SY7pjSiomJ4a233qJr167k5uby7rvv0q9fP9auXcsVV1zByZMnsdlsREU5dyFERUWxe/fui553+vTpTJ06tbKrX3PU62KuqLpjISybBqcT4OtHYc2/YcAUaPUHjReRKuHh7ka7ekG0qxd00TK5BTZSMvMI9fMq8SJs7eoF8eItHfi/Ia2Zv/EQH65J5EDKGb7fdeySx3l5uJFXYCfPZudoWg5HyzndOdjXkxZRAbSMCqBFtPnYMiqAIF8z7BuGQU6+nfScfNKz883HnALSs/PJtxkEensQ5ONJoI+n49HPy13BRmqMGtUSciF9+/alQYMGfPDBBxw9epR69erx888/07NnT0eZv/71r6xcuZK1a9de8BxqCbmEgjzYOAtWvghnUsx9cT3MRc4aXOnauolUELvd4Of9KSSczMTf2wN/qycB3h7mVvjc39sDT3c3R+g5tzXmxDmtM6nZeU7ntnA2EFgsZuvIsYwcDpzMwn6Rf33D/a3YDYP07HwKLlboIjzcLAT6eBLo7UGr6EAGtYumf6tILSInVabWtoRcSPfu3Vm1ahUA4eHhuLu7c+yY8/9mjh075jR75nxWqxWrVSPlL8jDC3r8CTqOgJ/fgF/+BYfWwvsDofn10ON+aHqNWkakRnNzs3B183Cubh5+2bJWD3dig32IDfYp12fm5NvYfyKT345lsCc5kz3J6fx2LJMjqdlOa7gAuFkoDBZmIAr09sTTw+1s60h2PmmFrSMFdoNTWXmcysrjQMoZFu9IxtPdwlVNwxnYNprr2kRdcmaQzW5wICWLPckZ7E7O4HRWHj5e7nh7uuPr5Y6Pp7l5Fz739XKnQagv9UN81AIjpVbjQ8iWLVuIiYkBwMvLiy5durBs2TJHi4rdbmfZsmVMmDDBhbWsBbwDzam7XcfCiumw+QPY+525hbeA7vdBxzvAGuDqmorUCN6e7rSNDaJtrHNXU3pOPoknz+Dl4Uagjxk4fEvQxVLUdZNWGExSMvP4ef9JFm9PZu/xTFb+doKVv53gqUXb6NYwlIHtoundPJzj6bnsTk5nd3IGe5Iz+O1YBrkFF54+fSlBPp60jQ2kbWwg7eoF0TY2kMbh/tVixVzDMDiRkcuBlDOE+nnRNMJPgamacGl3TGZmJvv27QOgc+fOvPrqq/Tv35/Q0FAaNGjApEmTOHLkCHPmzAHgtddeo3HjxrRt25acnBzeffddZsyYwXfffce1114LmFN0R48ezdtvv0337t157bXX+PTTT9m9e3exsSIXU6dnx5RUyn5Y9w5s/gjyzLu1Yg2ETiOh+70Q1tS19RMRh33HM1myI5klO5L59XDaZcv7eLrTIsqfltEBRAd6k1NgJzvPRna+rdhjZm4BiSlZ5NuK/yrx8XSndUwAzSMDcHOzYBgGNruB3TCDgc0wn9sNAw83C35WD/ytHvh5eeBndcff6oGv1QN/q7mKr9XTHc/Cu0V7uhfeRfqc17kFdhJOZnHgZBYJJ7NISDGfHziZ5TTLKirQSq9m4fRqGk6vwplTpXEmr8DsksvMJaXwnkophfdXMgdL59EuNogR3RvQKLzu3Q6jxsyOudjiY6NHj2b27NmMGTOGAwcOsGLFCgBeeukl3nnnHY4cOYKvry8dOnRg8uTJxc7x5ptvOhYr69SpE2+88QY9evQocb0UQkohNwO2fGwGkpS9Z/c3vx66/8nsqnHTCpUi1cWR1Gy+25HM4u3JbD6YSr0QH1pGBdAqJoBW0QG0jA6kQahvqVow8grs/HYsg51H09l+NI0dR9PZeTS92KwiV3KzQEyQDycyc8k7r6WnaYQfVzcL56pm4XRtGEJWro2jaebieklpOYUL7GVzNDWHo2nZl1wJ+Hy9m4dz55UNubZVZJ1ZrbfGhJDqSiGkDOx2+P0HWPuO2UVTNCGxXhcY9ALElXzFWhGp+Wx2g4STWew4mkZiyhksmGNvLBZwt1hws1gcN0F0s0C+zSArr4Cs3AIyi+7sXHh356K7OufZ7OTb7OTbDPILZynl2exOU6FjgrxpHO5Ho3A/GocVPob7ERfqg9XDnZx8GxsOnGb1/pP8vO8kvx5Joyy/Bb083IjwN++lFO5vJczxaMXPy53FO5JZ+dsJx7ljgrwZ0b0Bd3SLI7ISbk1QVklp2SSn5dD5AosKlpVCSDkphJRTyn5Y/5658Fl+4Q3N2t0C102FoPourZqI1D42u0F+4W0ASjpNu0jamXx++T2F1ftOsnr/SX4/kYXVw61w8LE3MUHmIOTYIG9ign2oF+xNVKA3/tbLL1h3MOUMH61LZP6Gw5zKMmdNebhZuL5tFMOvqI+f1aMwVBUGq6LnBQZ5Njtn8gpIKxx0nJZ99nnRQOTM3ALiQnwcY3DaFY4xKprifb7M3AJ+PZzKlkOpbDmYytbDqRxLz6VesA+rn7ymVNftUhRCykkhpIJkJJtLwG/+CDDAw8dcgbXXw+BV9/pJRaT6O5NXgI9nxa61kltg49ttyXy4JpENiacr7LwXU7/wppDtYoMI8fNi2+E0thxKZe/xjGLTwt3dLLSMCuCzB3pedMXg0lIIKSeFkAqWtBUWT4LE1ebrgBhz0bP2t2m8iIjUKbuS0vlwTSK/7E/BYgFPdze8PAoH2rpbzNeFA219vNydFqMr2gK9PQjy9cTH053fT2aZY3GOmGNxDp46c8nPjw3yplODYDrFBdMpLoR29QIrLHwUUQgpJ4WQSmAYsOt/8N3TkJpo7ovtDNc/Bw17aZ0REZEKkHYmnx1JaY5gcupMPm1jA+kUF0znuOAqGY+iEFJOCiGVKD8H1r4FP75ydmpvaFNof4s5biSihWvrJyIi5aIQUk4KIVUg8zgsfx62zoOC7LP7o9ubYaTdcAiOc139RESkTBRCykkhpArlZsKeb2H7Z7Dve7CfM/8+7kqzhaRNPPhHuKyKIiJScgoh5aQQ4iJnTsHOL2D753BgFY61Rixu0Liv2TrS+g/gU3Hz2UVEpGIphJSTQkg1kH4UdiyEbfPh6Oaz+908odkAaHcztByse9WIiFQzCiHlpBBSzZz6HbYvMLfjO87u9/CGFgPN7pr63cyF0DTLRkTEpRRCykkhpBo7vht2LDC7bFL2Ob9nDYKoNhDZBqLamltka/AOuvC5RESkwimElJNCSA1gGJD8q9k6sncpnNzjPKj1XEENILYjNOoDjXtDRCu1mIiIVBKFkHJSCKmBCvLg5G9wfCcc22Fux3dC+pHiZf0izTDSuI+5hTRWKBERqSAKIeWkEFKLZJ+GYzvh0FpI+BEOrnFelwQgsL4ZSgLrmeNMPL3Nx6Kt6LV/lLmOiQKLiMhFKYSUk0JILVaQC4c3mIEk4Uc4vB7s+SU/vu1NcMOr4BtaeXUUEanBFELKSSGkDsnLMltJDq6B7FQoyDlny4X8bPOxINvs4rEXmDfgG/YvaHatq2svIlLtKISUk0KIXNCRjbDgT5Cy13zd/T4YMBW8fF1bLxGRaqQ0v0N1H3WRkqrXBf70oxk+ANa9A2/3gSObXFsvEZEaSiFEpDS8fGHIy3DnArNbJmUvvHcdrHgRbBeZIiwiIhek7pgLUHeMlMiZU/D1o+by8gD1usJVD5njTLJPn7edMh9z0sHLD7yDzUXUijaf815bA8zNK+Dsc08fzcwRkWpPY0LKSSFESswwYNtn8PVjkJtWuZ9lcS8MJIHgF2a2xAREQ0Bs4WPh68BY8yZ/Ciwi4gKl+R3qUUV1EqmdLBbocCs07AlLJ8OpBHP6rk8I+BQ9nrNZAyD/DOSkQU5q4WOaOTOn6HlOGuRlQm7G2Q0DDFvhMamQdhDYfPF6efqaN/jr9Edo0h/c3KviaoiIlIpaQi5ALSFSrdjtZnA5N5RkHYeMJMhINu84nJFcuB2FMynOxwfEQsc7zEAS3tw130FE6gx1x5STQojUaAW5cGw7bPkYts03W06K1O9uhpF2N+vGfiJSKRRCykkhRGqNglzY8y1smQv7loJhN/d7eEPDq8wuo3MHxJ6/uRX22DrGl1jOe+5mDpj18jMfPX3V9SNSxymElJNCiNRKGcnw66ew5SM4sbvyPsfd6hxM3L04G14sYMH5tbsnxPWA1jdC/W7gppUDRGoyhZByUgiRWs0wIGmLuQx9Tvo5A2JTnQfH5qSB3QYYZ487exLzwV4A+TnmmBUq4J8S/yho9QdoPRQaXW0GFBGpURRCykkhRKSUDMO8305+trlOSn425GdB3hnzBoGGgTnDp+iRwq4hwwxCe7+D3xZDbvrZc/qEQMshZiBp0t+8m7GIVHsKIeWkECLiAgW55p2Nd30Ju78+b5aPBXzDwD8S/MLBLwL8znnuHwlhzSGsqWvWR7Hlm3dn3v8DpCaaoanVEA3+lTpJIaScFEJEXMxWAIfWwK7/mVv6kZId5xNqjiuJ62bOBKrXBaz+lVPH0wdg3zIzeCT86NyKA+bYmObXmTORWgwyx8iI1AEKIeWkECJSjRgGZB6HrBMX2U6ag26P7wJbrvOxFjeIamsGkvpdzdVkfQtbT3zDwP0y6zUahjlWJivFbJnJSIIDq8zgcWq/c1mfELMFJKSR2ZJzcs/Z9zx9zSDSbjg0G1C+rqWCPDMA2XIhsq0G8kq1oxBSTgohIjVQQR4kb4PD6+BQ4ZZ++NLHeAcXdu2EF4YSTzPUnEk5u9kvcmNCNw8z3DS9BppdAzGdzk5PNgw4vhO2f25upw+cPc4aaM4G8o8yP9c/8mzXUtFzn2Cz9Sdlv7md2g8p+8wt9eDZqdZ+EdBioDl2pkk/tbZItVBjQsiPP/7Iyy+/zMaNG0lKSmLhwoXEx8dftPyCBQuYOXMmW7ZsITc3l7Zt2zJlyhQGDhzoKDNlyhSmTp3qdFzLli3ZvbvkUxIVQkRqifSjZhg5vB6Stp5tOck+dfYXeUl4BZj36/ENh5gO0PRaaNwHvEvw74NhwNHNZhjZsbDkXUuXrI8/YIG8jLP73K3QpK+5XH+LQWarj4gL1Jh7x2RlZdGxY0fuuecebr755suW//HHH7nuuut4/vnnCQ4OZtasWQwdOpS1a9fSuXNnR7m2bdvy/fffO157eOgWOSJ1UmAstI03t3PZbeZdjbNOwpmTZ8OJvcAMGr6hha0jhS0k5ek+sVig3hXmdt3fzEB0ck9hF9NJcwn+c5+fOQUY5voqoU0grNnZx7Bm5uBb/yhzMOzBn83F6PZ8aw6I3fudufGI2TIT3c4MUF5+5tgYr6Kt8LU10GxNCYgGD2vZv6NIGVWb7hiLxXLZlpALadu2LbfffjuTJ08GzJaQRYsWsWXLljLXRS0hIuIytgJzjRaf4JKvPmsY5piY3woDyeENlHrdFp8Q807M/lGFd2SOOudOzTFnn1fG2i1nTplTvANiyj67KS/LnO7tH6lVe12sxrSElJfdbicjI4PQ0FCn/Xv37iU2NhZvb2969uzJ9OnTadCgwUXPk5ubS27u2QFt6enpFy0rIlKp3D3Mrp/SsFggqo259X7MbFnZ973ZHZWXaf6Czs0sfF74Oi/LDDuZx8CWZ7YMZZ82x7Jc/IPOtpwExpqhITDWvDFidAcIaVyygbIFeXBorTnAd/8PZlcZBnj6QViTwunWzZxbf3yCzYXxTiecM05mP5z63Rwrk5FkntvNE4IbQEhDCG54zmMjc/MJKVvQMQxIO2TWtSAXGvaCwJjSn0ec1OgQ8sorr5CZmcltt93m2NejRw9mz55Ny5YtSUpKYurUqfTu3Zvt27cTEBBwwfNMnz692DgSEZEayz/SvFFhSRiGGT4ykiGz6G7MSZBx7OydmjOSzM1eYHYZZR2H5F+Ln8saCNHtzUAS08F8jGhpDuJN2Q/7i6Y0/2QuZncui7u5L3mbuZ3PO8hs6bhkC4/FXBzv1P7is5fOPY9TwDkn6BQN7LXbzbCTtNVcXThpq7lln3Y+V3hLcxxO477mCr8+wRevmmGY1/DEHnPLy4COf4Sgepf4PrVfje2OmTt3Lvfeey9ffPEFAwYMuGi51NRUGjZsyKuvvsrYsWMvWOZCLSFxcXHqjhERKWK3F05TPgrpSWeDSdoROL4Dju0sPkUazAGzPiFmwDmXX4Q5s6jpNebMHt8wcxZR0SyglH2Fs4POaeUAM+iENYXQpuc9NjHfyzgKpxPNc6Umms+LHs+vw/kCYs1WnpR9xdd9AbOVJbK12ZKS9CtOgcjiBrGdzUDSuLfZrXZitxk4ThYGj/PP6ekH/Z6EKx8oWzdXbqYZutyt5hiiy005ryK1vjtm3rx5jBs3jvnz518ygAAEBwfTokUL9u3bd9EyVqsVq1WDskRELsrNDfwjzC2mY/H3bfnmL9rkX81f0EWPeRnmL393L2hwpTmzqOk1ENWueNdNeHNzO19uBqQeOjud+lLdKcENzK1x7+Lv5WfDqYTzgk7hVhSwMo6aZd2t5sDemI5nt8g2ZwfwnjkFB36C31dCwkrzHEc2mtuqVy9cN4u7GZYiWpotTEc2wNJnzLtc3/APaNTr4t+riGGYa9Wsfctcj+b8IORuBQ+vwker2fIT09EcGB17hXndPbwu/zlVpMaFkI8//ph77rmHefPmccMNN1y2fGZmJvv37+euu+6qgtqJiNRR7p7mL+3odme7goq6NTKPmb8Iy7qOiTXAHO9SXp4+Z8fOnO/MKXN8SfoRs3UlouWlWyd8Q6HNMHMDs0UoYaUZSg7+bM5CimgJEa3Mx/CWZotNUYix2807Wi+dDCd2wewh0HEEXDfN7E47X34ObP8M1rwFxy7QXQXmtPOCbHMrknYIjm03PwvMMBjd3gwk9bqY4SSsucsWvXNpd0xmZqajhaJz5868+uqr9O/fn9DQUBo0aMCkSZM4cuQIc+bMAcwumNGjR/P66687Ten18fEhKMi8R8Pjjz/O0KFDadiwIUePHuXZZ59ly5Yt7Ny5k4iIiBLVS7NjRESkSpw5Bcumwsb/AgZYg+DaZ6DrPeYsn4xjsOE9WP+eOZ0czBV4O46AHn8yW1YKcs3BxQW5ZpdYQd7Zx8xj5jo1RzbC0U3Fx7WA+ZmP7QYv3wr5SjVmsbIVK1bQv3//YvtHjx7N7NmzGTNmDAcOHGDFihUA9OvXj5UrV160PMAdd9zBjz/+SEpKChEREVx99dX8/e9/p2nTpiWul0KIiIhUqcMb4KtHzg74jelktqBsX2CO+wAIrA/d74UrRpktMaVlGGbL1JFN5nZ0ExzdYg6OfWhjRX2TmhNCqiuFEBERqXJ2G2x4H5b9DXLTzu6P62EOXm01tOIHn9oKzNaSCpylU+sHpoqIiNQ6bu5mS0ebYbD8ebOLpdtYc+xGZXH3cOk0YYUQERGR6sQ/Eoa+5upaVAndA1pERERcQiFEREREXEIhRERERFxCIURERERcQiFEREREXEIhRERERFxCIURERERcQiFEREREXEIhRERERFxCIURERERcQiFEREREXEL3jrmAohsLp6enu7gmIiIiNUvR786i36WXohByARkZGQDExcW5uCYiIiI1U0ZGBkFBQZcsYzFKElXqGLvdztGjRwkICMBisVTIOdPT04mLi+PQoUMEBgZWyDlF17Uy6dpWDl3XyqHrWnlKe20NwyAjI4PY2Fjc3C496kMtIRfg5uZG/fr1K+XcgYGB+gtSCXRdK4+ubeXQda0cuq6VpzTX9nItIEU0MFVERERcQiFEREREXEIhpIpYrVaeffZZrFarq6tSq+i6Vh5d28qh61o5dF0rT2VeWw1MFREREZdQS4iIiIi4hEKIiIiIuIRCiIiIiLiEQoiIiIi4hEJIFfnXv/5Fo0aN8Pb2pkePHqxbt87VVapRfvzxR4YOHUpsbCwWi4VFixY5vW8YBpMnTyYmJgYfHx8GDBjA3r17XVPZGmT69Ol069aNgIAAIiMjiY+PZ8+ePU5lcnJyGD9+PGFhYfj7+zN8+HCOHTvmohrXDDNnzqRDhw6OxZ169uzJt99+63hf17RivPDCC1gsFiZOnOjYp2tbNlOmTMFisThtrVq1crxfWddVIaQKfPLJJzz66KM8++yzbNq0iY4dOzJw4ECOHz/u6qrVGFlZWXTs2JF//etfF3z/pZde4o033uCtt95i7dq1+Pn5MXDgQHJycqq4pjXLypUrGT9+PGvWrGHp0qXk5+dz/fXXk5WV5SjzyCOP8L///Y/58+ezcuVKjh49ys033+zCWld/9evX54UXXmDjxo1s2LCBa665hmHDhrFjxw5A17QirF+/nrfffpsOHTo47de1Lbu2bduSlJTk2FatWuV4r9KuqyGVrnv37sb48eMdr202mxEbG2tMnz7dhbWquQBj4cKFjtd2u92Ijo42Xn75Zce+1NRUw2q1Gh9//LELalhzHT9+3ACMlStXGoZhXkdPT09j/vz5jjK7du0yAOOXX35xVTVrpJCQEOPdd9/VNa0AGRkZRvPmzY2lS5caffv2NR5++GHDMPTzWh7PPvus0bFjxwu+V5nXVS0hlSwvL4+NGzcyYMAAxz43NzcGDBjAL7/84sKa1R4JCQkkJyc7XeOgoCB69Oiha1xKaWlpAISGhgKwceNG8vPzna5tq1ataNCgga5tCdlsNubNm0dWVhY9e/bUNa0A48eP54YbbnC6hqCf1/Lau3cvsbGxNGnShJEjR3Lw4EGgcq+rbmBXyU6ePInNZiMqKsppf1RUFLt373ZRrWqX5ORkgAte46L35PLsdjsTJ06kV69etGvXDjCvrZeXF8HBwU5ldW0vb9u2bfTs2ZOcnBz8/f1ZuHAhbdq0YcuWLbqm5TBv3jw2bdrE+vXri72nn9ey69GjB7Nnz6Zly5YkJSUxdepUevfuzfbt2yv1uiqEiAhg/u9y+/btTv3AUnYtW7Zky5YtpKWl8dlnnzF69GhWrlzp6mrVaIcOHeLhhx9m6dKleHt7u7o6tcrgwYMdzzt06ECPHj1o2LAhn376KT4+PpX2ueqOqWTh4eG4u7sXG0V87NgxoqOjXVSr2qXoOuoal92ECRP46quvWL58OfXr13fsj46OJi8vj9TUVKfyuraX5+XlRbNmzejSpQvTp0+nY8eOvP7667qm5bBx40aOHz/OFVdcgYeHBx4eHqxcuZI33ngDDw8PoqKidG0rSHBwMC1atGDfvn2V+jOrEFLJvLy86NKlC8uWLXPss9vtLFu2jJ49e7qwZrVH48aNiY6OdrrG6enprF27Vtf4MgzDYMKECSxcuJAffviBxo0bO73fpUsXPD09na7tnj17OHjwoK5tKdntdnJzc3VNy+Haa69l27ZtbNmyxbF17dqVkSNHOp7r2laMzMxM9u/fT0xMTOX+zJZrWKuUyLx58wyr1WrMnj3b2Llzp3HfffcZwcHBRnJysqurVmNkZGQYmzdvNjZv3mwAxquvvmps3rzZSExMNAzDMF544QUjODjY+OKLL4xff/3VGDZsmNG4cWMjOzvbxTWv3h544AEjKCjIWLFihZGUlOTYzpw54yhz//33Gw0aNDB++OEHY8OGDUbPnj2Nnj17urDW1d+TTz5prFy50khISDB+/fVX48knnzQsFovx3XffGYaha1qRzp0dYxi6tmX12GOPGStWrDASEhKM1atXGwMGDDDCw8ON48ePG4ZReddVIaSKzJgxw2jQoIHh5eVldO/e3VizZo2rq1SjLF++3ACKbaNHjzYMw5ym+8wzzxhRUVGG1Wo1rr32WmPPnj2urXQNcKFrChizZs1ylMnOzjYefPBBIyQkxPD19TVuuukmIykpyXWVrgHuueceo2HDhoaXl5cRERFhXHvttY4AYhi6phXp/BCia1s2t99+uxETE2N4eXkZ9erVM26//XZj3759jvcr67paDMMwyteWIiIiIlJ6GhMiIiIiLqEQIiIiIi6hECIiIiIuoRAiIiIiLqEQIiIiIi6hECIiIiIuoRAiIiIiLqEQIiIiIi6hECIidYbFYmHRokWuroaIFFIIEZEqMWbMGCwWS7Ft0KBBrq6aiLiIh6srICJ1x6BBg5g1a5bTPqvV6qLaiIirqSVERKqM1WolOjraaQsJCQHMrpKZM2cyePBgfHx8aNKkCZ999pnT8du2beOaa67Bx8eHsLAw7rvvPjIzM53KvP/++7Rt2xar1UpMTAwTJkxwev/kyZPcdNNN+Pr60rx5c7788svK/dIiclEKISJSbTzzzDMMHz6crVu3MnLkSO644w527doFQFZWFgMHDiQkJIT169czf/58vv/+e6eQMXPmTMaPH899993Htm3b+PLLL2nWrJnTZ0ydOpXbbruNX3/9lSFDhjBy5EhOnTpVpd9TRAqV+z68IiIlMHr0aMPd3d3w8/Nz2v7+978bhmEYgHH//fc7HdOjRw/jgQceMAzDMN555x0jJCTEyMzMdLz/9ddfG25ubkZycrJhGIYRGxtrPPXUUxetA2A8/fTTjteZmZkGYHz77bcV9j1FpOQ0JkREqkz//v2ZOXOm077Q0FDH8549ezq917NnT7Zs2QLArl276NixI35+fo73e/Xqhd1uZ8+ePVgsFo4ePcq11157yTp06NDB8dzPz4/AwECOHz9e1q8kIuWgECIiVcbPz69Y90hF8fHxKVE5T09Pp9cWiwW73V4ZVRKRy9CYEBGpNtasWVPsdevWrQFo3bo1W7duJSsry/H+6tWrcXNzo2XLlgQEBNCoUSOWLVtWpXUWkbJTS4iIVJnc3FySk5Od9nl4eBAeHg7A/Pnz6dq1K1dffTUfffQR69at47333gNg5MiRPPvss4wePZopU6Zw4sQJHnroIe666y6ioqIAmDJlCvfffz+RkZEMHjyYjIwMVq9ezUMPPVS1X1RESkQhRESqzOLFi4mJiXHa17JlS3bv3g2YM1fmzZvHgw8+SExMDB9//DFt2rQBwNfXlyVLlvDwww/TrVs3fH19GT58OK+++qrjXKNHjyYnJ4d//vOfPP7444SHh3PLLbdU3RcUkVKxGIZhuLoSIiIWi4WFCxcSHx/v6qqISBXRmBARERFxCYUQERERcQmNCRGRakE9wyJ1j1pCRERExCUUQkRERMQlFEJERETEJRRCRERExCUUQkRERMQlFEJERETEJRRCRERExCUUQkRERMQl/h9BUXwf5Jih9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(best_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['loss'], label='Training Loss')\n",
    "plt.plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-DPrJzpSZtP",
    "outputId": "d510ce3f-3f90-49fd-961c-d84b8ecd74de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6100 - loss: 1.2808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.27437162399292, 0.6039999723434448]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNPAqDYzMKPN"
   },
   "source": [
    "### 10 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zfJ-KZy0UsXs",
    "outputId": "da1531b9-c857-40d7-ccc2-ff415e6a03a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_126              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_127              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_128              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_129              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_130              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_131              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_132              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_133              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_134              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_156 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_126              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_126 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_157 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_127              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_127 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_158 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_128              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_128 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_159 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_129              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_129 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_160 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_130              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_161 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_131              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_130 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_162 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_132              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_131 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_163 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_133              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_132 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_134              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_133 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_165 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,700</span> (96.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,700\u001b[0m (96.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,916</span> (93.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,916\u001b[0m (93.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.1039 - loss: 3.4464 - val_accuracy: 0.2840 - val_loss: 2.4897\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2492 - loss: 2.6182 - val_accuracy: 0.4170 - val_loss: 2.0357\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3261 - loss: 2.3207 - val_accuracy: 0.4690 - val_loss: 1.8317\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3502 - loss: 2.1546 - val_accuracy: 0.5010 - val_loss: 1.7345\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3849 - loss: 2.0567 - val_accuracy: 0.5110 - val_loss: 1.6658\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3992 - loss: 2.0023 - val_accuracy: 0.5320 - val_loss: 1.6228\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4141 - loss: 1.9537 - val_accuracy: 0.5250 - val_loss: 1.5884\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4233 - loss: 1.9103 - val_accuracy: 0.5440 - val_loss: 1.5505\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4312 - loss: 1.9019 - val_accuracy: 0.5330 - val_loss: 1.5383\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4222 - loss: 1.8930 - val_accuracy: 0.5320 - val_loss: 1.5470\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4410 - loss: 1.8471 - val_accuracy: 0.5570 - val_loss: 1.4872\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4461 - loss: 1.8355 - val_accuracy: 0.5490 - val_loss: 1.4795\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4371 - loss: 1.8276 - val_accuracy: 0.5490 - val_loss: 1.4698\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4383 - loss: 1.8025 - val_accuracy: 0.5380 - val_loss: 1.4755\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4528 - loss: 1.8145 - val_accuracy: 0.5710 - val_loss: 1.4260\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4659 - loss: 1.7594 - val_accuracy: 0.5720 - val_loss: 1.4509\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4570 - loss: 1.7733 - val_accuracy: 0.5650 - val_loss: 1.4346\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4584 - loss: 1.7681 - val_accuracy: 0.5780 - val_loss: 1.4008\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4688 - loss: 1.7373 - val_accuracy: 0.5720 - val_loss: 1.4109\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4712 - loss: 1.7185 - val_accuracy: 0.5880 - val_loss: 1.3932\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4671 - loss: 1.7493 - val_accuracy: 0.5900 - val_loss: 1.3801\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4753 - loss: 1.7252 - val_accuracy: 0.5820 - val_loss: 1.3882\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4697 - loss: 1.7282 - val_accuracy: 0.5900 - val_loss: 1.3481\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4661 - loss: 1.7234 - val_accuracy: 0.5690 - val_loss: 1.3726\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4702 - loss: 1.7319 - val_accuracy: 0.5930 - val_loss: 1.3497\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4732 - loss: 1.7120 - val_accuracy: 0.5900 - val_loss: 1.3500\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4810 - loss: 1.6979 - val_accuracy: 0.5940 - val_loss: 1.3350\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4798 - loss: 1.6902 - val_accuracy: 0.6090 - val_loss: 1.3314\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4837 - loss: 1.6870 - val_accuracy: 0.5900 - val_loss: 1.3563\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4778 - loss: 1.6811 - val_accuracy: 0.5940 - val_loss: 1.3228\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4803 - loss: 1.6812 - val_accuracy: 0.6010 - val_loss: 1.3133\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 1.6688 - val_accuracy: 0.5820 - val_loss: 1.3444\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4838 - loss: 1.6928 - val_accuracy: 0.5920 - val_loss: 1.3244\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4907 - loss: 1.6616 - val_accuracy: 0.5930 - val_loss: 1.3040\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4980 - loss: 1.6510 - val_accuracy: 0.5940 - val_loss: 1.3041\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4800 - loss: 1.6734 - val_accuracy: 0.6020 - val_loss: 1.3117\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4881 - loss: 1.6577 - val_accuracy: 0.5950 - val_loss: 1.3177\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4961 - loss: 1.6319 - val_accuracy: 0.5710 - val_loss: 1.3279\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4893 - loss: 1.6733 - val_accuracy: 0.6010 - val_loss: 1.2955\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4844 - loss: 1.6577 - val_accuracy: 0.5920 - val_loss: 1.3072\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4828 - loss: 1.6576 - val_accuracy: 0.5820 - val_loss: 1.3053\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 1.6417 - val_accuracy: 0.5970 - val_loss: 1.3006\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4992 - loss: 1.6378 - val_accuracy: 0.5960 - val_loss: 1.2906\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4960 - loss: 1.6298 - val_accuracy: 0.5890 - val_loss: 1.3109\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4932 - loss: 1.6437 - val_accuracy: 0.6020 - val_loss: 1.2907\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 1.6168 - val_accuracy: 0.5920 - val_loss: 1.2973\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4953 - loss: 1.6358 - val_accuracy: 0.5950 - val_loss: 1.2814\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5017 - loss: 1.6193 - val_accuracy: 0.5890 - val_loss: 1.2962\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4981 - loss: 1.6259 - val_accuracy: 0.5960 - val_loss: 1.2847\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4965 - loss: 1.6360 - val_accuracy: 0.5820 - val_loss: 1.3218\n",
      "Accuracy: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_135              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_167 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_136              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_135 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_168 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_137              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_136 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_138              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_137 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_139              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_140              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_138 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_172 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_141              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_139 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_142              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_140 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_143              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_141 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_175 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_166 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_135              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_134 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_167 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_136              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_135 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_168 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_137              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_136 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_169 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_138              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_137 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_170 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_139              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_171 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_140              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_138 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_172 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_141              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_139 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_173 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_142              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_140 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_174 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_143              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_141 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_175 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,700</span> (96.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,700\u001b[0m (96.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,916</span> (93.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,916\u001b[0m (93.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.0652 - loss: 3.6193 - val_accuracy: 0.2160 - val_loss: 2.6899\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.1364 - loss: 2.8716 - val_accuracy: 0.2640 - val_loss: 2.4207\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1969 - loss: 2.6125 - val_accuracy: 0.3030 - val_loss: 2.2435\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2173 - loss: 2.4785 - val_accuracy: 0.3220 - val_loss: 2.1304\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.2494 - loss: 2.3779 - val_accuracy: 0.3550 - val_loss: 2.0285\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2502 - loss: 2.3063 - val_accuracy: 0.3630 - val_loss: 1.9734\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.2790 - loss: 2.2437 - val_accuracy: 0.4030 - val_loss: 1.8944\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2960 - loss: 2.2006 - val_accuracy: 0.4170 - val_loss: 1.8358\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2993 - loss: 2.1694 - val_accuracy: 0.4350 - val_loss: 1.8128\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3007 - loss: 2.1665 - val_accuracy: 0.4390 - val_loss: 1.7946\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3220 - loss: 2.1210 - val_accuracy: 0.4250 - val_loss: 1.7651\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3231 - loss: 2.1034 - val_accuracy: 0.4710 - val_loss: 1.7243\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3349 - loss: 2.0818 - val_accuracy: 0.4320 - val_loss: 1.7344\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3309 - loss: 2.0938 - val_accuracy: 0.4590 - val_loss: 1.6916\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3310 - loss: 2.0755 - val_accuracy: 0.4690 - val_loss: 1.6853\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3380 - loss: 2.0558 - val_accuracy: 0.4670 - val_loss: 1.6923\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3571 - loss: 2.0320 - val_accuracy: 0.4640 - val_loss: 1.6624\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3522 - loss: 2.0347 - val_accuracy: 0.4770 - val_loss: 1.6580\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3583 - loss: 2.0143 - val_accuracy: 0.4940 - val_loss: 1.6258\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3540 - loss: 2.0216 - val_accuracy: 0.4810 - val_loss: 1.6305\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3659 - loss: 2.0059 - val_accuracy: 0.5010 - val_loss: 1.6323\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3700 - loss: 1.9992 - val_accuracy: 0.5090 - val_loss: 1.6017\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3678 - loss: 1.9924 - val_accuracy: 0.4880 - val_loss: 1.5810\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3737 - loss: 1.9745 - val_accuracy: 0.5060 - val_loss: 1.6082\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3771 - loss: 1.9779 - val_accuracy: 0.5130 - val_loss: 1.5856\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3727 - loss: 1.9790 - val_accuracy: 0.5150 - val_loss: 1.5969\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3794 - loss: 1.9632 - val_accuracy: 0.5200 - val_loss: 1.5693\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3746 - loss: 1.9693 - val_accuracy: 0.5020 - val_loss: 1.5882\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3766 - loss: 1.9604 - val_accuracy: 0.5110 - val_loss: 1.5553\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3856 - loss: 1.9331 - val_accuracy: 0.5290 - val_loss: 1.5361\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3863 - loss: 1.9434 - val_accuracy: 0.5260 - val_loss: 1.5274\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3951 - loss: 1.9275 - val_accuracy: 0.5140 - val_loss: 1.5341\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3883 - loss: 1.9496 - val_accuracy: 0.5400 - val_loss: 1.5324\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3878 - loss: 1.9355 - val_accuracy: 0.5410 - val_loss: 1.5319\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.3900 - loss: 1.9399 - val_accuracy: 0.5180 - val_loss: 1.5051\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3984 - loss: 1.9106 - val_accuracy: 0.5530 - val_loss: 1.4851\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3987 - loss: 1.9188 - val_accuracy: 0.5280 - val_loss: 1.5098\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3969 - loss: 1.9387 - val_accuracy: 0.5410 - val_loss: 1.5139\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4027 - loss: 1.9159 - val_accuracy: 0.5360 - val_loss: 1.5084\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4081 - loss: 1.9149 - val_accuracy: 0.5380 - val_loss: 1.5132\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4005 - loss: 1.9038 - val_accuracy: 0.5460 - val_loss: 1.4955\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4034 - loss: 1.9232 - val_accuracy: 0.5500 - val_loss: 1.4913\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4035 - loss: 1.9145 - val_accuracy: 0.5280 - val_loss: 1.5002\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4031 - loss: 1.9040 - val_accuracy: 0.5330 - val_loss: 1.5085\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4053 - loss: 1.8867 - val_accuracy: 0.5450 - val_loss: 1.4821\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4135 - loss: 1.8904 - val_accuracy: 0.5500 - val_loss: 1.4905\n",
      "Epoch 47/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4107 - loss: 1.8913 - val_accuracy: 0.5410 - val_loss: 1.4816\n",
      "Epoch 48/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4118 - loss: 1.9111 - val_accuracy: 0.5550 - val_loss: 1.4687\n",
      "Epoch 49/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4155 - loss: 1.8979 - val_accuracy: 0.5530 - val_loss: 1.4780\n",
      "Epoch 50/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4107 - loss: 1.8992 - val_accuracy: 0.5520 - val_loss: 1.4823\n",
      "Accuracy: 0.5465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_176 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_144              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_142 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_145              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_143 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_146              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_144 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_147              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_145 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_180 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_148              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_181 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_149              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_146 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_182 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_150              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_183 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_151              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_184 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_152              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_185 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_176 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_144              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_142 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_177 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_145              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_143 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_146              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_144 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_179 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_147              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_145 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_180 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_148              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_181 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_149              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_146 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_182 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_150              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_147 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_183 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_151              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_148 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_184 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_152              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_149 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_185 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,700</span> (96.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,700\u001b[0m (96.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,916</span> (93.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,916\u001b[0m (93.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.0837 - loss: 3.4780 - val_accuracy: 0.2820 - val_loss: 2.5967\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.2366 - loss: 2.6812 - val_accuracy: 0.3750 - val_loss: 2.1362\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3069 - loss: 2.3918 - val_accuracy: 0.4480 - val_loss: 1.9425\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3446 - loss: 2.2142 - val_accuracy: 0.4790 - val_loss: 1.8183\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3786 - loss: 2.1020 - val_accuracy: 0.5040 - val_loss: 1.7367\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3948 - loss: 2.0290 - val_accuracy: 0.5150 - val_loss: 1.6753\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4021 - loss: 1.9782 - val_accuracy: 0.5290 - val_loss: 1.6197\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4242 - loss: 1.9354 - val_accuracy: 0.5350 - val_loss: 1.5907\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4277 - loss: 1.8975 - val_accuracy: 0.5400 - val_loss: 1.5364\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4424 - loss: 1.8506 - val_accuracy: 0.5440 - val_loss: 1.5290\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4409 - loss: 1.8281 - val_accuracy: 0.5480 - val_loss: 1.4947\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4509 - loss: 1.8189 - val_accuracy: 0.5590 - val_loss: 1.4766\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4532 - loss: 1.7794 - val_accuracy: 0.5680 - val_loss: 1.4700\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4589 - loss: 1.7861 - val_accuracy: 0.5700 - val_loss: 1.4582\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4760 - loss: 1.7476 - val_accuracy: 0.5810 - val_loss: 1.4343\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4716 - loss: 1.7396 - val_accuracy: 0.5740 - val_loss: 1.4221\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4709 - loss: 1.7504 - val_accuracy: 0.5480 - val_loss: 1.4455\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4780 - loss: 1.7185 - val_accuracy: 0.5710 - val_loss: 1.4039\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4828 - loss: 1.7050 - val_accuracy: 0.5920 - val_loss: 1.3790\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4863 - loss: 1.6852 - val_accuracy: 0.5840 - val_loss: 1.3842\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4851 - loss: 1.6964 - val_accuracy: 0.5780 - val_loss: 1.3581\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4976 - loss: 1.6663 - val_accuracy: 0.5930 - val_loss: 1.3692\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4986 - loss: 1.6645 - val_accuracy: 0.5810 - val_loss: 1.3694\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5007 - loss: 1.6570 - val_accuracy: 0.5730 - val_loss: 1.3621\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4966 - loss: 1.6625 - val_accuracy: 0.5810 - val_loss: 1.3647\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4948 - loss: 1.6372 - val_accuracy: 0.5820 - val_loss: 1.3597\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5065 - loss: 1.6247 - val_accuracy: 0.5980 - val_loss: 1.3290\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5076 - loss: 1.6291 - val_accuracy: 0.5900 - val_loss: 1.3368\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5069 - loss: 1.6085 - val_accuracy: 0.5980 - val_loss: 1.3389\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5071 - loss: 1.6173 - val_accuracy: 0.5900 - val_loss: 1.3230\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5076 - loss: 1.5983 - val_accuracy: 0.5980 - val_loss: 1.3383\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5127 - loss: 1.5987 - val_accuracy: 0.6010 - val_loss: 1.3029\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: 1.6281 - val_accuracy: 0.5970 - val_loss: 1.2927\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5162 - loss: 1.5745 - val_accuracy: 0.6050 - val_loss: 1.2997\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5025 - loss: 1.6087 - val_accuracy: 0.5920 - val_loss: 1.2884\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5091 - loss: 1.6107 - val_accuracy: 0.5960 - val_loss: 1.3061\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5222 - loss: 1.5857 - val_accuracy: 0.5970 - val_loss: 1.2941\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5158 - loss: 1.5889 - val_accuracy: 0.6030 - val_loss: 1.2998\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5225 - loss: 1.5752 - val_accuracy: 0.5880 - val_loss: 1.2917\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5068 - loss: 1.5897 - val_accuracy: 0.6050 - val_loss: 1.2888\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5168 - loss: 1.5768 - val_accuracy: 0.6010 - val_loss: 1.2974\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5155 - loss: 1.5662 - val_accuracy: 0.6020 - val_loss: 1.2850\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5209 - loss: 1.5639 - val_accuracy: 0.6000 - val_loss: 1.2840\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5241 - loss: 1.5601 - val_accuracy: 0.5990 - val_loss: 1.2793\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5221 - loss: 1.5610 - val_accuracy: 0.6040 - val_loss: 1.2690\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5213 - loss: 1.5622 - val_accuracy: 0.6090 - val_loss: 1.2828\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5139 - loss: 1.5793 - val_accuracy: 0.6040 - val_loss: 1.2760\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5195 - loss: 1.5680 - val_accuracy: 0.6030 - val_loss: 1.2823\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5204 - loss: 1.5667 - val_accuracy: 0.5930 - val_loss: 1.2598\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5279 - loss: 1.5438 - val_accuracy: 0.6170 - val_loss: 1.2571\n",
      "Accuracy: 0.5915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_186 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_153              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_187 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_154              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_188 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_155              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_189 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_156              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_190 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_157              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_191 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_158              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_154 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_192 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_159              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_155 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_193 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_160              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_156 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_194 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_161              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_157 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_195 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_186 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_153              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_150 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_187 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_154              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_151 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_188 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_155              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_152 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_189 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_156              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_153 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_190 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_157              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_191 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_158              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_154 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_192 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_159              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_155 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_193 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_160              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_156 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_194 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_161              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_157 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_195 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,700</span> (96.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,700\u001b[0m (96.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,916</span> (93.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,916\u001b[0m (93.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.0654 - loss: 3.6842 - val_accuracy: 0.2330 - val_loss: 2.8401\n",
      "Epoch 2/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1357 - loss: 2.9722 - val_accuracy: 0.3030 - val_loss: 2.3648\n",
      "Epoch 3/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.1888 - loss: 2.6483 - val_accuracy: 0.3310 - val_loss: 2.2186\n",
      "Epoch 4/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2266 - loss: 2.5008 - val_accuracy: 0.3730 - val_loss: 2.1142\n",
      "Epoch 5/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2522 - loss: 2.4020 - val_accuracy: 0.3770 - val_loss: 2.0370\n",
      "Epoch 6/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2746 - loss: 2.3296 - val_accuracy: 0.3830 - val_loss: 1.9656\n",
      "Epoch 7/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.2839 - loss: 2.2631 - val_accuracy: 0.4040 - val_loss: 1.9207\n",
      "Epoch 8/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3028 - loss: 2.2033 - val_accuracy: 0.4140 - val_loss: 1.8665\n",
      "Epoch 9/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3086 - loss: 2.1675 - val_accuracy: 0.4270 - val_loss: 1.8373\n",
      "Epoch 10/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3164 - loss: 2.1328 - val_accuracy: 0.4370 - val_loss: 1.8022\n",
      "Epoch 11/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3187 - loss: 2.1192 - val_accuracy: 0.4510 - val_loss: 1.7789\n",
      "Epoch 12/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3253 - loss: 2.0856 - val_accuracy: 0.4520 - val_loss: 1.7632\n",
      "Epoch 13/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3289 - loss: 2.0785 - val_accuracy: 0.4540 - val_loss: 1.7368\n",
      "Epoch 14/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3365 - loss: 2.0616 - val_accuracy: 0.4540 - val_loss: 1.7317\n",
      "Epoch 15/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3504 - loss: 2.0281 - val_accuracy: 0.4620 - val_loss: 1.6992\n",
      "Epoch 16/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3430 - loss: 2.0281 - val_accuracy: 0.4880 - val_loss: 1.6798\n",
      "Epoch 17/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3479 - loss: 2.0228 - val_accuracy: 0.4810 - val_loss: 1.6636\n",
      "Epoch 18/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3496 - loss: 2.0091 - val_accuracy: 0.4740 - val_loss: 1.6453\n",
      "Epoch 19/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3603 - loss: 1.9954 - val_accuracy: 0.4990 - val_loss: 1.6369\n",
      "Epoch 20/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3682 - loss: 1.9816 - val_accuracy: 0.4780 - val_loss: 1.6354\n",
      "Epoch 21/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3665 - loss: 1.9814 - val_accuracy: 0.4960 - val_loss: 1.6107\n",
      "Epoch 22/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3690 - loss: 1.9655 - val_accuracy: 0.5010 - val_loss: 1.6013\n",
      "Epoch 23/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3632 - loss: 1.9751 - val_accuracy: 0.4900 - val_loss: 1.5917\n",
      "Epoch 24/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3895 - loss: 1.9210 - val_accuracy: 0.5020 - val_loss: 1.5903\n",
      "Epoch 25/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3844 - loss: 1.9467 - val_accuracy: 0.5110 - val_loss: 1.5833\n",
      "Epoch 26/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3987 - loss: 1.9220 - val_accuracy: 0.5130 - val_loss: 1.5562\n",
      "Epoch 27/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3812 - loss: 1.9307 - val_accuracy: 0.5150 - val_loss: 1.5572\n",
      "Epoch 28/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3899 - loss: 1.9235 - val_accuracy: 0.5310 - val_loss: 1.5506\n",
      "Epoch 29/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3945 - loss: 1.9107 - val_accuracy: 0.5110 - val_loss: 1.5606\n",
      "Epoch 30/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3886 - loss: 1.9188 - val_accuracy: 0.5220 - val_loss: 1.5406\n",
      "Epoch 31/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4045 - loss: 1.8780 - val_accuracy: 0.5150 - val_loss: 1.5293\n",
      "Epoch 32/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4048 - loss: 1.8879 - val_accuracy: 0.5280 - val_loss: 1.5239\n",
      "Epoch 33/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4044 - loss: 1.8891 - val_accuracy: 0.5430 - val_loss: 1.5025\n",
      "Epoch 34/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4051 - loss: 1.8680 - val_accuracy: 0.5370 - val_loss: 1.5024\n",
      "Epoch 35/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4019 - loss: 1.8912 - val_accuracy: 0.5250 - val_loss: 1.4957\n",
      "Epoch 36/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4080 - loss: 1.8723 - val_accuracy: 0.5350 - val_loss: 1.4835\n",
      "Epoch 37/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4075 - loss: 1.8783 - val_accuracy: 0.5310 - val_loss: 1.4963\n",
      "Epoch 38/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4143 - loss: 1.8525 - val_accuracy: 0.5360 - val_loss: 1.4764\n",
      "Epoch 39/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4142 - loss: 1.8622 - val_accuracy: 0.5430 - val_loss: 1.4654\n",
      "Epoch 40/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4163 - loss: 1.8589 - val_accuracy: 0.5320 - val_loss: 1.4784\n",
      "Epoch 41/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4164 - loss: 1.8481 - val_accuracy: 0.5390 - val_loss: 1.4772\n",
      "Epoch 42/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4132 - loss: 1.8464 - val_accuracy: 0.5570 - val_loss: 1.4517\n",
      "Epoch 43/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4213 - loss: 1.8432 - val_accuracy: 0.5570 - val_loss: 1.4550\n",
      "Epoch 44/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4242 - loss: 1.8436 - val_accuracy: 0.5470 - val_loss: 1.4648\n",
      "Epoch 45/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4252 - loss: 1.8384 - val_accuracy: 0.5540 - val_loss: 1.4562\n",
      "Epoch 46/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4364 - loss: 1.8115 - val_accuracy: 0.5530 - val_loss: 1.4542\n",
      "Epoch 47/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4189 - loss: 1.8417 - val_accuracy: 0.5630 - val_loss: 1.4220\n",
      "Epoch 48/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4226 - loss: 1.8132 - val_accuracy: 0.5460 - val_loss: 1.4482\n",
      "Epoch 49/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4224 - loss: 1.8388 - val_accuracy: 0.5570 - val_loss: 1.4315\n",
      "Epoch 50/50\n",
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4316 - loss: 1.8190 - val_accuracy: 0.5720 - val_loss: 1.4126\n",
      "Accuracy: 0.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning:\n",
      "\n",
      "Argument `decay` is no longer supported and will be ignored.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_196 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_162              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_158 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_197 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_163              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_159 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_198 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_164              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_160 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_199 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_165              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_161 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_200 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_166              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_201 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_167              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_162 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_202 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_168              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_163 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_203 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_169              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_204 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_170              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_205 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_196 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_162              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_158 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_197 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_163              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_159 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_198 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_164              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_160 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_199 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_165              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_161 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_200 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_166              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_201 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m528\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_167              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_162 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_202 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_168              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │              \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_163 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_203 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m144\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_169              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │              \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_164 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_204 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m544\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_170              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_165 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_205 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m660\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,700</span> (96.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,700\u001b[0m (96.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,916</span> (93.42 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,916\u001b[0m (93.42 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> (3.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m784\u001b[0m (3.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2013 - loss: 2.7465 - val_accuracy: 0.3530 - val_loss: 2.0509\n",
      "Epoch 2/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3146 - loss: 2.1717 - val_accuracy: 0.4330 - val_loss: 1.8810\n",
      "Epoch 3/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3406 - loss: 2.1291 - val_accuracy: 0.4170 - val_loss: 1.9342\n",
      "Epoch 4/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3554 - loss: 2.0884 - val_accuracy: 0.4490 - val_loss: 1.8282\n",
      "Epoch 5/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3755 - loss: 2.0469 - val_accuracy: 0.4710 - val_loss: 1.7539\n",
      "Epoch 6/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3789 - loss: 2.0443 - val_accuracy: 0.4730 - val_loss: 1.8405\n",
      "Epoch 7/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.3925 - loss: 2.0220 - val_accuracy: 0.4470 - val_loss: 1.7660\n",
      "Epoch 8/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3989 - loss: 1.9941 - val_accuracy: 0.4860 - val_loss: 1.6912\n",
      "Epoch 9/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4085 - loss: 2.0020 - val_accuracy: 0.4770 - val_loss: 1.7349\n",
      "Epoch 10/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4041 - loss: 1.9768 - val_accuracy: 0.4760 - val_loss: 1.7736\n",
      "Epoch 11/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.3955 - loss: 1.9996 - val_accuracy: 0.4770 - val_loss: 1.7291\n",
      "Epoch 12/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4072 - loss: 1.9773 - val_accuracy: 0.4810 - val_loss: 1.6779\n",
      "Epoch 13/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4136 - loss: 1.9704 - val_accuracy: 0.4570 - val_loss: 1.8247\n",
      "Epoch 14/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4198 - loss: 1.9434 - val_accuracy: 0.4970 - val_loss: 1.6551\n",
      "Epoch 15/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4256 - loss: 1.9246 - val_accuracy: 0.4960 - val_loss: 1.6963\n",
      "Epoch 16/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4265 - loss: 1.9419 - val_accuracy: 0.4790 - val_loss: 1.7155\n",
      "Epoch 17/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4255 - loss: 1.9272 - val_accuracy: 0.5010 - val_loss: 1.6808\n",
      "Epoch 18/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4266 - loss: 1.9325 - val_accuracy: 0.4760 - val_loss: 1.7542\n",
      "Epoch 19/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4249 - loss: 1.9322 - val_accuracy: 0.5340 - val_loss: 1.6195\n",
      "Epoch 20/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4258 - loss: 1.9200 - val_accuracy: 0.5170 - val_loss: 1.6224\n",
      "Epoch 21/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4329 - loss: 1.9096 - val_accuracy: 0.5370 - val_loss: 1.6397\n",
      "Epoch 22/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4221 - loss: 1.9333 - val_accuracy: 0.5090 - val_loss: 1.6798\n",
      "Epoch 23/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4416 - loss: 1.8949 - val_accuracy: 0.5190 - val_loss: 1.6842\n",
      "Epoch 24/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4385 - loss: 1.9019 - val_accuracy: 0.5180 - val_loss: 1.6456\n",
      "Epoch 25/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4392 - loss: 1.8919 - val_accuracy: 0.4990 - val_loss: 1.6642\n",
      "Epoch 26/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4393 - loss: 1.8759 - val_accuracy: 0.5120 - val_loss: 1.6275\n",
      "Epoch 27/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 1.9010 - val_accuracy: 0.5570 - val_loss: 1.5594\n",
      "Epoch 28/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4543 - loss: 1.8880 - val_accuracy: 0.5360 - val_loss: 1.6269\n",
      "Epoch 29/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4463 - loss: 1.8967 - val_accuracy: 0.4780 - val_loss: 1.7298\n",
      "Epoch 30/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4465 - loss: 1.8751 - val_accuracy: 0.5040 - val_loss: 1.6558\n",
      "Epoch 31/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4419 - loss: 1.8875 - val_accuracy: 0.5060 - val_loss: 1.6449\n",
      "Epoch 32/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4489 - loss: 1.8682 - val_accuracy: 0.5390 - val_loss: 1.5921\n",
      "Epoch 33/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4487 - loss: 1.8873 - val_accuracy: 0.5590 - val_loss: 1.5362\n",
      "Epoch 34/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4517 - loss: 1.8568 - val_accuracy: 0.5060 - val_loss: 1.6511\n",
      "Epoch 35/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4386 - loss: 1.8941 - val_accuracy: 0.5300 - val_loss: 1.6404\n",
      "Epoch 36/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4472 - loss: 1.8844 - val_accuracy: 0.5310 - val_loss: 1.5783\n",
      "Epoch 37/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4531 - loss: 1.8589 - val_accuracy: 0.5570 - val_loss: 1.5429\n",
      "Epoch 38/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4639 - loss: 1.8632 - val_accuracy: 0.5190 - val_loss: 1.6559\n",
      "Epoch 39/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4491 - loss: 1.8719 - val_accuracy: 0.5510 - val_loss: 1.5815\n",
      "Epoch 40/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4463 - loss: 1.8931 - val_accuracy: 0.5110 - val_loss: 1.6564\n",
      "Epoch 41/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.4532 - loss: 1.8581 - val_accuracy: 0.5410 - val_loss: 1.5864\n",
      "Epoch 42/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.4482 - loss: 1.8718 - val_accuracy: 0.5370 - val_loss: 1.6099\n",
      "Epoch 43/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4605 - loss: 1.8644 - val_accuracy: 0.5270 - val_loss: 1.6306\n",
      "Epoch 44/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4669 - loss: 1.8444 - val_accuracy: 0.5390 - val_loss: 1.5459\n",
      "Epoch 45/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4611 - loss: 1.8574 - val_accuracy: 0.5340 - val_loss: 1.5567\n",
      "Epoch 46/50\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4531 - loss: 1.8693 - val_accuracy: 0.5520 - val_loss: 1.5446\n",
      "Epoch 47/50\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.001, 0.01,0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "dropout = [0.1,0.2]\n",
    "best_accuracy = 0\n",
    "input_shape = X_train.shape[1:]\n",
    "best_history = None\n",
    "best_model = None\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for batch in batch_sizes:\n",
    "        for d in dropout:\n",
    "            model = Ten_Layer_NN()\n",
    "            config = {\n",
    "                        'input_shape': input_shape,\n",
    "                        'epochs': 50,\n",
    "                        'dropout': d,\n",
    "                        'batch_size': batch,\n",
    "                        'lr': lr\n",
    "                    }\n",
    "            model.build_model(config)\n",
    "            history = model.train(X_train, y_train, X_valid, y_valid, config)\n",
    "            loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "            print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_model = model\n",
    "                best_accuracy = accuracy\n",
    "                best_params = {'learning_rate': lr, 'batch_size': batch, 'dropout': d}\n",
    "                best_history = history\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "id": "sPIFv6PcU3zU",
    "outputId": "2aa4766b-0121-4283-f6fe-e079f847ab5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAGJCAYAAABcsOOZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABz50lEQVR4nO3dd3gUZdfA4d+mbXrvpIcQekCagDSNVJGIBXmRoiCKoKJiwYKAJYhd8AN9VRAV8UUFFQUEJKBI70iRQEiANEhI77vz/TFkYUlCejYh576uuXZ39pmZM2N0j0/VKIqiIIQQQgjRwMxMHYAQQgghmidJQoQQQghhEpKECCGEEMIkJAkRQgghhElIEiKEEEIIk5AkRAghhBAmIUmIEEIIIUxCkhAhhBBCmIQkIUIIIYQwCUlChKhjEyZMICgoqEbHzp49G41GU7cBNTJnzpxBo9GwdOnSBr+2RqNh9uzZhs9Lly5Fo9Fw5syZSo8NCgpiwoQJdRpPbf5WhLgRSBIimg2NRlOlLSYmxtShNntPPPEEGo2G2NjYCsu89NJLaDQaDh061ICRVV9iYiKzZ8/mwIEDpg7FoDQRfOedd0wdimjmLEwdgBAN5auvvjL6vGzZMjZs2FBmf5s2bWp1nf/+97/o9foaHfvyyy/zwgsv1Or6N4IxY8awYMECli9fzqxZs8ot8+2339KhQwc6duxY4+uMHTuW+++/H61WW+NzVCYxMZE5c+YQFBREp06djL6rzd+KEDcCSUJEs/HAAw8Yfd6xYwcbNmwos/9aeXl52NraVvk6lpaWNYoPwMLCAgsL+deyR48etGzZkm+//bbcJGT79u3ExcUxb968Wl3H3Nwcc3PzWp2jNmrztyLEjUCaY4S4Sv/+/Wnfvj179+6lb9++2Nra8uKLLwLw008/MWzYMHx9fdFqtYSGhvLaa6+h0+mMznFtO//VVd+ffvopoaGhaLVaunXrxu7du42OLa9PiEajYdq0aaxevZr27duj1Wpp164d69atKxN/TEwMXbt2xdramtDQUD755JMq9zP5888/uffeewkICECr1eLv789TTz1Ffn5+mfuzt7fn/PnzREVFYW9vj4eHBzNmzCjzLDIyMpgwYQJOTk44Ozszfvx4MjIyKo0F1NqQ48ePs2/fvjLfLV++HI1Gw+jRoykqKmLWrFl06dIFJycn7Ozs6NOnD5s3b670GuX1CVEUhddffx0/Pz9sbW0ZMGAA//zzT5lj09PTmTFjBh06dMDe3h5HR0eGDBnCwYMHDWViYmLo1q0bAA8++KChya+0P0x5fUJyc3N55pln8Pf3R6vVEh4ezjvvvMO1C55X5++iplJTU5k4cSJeXl5YW1sTERHBl19+WabcihUr6NKlCw4ODjg6OtKhQwc+/PBDw/fFxcXMmTOHsLAwrK2tcXNz45ZbbmHDhg11FqtomuR/uYS4RlpaGkOGDOH+++/ngQcewMvLC1B/sOzt7Xn66aext7fnjz/+YNasWWRlZfH2229Xet7ly5eTnZ3NI488gkajYf78+YwcOZLTp09X+n/Ef/31Fz/++COPPfYYDg4OfPTRR9x9990kJCTg5uYGwP79+xk8eDA+Pj7MmTMHnU7H3Llz8fDwqNJ9r1y5kry8PKZMmYKbmxu7du1iwYIFnDt3jpUrVxqV1el0DBo0iB49evDOO++wceNG3n33XUJDQ5kyZQqg/piPGDGCv/76i0cffZQ2bdqwatUqxo8fX6V4xowZw5w5c1i+fDk33XST0bX/97//0adPHwICArh48SKfffYZo0eP5uGHHyY7O5vPP/+cQYMGsWvXrjJNIJWZNWsWr7/+OkOHDmXo0KHs27ePgQMHUlRUZFTu9OnTrF69mnvvvZfg4GBSUlL45JNP6NevH0ePHsXX15c2bdowd+5cZs2axeTJk+nTpw8AvXr1KvfaiqJw5513snnzZiZOnEinTp1Yv349zz77LOfPn+f99983Kl+Vv4uays/Pp3///sTGxjJt2jSCg4NZuXIlEyZMICMjgyeffBKADRs2MHr0aG677TbeeustAI4dO8a2bdsMZWbPnk10dDSTJk2ie/fuZGVlsWfPHvbt28ftt99eqzhFE6cI0UxNnTpVufZfgX79+imAsnjx4jLl8/Lyyux75JFHFFtbW6WgoMCwb/z48UpgYKDhc1xcnAIobm5uSnp6umH/Tz/9pADKL7/8Ytj36quvlokJUKysrJTY2FjDvoMHDyqAsmDBAsO+4cOHK7a2tsr58+cN+06ePKlYWFiUOWd5yru/6OhoRaPRKPHx8Ub3Byhz5841Ktu5c2elS5cuhs+rV69WAGX+/PmGfSUlJUqfPn0UQFmyZEmlMXXr1k3x8/NTdDqdYd+6desUQPnkk08M5ywsLDQ67tKlS4qXl5fy0EMPGe0HlFdffdXwecmSJQqgxMXFKYqiKKmpqYqVlZUybNgwRa/XG8q9+OKLCqCMHz/esK+goMAoLkVR/1lrtVqjZ7N79+4K7/fav5XSZ/b6668blbvnnnsUjUZj9DdQ1b+L8pT+Tb799tsVlvnggw8UQPn6668N+4qKipSePXsq9vb2SlZWlqIoivLkk08qjo6OSklJSYXnioiIUIYNG3bdmETzJM0xQlxDq9Xy4IMPltlvY2NjeJ+dnc3Fixfp06cPeXl5HD9+vNLzjho1ChcXF8Pn0v8rPn36dKXHRkZGEhoaavjcsWNHHB0dDcfqdDo2btxIVFQUvr6+hnItW7ZkyJAhlZ4fjO8vNzeXixcv0qtXLxRFYf/+/WXKP/roo0af+/TpY3Qvv/32GxYWFoaaEVD7YDz++ONVigfUfjznzp1j69athn3Lly/HysqKe++913BOKysrAPR6Penp6ZSUlNC1a9dym3KuZ+PGjRQVFfH4448bNWFNnz69TFmtVouZmfqfUJ1OR1paGvb29oSHh1f7uqV+++03zM3NeeKJJ4z2P/PMMyiKwtq1a432V/Z3URu//fYb3t7ejB492rDP0tKSJ554gpycHLZs2QKAs7Mzubm5121acXZ25p9//uHkyZO1jkvcWCQJEeIaLVq0MPyoXe2ff/7hrrvuwsnJCUdHRzw8PAydWjMzMys9b0BAgNHn0oTk0qVL1T629PjSY1NTU8nPz6dly5ZlypW3rzwJCQlMmDABV1dXQz+Pfv36AWXvz9raukwzz9XxAMTHx+Pj44O9vb1RufDw8CrFA3D//fdjbm7O8uXLASgoKGDVqlUMGTLEKKH78ssv6dixo6G/gYeHB7/++muV/rlcLT4+HoCwsDCj/R4eHkbXAzXhef/99wkLC0Or1eLu7o6HhweHDh2q9nWvvr6vry8ODg5G+0tHbJXGV6qyv4vaiI+PJywszJBoVRTLY489RqtWrRgyZAh+fn489NBDZfqlzJ07l4yMDFq1akWHDh149tlnG/3QatEwJAkR4hpX1wiUysjIoF+/fhw8eJC5c+fyyy+/sGHDBkMbeFWGWVY0CkO5psNhXR9bFTqdjttvv51ff/2V559/ntWrV7NhwwZDB8pr76+hRpR4enpy++2388MPP1BcXMwvv/xCdnY2Y8aMMZT5+uuvmTBhAqGhoXz++eesW7eODRs2cOutt9br8Nc333yTp59+mr59+/L111+zfv16NmzYQLt27Rps2G19/11UhaenJwcOHODnn3829GcZMmSIUd+fvn37curUKb744gvat2/PZ599xk033cRnn33WYHGKxkk6pgpRBTExMaSlpfHjjz/St29fw/64uDgTRnWFp6cn1tbW5U7udb0Jv0odPnyYf//9ly+//JJx48YZ9tdm9EJgYCCbNm0iJyfHqDbkxIkT1TrPmDFjWLduHWvXrmX58uU4OjoyfPhww/fff/89ISEh/Pjjj0ZNKK+++mqNYgY4efIkISEhhv0XLlwoU7vw/fffM2DAAD7//HOj/RkZGbi7uxs+V2cG3MDAQDZu3Eh2drZRbUhpc19pfA0hMDCQQ4cOodfrjWpDyovFysqK4cOHM3z4cPR6PY899hiffPIJr7zyiqEmztXVlQcffJAHH3yQnJwc+vbty+zZs5k0aVKD3ZNofKQmRIgqKP0/zqv/D7OoqIj/+7//M1VIRszNzYmMjGT16tUkJiYa9sfGxpbpR1DR8WB8f4qiGA2zrK6hQ4dSUlLCokWLDPt0Oh0LFiyo1nmioqKwtbXl//7v/1i7di0jR47E2tr6urHv3LmT7du3VzvmyMhILC0tWbBggdH5PvjggzJlzc3Ny9Q4rFy5kvPnzxvts7OzA6jS0OShQ4ei0+lYuHCh0f73338fjUZT5f49dWHo0KEkJyfz3XffGfaVlJSwYMEC7O3tDU11aWlpRseZmZkZJpArLCwst4y9vT0tW7Y0fC+aL6kJEaIKevXqhYuLC+PHjzdMKf7VV181aLV3ZWbPns3vv/9O7969mTJliuHHrH379pVOGd66dWtCQ0OZMWMG58+fx9HRkR9++KFWfQuGDx9O7969eeGFFzhz5gxt27blxx9/rHZ/CXt7e6Kiogz9Qq5uigG44447+PHHH7nrrrsYNmwYcXFxLF68mLZt25KTk1Ota5XOdxIdHc0dd9zB0KFD2b9/P2vXrjWq3Si97ty5c3nwwQfp1asXhw8f5ptvvjGqQQEIDQ3F2dmZxYsX4+DggJ2dHT169CA4OLjM9YcPH86AAQN46aWXOHPmDBEREfz+++/89NNPTJ8+3agTal3YtGkTBQUFZfZHRUUxefJkPvnkEyZMmMDevXsJCgri+++/Z9u2bXzwwQeGmppJkyaRnp7Orbfeip+fH/Hx8SxYsIBOnToZ+o+0bduW/v3706VLF1xdXdmzZw/ff/8906ZNq9P7EU2QaQblCGF6FQ3RbdeuXbnlt23bptx8882KjY2N4uvrqzz33HPK+vXrFUDZvHmzoVxFQ3TLGw7JNUNGKxqiO3Xq1DLHBgYGGg0ZVRRF2bRpk9K5c2fFyspKCQ0NVT777DPlmWeeUaytrSt4ClccPXpUiYyMVOzt7RV3d3fl4YcfNgz5vHp46fjx4xU7O7syx5cXe1pamjJ27FjF0dFRcXJyUsaOHavs37+/ykN0S/36668KoPj4+JQZFqvX65U333xTCQwMVLRardK5c2dlzZo1Zf45KErlQ3QVRVF0Op0yZ84cxcfHR7GxsVH69++vHDlypMzzLigoUJ555hlDud69eyvbt29X+vXrp/Tr18/ouj/99JPStm1bw3Dp0nsvL8bs7GzlqaeeUnx9fRVLS0slLCxMefvtt42GDJfeS1X/Lq5V+jdZ0fbVV18piqIoKSkpyoMPPqi4u7srVlZWSocOHcr8c/v++++VgQMHKp6enoqVlZUSEBCgPPLII0pSUpKhzOuvv650795dcXZ2VmxsbJTWrVsrb7zxhlJUVHTdOMWNT6Mojeh/5YQQdS4qKkqGRwohGiXpEyLEDeTaKdZPnjzJb7/9Rv/+/U0TkBBCXIfUhAhxA/Hx8WHChAmEhIQQHx/PokWLKCwsZP/+/WXmvhBCCFOTjqlC3EAGDx7Mt99+S3JyMlqtlp49e/Lmm29KAiKEaJSkJkQIIYQQJiF9QoQQQghhEpKECCGEEMIkpE9IOfR6PYmJiTg4OFRrymUhhBCiuVMUhezsbHx9fcssgHgtSULKkZiYiL+/v6nDEEIIIZqss2fP4ufnd90ykoSUo3Q64rNnz+Lo6GjiaIQQQoimIysrC39/f6NFGCsiSUg5SptgHB0dJQkRQgghaqAq3RlM2jF10aJFdOzY0fBj37Nnz+uu+Pnf//6XPn364OLigouLC5GRkezatcuozIQJE9BoNEbb4MGD6/tWhBBCCFFNJk1C/Pz8mDdvHnv37mXPnj3ceuutjBgxgn/++afc8jExMYwePZrNmzezfft2/P39GThwYJmlswcPHkxSUpJh+/bbbxvidoQQQghRDY1usjJXV1fefvttJk6cWGlZnU6Hi4sLCxcuZNy4cYBaE5KRkcHq1atrHENWVhZOTk5kZmZKc4wQQghRDdX5DW00fUJ0Oh0rV64kNzeXnj17VumYvLw8iouLcXV1NdofExODp6cnLi4u3Hrrrbz++uu4ublVeJ7CwkIKCwsNn7Oysmp2E0II0YjodDqKi4tNHYa4wZibm2NhYVEnU1iYPAk5fPgwPXv2pKCgAHt7e1atWkXbtm2rdOzzzz+Pr68vkZGRhn2DBw9m5MiRBAcHc+rUKV588UWGDBnC9u3bMTc3L/c80dHRzJkzp07uRwghGoOcnBzOnTtHI6vsFjcIW1tbfHx8sLKyqtV5TN4cU1RUREJCApmZmXz//fd89tlnbNmypdJEZN68ecyfP5+YmBg6duxYYbnTp08TGhrKxo0bue2228otU15NiL+/vzTHCCGaJJ1Ox8mTJ7G1tcXDw0MmXRR1RlEUioqKuHDhAjqdjrCwsDITkjWp5hgrKytatmwJQJcuXdi9ezcffvghn3zySYXHvPPOO8ybN4+NGzdeNwEBCAkJwd3dndjY2AqTEK1Wi1arrflNCCFEI1JcXIyiKHh4eGBjY2PqcMQNxsbGBktLS+Lj4ykqKsLa2rrG5zJ5EnItvV5vVCtxrfnz5/PGG2+wfv16unbtWun5zp07R1paGj4+PnUZphBCNHpSAyLqS2XTsVeVSZOQmTNnMmTIEAICAsjOzmb58uXExMSwfv16AMaNG0eLFi2Ijo4G4K233mLWrFksX76coKAgkpOTAbC3t8fe3p6cnBzmzJnD3Xffjbe3N6dOneK5556jZcuWDBo0yGT3KYQQQoiyTJqEpKamMm7cOJKSknBycqJjx46sX7+e22+/HYCEhASjbGvRokUUFRVxzz33GJ3n1VdfZfbs2Zibm3Po0CG+/PJLMjIy8PX1ZeDAgbz22msmb275+9RFUrIKuL2tN/baRlcBJYQQQjQ4k/4afv7559f9PiYmxujzmTNnrlvexsbGUIvS2Dzx7X4u5hTx6xMOtPN1MnU4QgjRLAQFBTF9+nSmT59epfIxMTEMGDCAS5cu4ezsXK+xCRPPmNqceDqoHXdSsyvu7yKEEM3VtcttXLvNnj27RufdvXs3kydPrnL5Xr16GWrn61NMTAwajYaMjIx6vU5jJ+0CDcTTUcvRJEjNKjB1KEII0egkJSUZ3n/33XfMmjWLEydOGPbZ29sb3iuKgk6nw8Ki8p8wDw+PasVhZWWFt7d3tY4RNSc1IQ3E00Htk5KaJTUhQoiGpSgKeUUlJtmqOhWVt7e3YXNyckKj0Rg+Hz9+HAcHB9auXUuXLl3QarX89ddfnDp1ihEjRuDl5YW9vT3dunVj48aNRucNCgrigw8+MHzWaDR89tln3HXXXdja2hIWFsbPP/9s+P7aGoqlS5fi7OzM+vXradOmDfb29ob1yUqVlJTwxBNP4OzsjJubG88//zzjx48nKiqqxv/MLl26xLhx43BxccHW1pYhQ4Zw8uRJw/fx8fEMHz4cFxcX7OzsaNeuHb/99pvh2DFjxhiGaIeFhbFkyZIax1KfpCakgXg5SnOMEMI08ot1tJ1lmv5yR+cOwtaqbn5qXnjhBd555x1CQkJwcXHh7NmzDB06lDfeeAOtVsuyZcsYPnw4J06cICAgoMLzzJkzh/nz5/P222+zYMECxowZQ3x8fJklQErl5eXxzjvv8NVXX2FmZsYDDzzAjBkz+OabbwB15OY333zDkiVLaNOmDR9++CGrV69mwIABNb7XCRMmcPLkSX7++WccHR15/vnnGTp0KEePHsXS0pKpU6dSVFTE1q1bsbOz4+jRo4baoldeeYWjR4+ydu1awzxZ+fn5NY6lPkkS0kBKa0JSpDlGCCFqZO7cuYbRk6AueBoREWH4/Nprr7Fq1Sp+/vlnpk2bVuF5JkyYwOjRowF48803+eijj9i1axeDBw8ut3xxcTGLFy8mNDQUgGnTpjF37lzD9wsWLGDmzJncddddACxcuNBQK1ETpcnHtm3b6NWrFwDffPMN/v7+rF69mnvvvZeEhATuvvtuOnToAKgTc5ZKSEigc+fOhrm0goKCahxLfZMkpIF4SMdUIYSJ2Fiac3SuaeZKsrEsf82umrh2gsqcnBxmz57Nr7/+SlJSEiUlJeTn55OQkHDd81w907adnR2Ojo6kpqZWWN7W1taQgAD4+PgYymdmZpKSkkL37t0N35ubm9OlSxf0en217q/UsWPHsLCwoEePHoZ9bm5uhIeHc+zYMQCeeOIJpkyZwu+//05kZCR333234b6mTJnC3Xffzb59+xg4cCBRUVGGZKaxkT4hDcTLUa0JuSBJiBCigWk0GmytLEyy1eWsrXZ2dkafZ8yYwapVq3jzzTf5888/OXDgAB06dKCoqOi657G0tCzzfK6XMJRX3tQLA06aNInTp08zduxYDh8+TNeuXVmwYAEAQ4YMIT4+nqeeeorExERuu+02ZsyYYdJ4KyJJSAPxNPQJKTD5H68QQtwItm3bxoQJE7jrrrvo0KED3t7elc4nVdecnJzw8vJi9+7dhn06nY59+/bV+Jxt2rShpKSEnTt3GvalpaVx4sQJo8Vd/f39efTRR/nxxx955pln+O9//2v4zsPDg/Hjx/P111/zwQcf8Omnn9Y4nvokzTENxMNerQkp1ilcyivG1a52yx8LIURzFxYWxo8//sjw4cPRaDS88sorNW4CqY3HH3+c6OhoWrZsSevWrVmwYAGXLl2qUi3Q4cOHcXBwMHzWaDREREQwYsQIHn74YT755BMcHBx44YUXaNGiBSNGjABg+vTpDBkyhFatWnHp0iU2b95MmzZtAJg1axZdunShXbt2FBYWsmbNGsN3jY0kIQ3EysIMVzsr0nOLSM0ukCRECCFq6b333uOhhx6iV69euLu78/zzz5OVldXgcTz//PMkJyczbtw4zM3NmTx5MoMGDcLcvPL+MH379jX6bG5uTklJCUuWLOHJJ5/kjjvuoKioiL59+/Lbb78ZmoZ0Oh1Tp07l3LlzODo6MnjwYN5//31Anetk5syZnDlzBhsbG/r06cOKFSvq/sbrgEaRtoEysrKycHJyIjMzE0dHxzo77+APtnI8OZsvH+pOv1bVm0BHCCGqqqCggLi4OIKDg2u1zLqoGb1eT5s2bbjvvvt47bXXTB1Ovbje31h1fkOlJqQBeThoOZ6cLbOmCiHEDSQ+Pp7ff/+dfv36UVhYyMKFC4mLi+M///mPqUNr9KRjagOSCcuEEOLGY2ZmxtKlS+nWrRu9e/fm8OHDbNy4sdH2w2hMpCakAV2Zul1qQoQQ4kbh7+/Ptm3bTB1GkyQ1IQ3IkIRITYgQQgghSUhDkuYYIYQQ4gpJQhqQp6OsHyOEEEKUkiSkAXletX6MjIwWQgjR3EkS0oA8LvcJKSrRk5VfYuJohBBCCNOSJKQBWVua42SjznaXki1NMkIIIZo3SUIa2JVhutI5VQgh6lr//v2ZPn264XNQUBAffPDBdY/RaDSsXr261teuq/M0J5KENDCvq1bTFUIIoRo+fDiDBw8u97s///wTjUbDoUOHqn3e3bt3M3ny5NqGZ2T27Nl06tSpzP6kpCSGDBlSp9e61tKlS3F2dq7XazQkSUIaWGlNSIrUhAghhMHEiRPZsGED586dK/PdkiVL6Nq1Kx07dqz2eT08PLC1ta2LECvl7e2NVqttkGvdKCQJaWAejqUTlklNiBCigSgKFOWaZqviSMA77rgDDw8Pli5darQ/JyeHlStXMnHiRNLS0hg9ejQtWrTA1taWDh068O233173vNc2x5w8eZK+fftibW1N27Zt2bBhQ5ljnn/+eVq1aoWtrS0hISG88sorFBcXA2pNxJw5czh48CAajQaNRmOI+drmmMOHD3PrrbdiY2ODm5sbkydPJicnx/D9hAkTiIqK4p133sHHxwc3NzemTp1quFZNJCQkMGLECOzt7XF0dOS+++4jJSXF8P3BgwcZMGAADg4OODo60qVLF/bs2QOoa+AMHz4cFxcX7OzsaNeuHb/99luNY6kKmba9gXk5yIRlQogGVpwHb/qa5tovJoKVXaXFLCwsGDduHEuXLuWll15Co9EAsHLlSnQ6HaNHjyYnJ4cuXbrw/PPP4+joyK+//srYsWMJDQ2le/fulV5Dr9czcuRIvLy82LlzJ5mZmUb9R0o5ODiwdOlSfH19OXz4MA8//DAODg4899xzjBo1iiNHjrBu3To2btwIgJOTU5lz5ObmMmjQIHr27Mnu3btJTU1l0qRJTJs2zSjR2rx5Mz4+PmzevJnY2FhGjRpFp06dePjhhyu9n/LurzQB2bJlCyUlJUydOpVRo0YRExMDwJgxY+jcuTOLFi3C3NycAwcOYGmpDpiYOnUqRUVFbN26FTs7O44ePYq9vX2146gOk9aELFq0iI4dO+Lo6IijoyM9e/Zk7dq11z1m5cqVtG7dGmtrazp06FAmS1MUhVmzZuHj44ONjQ2RkZGcPHmyPm+jWkonLJP1Y4QQwthDDz3EqVOn2LJli2HfkiVLuPvuu3FycqJFixbMmDGDTp06ERISwuOPP87gwYP53//+V6Xzb9y4kePHj7Ns2TIiIiLo27cvb775ZplyL7/8Mr169SIoKIjhw4czY8YMwzVsbGywt7fHwsICb29vvL29sbGxKXOO5cuXU1BQwLJly2jfvj233norCxcu5KuvvjKqmXBxcWHhwoW0bt2aO+64g2HDhrFp06bqPjoANm3axOHDh1m+fDldunShR48eLFu2jC1btrB7925ArSmJjIykdevWhIWFce+99xIREWH4rnfv3nTo0IGQkBDuuOMO+vbtW6NYqsqkNSF+fn7MmzePsLAwFEXhyy+/ZMSIEezfv5927dqVKf/3338zevRooqOjueOOO1i+fDlRUVHs27eP9u3bAzB//nw++ugjvvzyS4KDg3nllVcYNGgQR48exdrauqFvsQxPqQkRQjQ0S1u1RsJU166i1q1b06tXL7744gv69+9PbGwsf/75J3PnzgVAp9Px5ptv8r///Y/z589TVFREYWFhlft8HDt2DH9/f3x9r9QK9ezZs0y57777jo8++ohTp06Rk5NDSUkJjo6OVb6P0mtFRERgZ3elFqh3797o9XpOnDiBl5cXAO3atcPc3NxQxsfHh8OHD1frWldf09/fH39/f8O+tm3b4uzszLFjx+jWrRtPP/00kyZN4quvviIyMpJ7772X0NBQAJ544gmmTJnC77//TmRkJHfffXeN+uFUh0lrQoYPH87QoUMJCwujVatWvPHGG9jb27Njx45yy3/44YcMHjyYZ599ljZt2vDaa69x0003sXDhQkCtBfnggw94+eWXGTFiBB07dmTZsmUkJiY2mmFTXo5XhujKrKlCiAah0ahNIqbYLjerVNXEiRP54YcfyM7OZsmSJYSGhtKvXz8A3n77bT788EOef/55Nm/ezIEDBxg0aBBFRUV19qi2b9/OmDFjGDp0KGvWrGH//v289NJLdXqNq5U2hZTSaDTo9fp6uRaoI3v++ecfhg0bxh9//EHbtm1ZtWoVAJMmTeL06dOMHTuWw4cP07VrVxYsWFBvsUAj6piq0+lYsWIFubm55WamoP5xREZGGu0bNGgQ27dvByAuLo7k5GSjMk5OTvTo0cNQpjyFhYVkZWUZbfWltCYkv1hHdqHMmiqEEFe77777MDMzY/ny5SxbtoyHHnrI0D9k27ZtjBgxggceeICIiAhCQkL4999/q3zuNm3acPbsWZKSkgz7rv2f3r///pvAwEBeeuklunbtSlhYGPHx8UZlrKys0Ol0lV7r4MGD5ObmGvZt27YNMzMzwsPDqxxzdZTe39mzZw37jh49SkZGBm3btjXsa9WqFU899RS///47I0eOZMmSJYbv/P39efTRR/nxxx955pln+O9//1svsZYyeRJy+PBh7O3t0Wq1PProo6xatcroYV0tOTnZUIVVysvLi+TkZMP3pfsqKlOe6OhonJycDNvVVVl1zcbKHAet2gomE5YJIYQxe3t7Ro0axcyZM0lKSmLChAmG78LCwtiwYQN///03x44d45FHHjHqX1GZyMhIWrVqxfjx4zl48CB//vknL730klGZsLAwEhISWLFiBadOneKjjz4y1BSUCgoKIi4ujgMHDnDx4kUKC8v+t3zMmDFYW1szfvx4jhw5wubNm3n88ccZO3Zsmd+o6tLpdBw4cMBoO3bsGJGRkXTo0IExY8awb98+du3axbhx4+jXrx9du3YlPz+fadOmERMTQ3x8PNu2bWP37t20adMGgOnTp7N+/Xri4uLYt28fmzdvNnxXX0yehISHh3PgwAF27tzJlClTGD9+PEePHm3QGGbOnElmZqZhuzqLrA+eMkxXCCEqNHHiRC5dusSgQYOM+m+8/PLL3HTTTQwaNIj+/fvj7e1NVFRUlc9rZmbGqlWryM/Pp3v37kyaNIk33njDqMydd97JU089xbRp0+jUqRN///03r7zyilGZu+++m8GDBzNgwAA8PDzKHSZsa2vL+vXrSU9Pp1u3btxzzz3cdttthu4DtZGTk0Pnzp2NtuHDh6PRaPjpp59wcXGhb9++REZGEhISwnfffQeAubk5aWlpjBs3jlatWnHfffcxZMgQ5syZA6jJzdSpU2nTpg2DBw+mVatW/N///V+t470ejdLIOiZERkYSGhrKJ598Uua7gIAAnn76aaMhVa+++iqrV6/m4MGDnD59mtDQUPbv3280m12/fv3o1KkTH374YZViyMrKwsnJiczMzGp3RqqK0Z/uYPvpND4Y1Ymozi3q/PxCiOatoKCAuLg4goODG0WHfHHjud7fWHV+Q01eE3ItvV5fbtUWqL2Yrx26tGHDBkMfkuDgYLy9vY3KZGVlsXPnzgr7mZiC1IQIIYQQJh6iO3PmTIYMGUJAQADZ2dksX76cmJgY1q9fD8C4ceNo0aIF0dHRADz55JP069ePd999l2HDhrFixQr27NnDp59+Cqi9iqdPn87rr79OWFiYYYiur69vtars6pth/RjpEyKEEKIZM2kSkpqayrhx40hKSsLJyYmOHTuyfv16br/9dkCdOMXM7EplTa9evVi+fDkvv/wyL774ImFhYaxevdowRwjAc889R25uLpMnTyYjI4NbbrmFdevWNaoqScP6MTJXiBBCiGas0fUJaQzqu0/ITwfO8+SKA/QIduW7RxpPM5EQ4sYgfUJEfbth+4Q0B6XNMRekJkQIUY/k/zFFfamrvy1JQkzA0Bwj68cIIepB6TTg9TXLpxB5eXlA2Rlfq0tW0TUBz8s1IblFOnILS7DTyj8GIUTdsbCwwNbWlgsXLmBpaWnUt06I2lAUhby8PFJTU3F2djZa96Ym5NfPBOy1FthZmZNbpCM1u5BgSUKEEHVIo9Hg4+NDXFxcmSnHhagLzs7OeHt71/o88utnIp6O1sRdzCUlq4Bgd7vKDxBCiGqwsrIiLCxMmmREnbO0tKx1DUgpSUJMxMNBS9zFXFKlc6oQop6YmZnJ6BjRqElDoYlcmbBMOqcKIYRoniQJMZHSETJSEyKEEKK5kiTERAxJiNSECCGEaKYkCTERQ3OM1IQIIYRopiQJMRGZsEwIIURzJ0mIiXg6Sp8QIYQQzZskISZSOmtqdkEJ+UU6E0cjhBBCNDxJQkzEQWuBtaX6+FOzpUlGCCFE8yNJiIloNBo8HaRzqhBCiOZLkhAT8irtF5IlSYgQQojmR5IQEyqtCZERMkIIIZojSUJMyENmTRVCCNGMSRJiQlcmLJOaECGEEM2PJCEmdGXqdqkJEUII0fxIEmJCVyYsk5oQIYQQzY8kISYk68cIIYRoziQJMaHS5piMvGIKimXWVCGEEM2LJCEm5GRjiZWF+o/ggtSGCCGEaGYkCTEhddZUGaYrhBCieTJpEhIdHU23bt1wcHDA09OTqKgoTpw4cd1j+vfvj0ajKbMNGzbMUGbChAllvh88eHB9306NXBkhI51ThRBCNC8Wprz4li1bmDp1Kt26daOkpIQXX3yRgQMHcvToUezs7Mo95scff6SoqMjwOS0tjYiICO69916jcoMHD2bJkiWGz1qttn5uopZk/RghhBDNlUmTkHXr1hl9Xrp0KZ6enuzdu5e+ffuWe4yrq6vR5xUrVmBra1smCdFqtXh7e9dtwPXAS4bpCiGEaKYaVZ+QzMxMoGyicT2ff/45999/f5mak5iYGDw9PQkPD2fKlCmkpaVVeI7CwkKysrKMtobi6Vi6fozUhAghhGheGk0SotfrmT59Or1796Z9+/ZVOmbXrl0cOXKESZMmGe0fPHgwy5YtY9OmTbz11lts2bKFIUOGoNOVPww2OjoaJycnw+bv71/r+6kqWT9GCCFEc6VRFEUxdRAAU6ZMYe3atfz111/4+flV6ZhHHnmE7du3c+jQoeuWO336NKGhoWzcuJHbbrutzPeFhYUUFl5JArKysvD39yczMxNHR8fq3Ug1bfn3AuO/2EVrbwfWTS+/CUoIIYRoKrKysnBycqrSb2ijqAmZNm0aa9asYfPmzVVOQHJzc1mxYgUTJ06stGxISAju7u7ExsaW+71Wq8XR0dFoaygyRFcIIURzZdIkRFEUpk2bxqpVq/jjjz8IDg6u8rErV66ksLCQBx54oNKy586dIy0tDR8fn9qEWy9Kk5D03CKKSvQmjkYIIYRoOCZNQqZOncrXX3/N8uXLcXBwIDk5meTkZPLz8w1lxo0bx8yZM8sc+/nnnxMVFYWbm5vR/pycHJ599ll27NjBmTNn2LRpEyNGjKBly5YMGjSo3u+pulxsrbA01wBwMUdqQ4QQQjQfJk1CFi1aRGZmJv3798fHx8ewfffdd4YyCQkJJCUlGR134sQJ/vrrr3KbYszNzTl06BB33nknrVq1YuLEiXTp0oU///yzUc4VYmamwcNejStFJiwTQgjRjJh0npCq9ImNiYkpsy88PLzCY21sbFi/fn1tQ2tQHo7WJGYWSL8QIYQQzUqj6Jja3HlJ51QhhBDNkCQhjYCno6wfI4QQovmRJKQRMKwfI7OmCiGEaEYkCWkEZP0YIYQQzZEkIY1AaU2IrB8jhBCiOZEkpBGQ9WOEEEI0R5KENAJel1fSTcstpEQns6YKIYRoHiQJaQTc7KwwN9OgKHAxp8jU4QghhBANQpKQRsDMTIO7vRUgnVOFEEI0H5KENBKlTTIyTFcIIURzIUlII1G6mm6K1IQIIYRoJiQJaSQ8ZMIyIYQQzYwkIY3ElQnLJAkRQgjRPEgS0hAUBc7vg39WQ3F+uUWuTN0uzTFCCCGaB0lCGoJGA1+PhJXjIe1UuUVKa0KSJQkRQgjRTEgS0lBcgtTXjPhyvw71sAfgZEoOBcW6BgpKCCGEMB1JQhqKc6D6eqn8JCTQzRZ3ey1FOj2Hz2c2YGBCCCGEaUgS0lBcSpOQM+V+rdFo6BbkAsDuM+kNFJQQQghhOpKENJTSmpAKmmMAuga5ArDnzKWGiEgIIYQwKUlCGkppn5AKmmMAQ03I3vhL6PVKAwQlhBBCmI4kIQ3l6o6pSvkJRlsfR2ytzMnMLyb2Qk7DxSaEEEKYgCQhDcXJD9BAcR7kXii3iIW5GZ38nQHpFyKEEOLGJ0lIQ7HQgmML9f11mmSkX4gQQojmQpKQhuRSeedUGSEjhBCiuZAkpCEZ5gqJq7BI5wAXzDRw7lI+SZnlT/EuhBBC3AhMmoRER0fTrVs3HBwc8PT0JCoqihMnTlz3mKVLl6LRaIw2a2trozKKojBr1ix8fHywsbEhMjKSkydP1uetVI3L9ScsA7DXWtDW1xGQJhkhhBA3NpMmIVu2bGHq1Kns2LGDDRs2UFxczMCBA8nNzb3ucY6OjiQlJRm2+HjjH/X58+fz0UcfsXjxYnbu3ImdnR2DBg2ioMDE67JUMnV7qa6Bpf1CpElGCCHEjcvClBdft26d0eelS5fi6enJ3r176du3b4XHaTQavL29y/1OURQ++OADXn75ZUaMGAHAsmXL8PLyYvXq1dx///11dwPV5Xz9WVNLdQtyZenfZ9gTLzUhQgghblyNqk9IZqa6Zoqrq+t1y+Xk5BAYGIi/vz8jRozgn3/+MXwXFxdHcnIykZGRhn1OTk706NGD7du3l3u+wsJCsrKyjLZ6Udock3kedCUVFut6uXPqsaQssguK6ycWIYQQwsQaTRKi1+uZPn06vXv3pn379hWWCw8P54svvuCnn37i66+/Rq/X06tXL86dOwdAcnIyAF5eXkbHeXl5Gb67VnR0NE5OTobN39+/ju7qGvbeYK4FRQdZ5yos5uVojb+rDXoF9idk1E8sQgghhIk1miRk6tSpHDlyhBUrVly3XM+ePRk3bhydOnWiX79+/Pjjj3h4ePDJJ5/U+NozZ84kMzPTsJ09e7bG57ouMzNwDlDfX6dzKkA36RcihBDiBtcokpBp06axZs0aNm/ejJ+fX7WOtbS0pHPnzsTGxgIY+oqkpKQYlUtJSamwH4lWq8XR0dFoqzeVrKZbqnTSst0yQkYIIcQNyqRJiKIoTJs2jVWrVvHHH38QHBxc7XPodDoOHz6Mj48PAMHBwXh7e7Np0yZDmaysLHbu3EnPnj3rLPYaq8JqunBl0rL9Zy9RrNPXd1RCCCFEgzPp6JipU6eyfPlyfvrpJxwcHAx9NpycnLCxsQFg3LhxtGjRgujoaADmzp3LzTffTMuWLcnIyODtt98mPj6eSZMmAerImenTp/P6668TFhZGcHAwr7zyCr6+vkRFRZnkPo1UYTVdgFAPe5xtLcnIK+afxCzDmjJCCCHEjcKkSciiRYsA6N+/v9H+JUuWMGHCBAASEhIwM7tSYXPp0iUefvhhkpOTcXFxoUuXLvz999+0bdvWUOa5554jNzeXyZMnk5GRwS233MK6devKTGpmElVsjjEz09AlwIVNx1PZcyZdkhAhhBA3HI2iVLCufDOWlZWFk5MTmZmZdd8/JPEAfNoP7Dzg2djrFl0Uc4q31h1ncDtvFo/tUrdxCCGEEPWgOr+hjaJjarNS2hyTewGKrj8zbGm/kD3x6UiuKIQQ4kYjSUhDs3EGayf1fSX9Qjr4OWFlYcbFnCLOpOXVf2xCCCFEA5IkxBSqOEJGa2FOhJ+asOyW+UKEEELcYCQJMYUqrKZbqnS+EJm0TAghxI1GkhBTqOJqunBVvxCZtEwIIcQNRpIQU6jiaroANwWoScjpi7lczCmsx6CEEEKIhiVJiClUccIyAGdbK1p52QNSGyKEEOLGIkmIKVzdHFOFobel/UL2xku/ECGEEDcOSUJMwclffS3Kgby0SouX9guRxeyEEELcSCQJMQVLa3BQF9yr0giZQLUm5Mj5TPKLdPUZmRBCCNFgJAkxFUOTzJlKi/q52ODtaE2JXuHA2Yz6jEoIIYRoMJKEmIpz1ecK0Wg0dDEM1ZV+IUIIIW4MkoSYShVX0y3VLfByv5B46RcihBDixiBJiKlUcer2UqUjZPbFX0Knl8XshBBCNH2ShJhKNeYKAWjt7YC91oKcwhKOJ2fVX1xCCCFEA5EkxFRKm2Myz4K+8hEvFuZmdA5wBuDv2MqH9QohhBCNnSQhpuLgA2aWoC+BrPNVOmRgWy8Avt2dgFKFSc6EEEKIxkySEFMxMwfnAPV9FZtkojq3wM7KnNMXctkmtSFCCCGaOElCTMmlep1THawtubuLHwDLtp+pp6CEEEKIhiFJiClVYzXdUmNvVo/ZeCyF8xn59RCUEEII0TBqlIScPXuWc+fOGT7v2rWL6dOn8+mnn9ZZYM2CS9UnLCsV5uVAzxA39Aos31n144QQQojGpkZJyH/+8x82b94MQHJyMrfffju7du3ipZdeYu7cuXUa4A3t6tV0q2FcTzV5WbHrLIUlspaMEEKIpqlGSciRI0fo3r07AP/73/9o3749f//9N9988w1Lly6ty/hubDVojgG4va0X3o7WpOUW8dvhpLqPSwghhGgANUpCiouL0Wq1AGzcuJE777wTgNatW5OUJD+KVVZaE5KTAsVV799hYW7GmB7qyJpl26VJRgghRNNUoySkXbt2LF68mD///JMNGzYwePBgABITE3Fzc6vTAG9oNi6gdVTfZyRU69D7uwdgaa5hf0IGR85n1kNwQgghRP2qURLy1ltv8cknn9C/f39Gjx5NREQEAD///LOhmaYqoqOj6datGw4ODnh6ehIVFcWJEyeue8x///tf+vTpg4uLCy4uLkRGRrJr1y6jMhMmTECj0RhtpYlSo6LR1LhJxsNBy5D2PoAM1xVCCNE01SgJ6d+/PxcvXuTixYt88cUXhv2TJ09m8eLFVT7Pli1bmDp1Kjt27GDDhg0UFxczcOBAcnNzKzwmJiaG0aNHs3nzZrZv346/vz8DBw7k/HnjWUcHDx5MUlKSYfv222+rf6MNoQYjZEqVdlD96UAiGXlFdRmVEEIIUe8sanJQfn4+iqLg4qIuLx8fH8+qVato06YNgwYNqvJ51q1bZ/R56dKleHp6snfvXvr27VvuMd98843R588++4wffviBTZs2MW7cOMN+rVaLt7d3lWMxmWqupnu1LoEutPFx5FhSFiv3nOPhviF1HJwQQghRf2pUEzJixAiWLVsGQEZGBj169ODdd98lKiqKRYsW1TiYzEy1b4Orq2uVj8nLy6O4uLjMMTExMXh6ehIeHs6UKVNIS6t4mvPCwkKysrKMtgZjWE33TLUP1Wg0jL9cG/LVjnj0ellPRgghRNNRoyRk37599OnTB4Dvv/8eLy8v4uPjWbZsGR999FGNAtHr9UyfPp3evXvTvn37Kh/3/PPP4+vrS2RkpGHf4MGDWbZsGZs2beKtt95iy5YtDBkyBJ2u/Dk1oqOjcXJyMmz+/v41uocaqUVzDMCITi1wtLYgIT2PLf9eqMPAhBBCiPpVoyQkLy8PBwcHAH7//XdGjhyJmZkZN998M/HxNfsxnTp1KkeOHGHFihVVPmbevHmsWLGCVatWYW1tbdh///33c+edd9KhQweioqJYs2YNu3fvJiYmptzzzJw5k8zMTMN29uzZGt1DjVzdHFODlXFtrMy5t6uaNEkHVSGEEE1JjZKQli1bsnr1as6ePcv69esZOHAgAKmpqTg6Olb7fNOmTWPNmjVs3rwZPz+/Kh3zzjvvMG/ePH7//Xc6dux43bIhISG4u7sTGxtb7vdarRZHR0ejrcGUrqRbmAX5l2p0igcurycT8+8FEtLy6ioyIYQQol7VKAmZNWsWM2bMICgoiO7du9OzZ09ArRXp3Llzlc+jKArTpk1j1apV/PHHHwQHB1fpuPnz5/Paa6+xbt06unbtWmn5c+fOkZaWho+PT5VjazBWtmDvpb6vQb8QgGB3O/q28kBR4GtZT0YIIUQTUaMk5J577iEhIYE9e/awfv16w/7bbruN999/v8rnmTp1Kl9//TXLly/HwcGB5ORkkpOTyc+/MnvouHHjmDlzpuHzW2+9xSuvvMIXX3xBUFCQ4ZicnBwAcnJyePbZZ9mxYwdnzpxh06ZNjBgxgpYtW1Zr5E6DqsUImVKlHVS/232W/CJZT0YIIUTjV6MkBMDb25vOnTuTmJhoWFG3e/futG7dusrnWLRoEZmZmfTv3x8fHx/D9t133xnKJCQkGE0Fv2jRIoqKirjnnnuMjnnnnXcAMDc359ChQ9x55520atWKiRMn0qVLF/7880/DVPONjmGETM2TkP7hnvi52JCZX8wvBxPrJi4hhBCiHtVonhC9Xs/rr7/Ou+++a6iBcHBw4JlnnuGll17CzKxquY1ShY6Y13YmPXPmzHXL29jYGNXONAkuta8JMTfT8MDNgcxbe5xlO85wb1c/NBpNHQUohBBC1L0a1YS89NJLLFy4kHnz5rF//37279/Pm2++yYIFC3jllVfqOsYbXw2nbr/WqK7+aC3MOHI+i9+PptQ+LiGEEKIe1agm5Msvv+Szzz4zrJ4L0LFjR1q0aMFjjz3GG2+8UWcBNgu1nCvEcBo7Kyb1Cebjzad449dj9GvlgbWleR0EKIQQQtS9GtWEpKenl9v3o3Xr1qSnp9c6qGantE9I5lnQ165T6WP9W+LlqCUhPY/P/4qrfWxCCCFEPalREhIREcHChQvL7F+4cGGlc3aIcji2ADML0BVBdlLl5a/DTmvBzCFtAPh4cyzJmQV1EaEQQghR52rUHDN//nyGDRvGxo0bDXOEbN++nbNnz/Lbb7/VaYDNgpk5OPmpfUIuxavva2FEJ1+WbT/DvoQM5q87znujOtVJmEIIIURdqlFNSL9+/fj333+56667yMjIICMjg5EjR/LPP//w1Vdf1XWMzUNpk0wtRsiU0mg0zL6zHRoN/Lj/PPsSajYTqxBCCFGfNEpVxslW0cGDB7npppsqXCiuqcjKysLJyYnMzMyGm8L95ydg35fQ73kY8GKdnPK57w/yvz3niPBzYtVjvTEzkyG7Qggh6ld1fkNrPFmZqGN1NELmajMGhWOvteDguUx+2Heuzs4rhBBC1AVJQhqLOpor5GqeDtY8cVtLAN5ad4LsguI6O7cQQghRW5KENBZe7dTXpANQlFtnp53QK5hgdzsu5hSy8I/yVxEWQgghTKFao2NGjhx53e8zMjJqE0vz5tEanAMgIwFObYY2d9TJaa0szHjljjY8tHQPX2yL4/7uAQS729XJuYUQQojaqFZNiJOT03W3wMBAxo0bV1+x3tg0Gggfpr4/UbfDnG9t7UX/cA+KdQqvrzlap+cWQgghaqpaNSFLliyprzgEQOuhsHMR/LtOnTnVrO6mXH/ljrb8dXIrm46nEnMilf7hnnV2biGEEKImpE9IYxLQC6ydIS8Nzu6s01OHetgzoVcQAHPXHKVYp6/T8wshhBDVJUlIY2JuAa0Gq++P/1rnp38iMgx3eytOX8hl6bYzdX5+IYQQojokCWlsWg9VX4//CnU3jxwAjtaWPDsoHIC3fz/BsaSsOj2/EEIIUR2ShDQ2obeBuRYuxcGF43V++vu6+jMg3IOiEj2Pf7ufvKKSOr+GEEIIURWShDQ2WnsI6ae+r4cmGY1Gwzv3RuDpoCU2NYe5v8hoGSGEEKYhSUhjFH65SaaOh+qWcrPX8sGoTmg0sGL3WX45mFgv1xFCCCGuR5KQxih8KKCB83shK6leLtGrpTuP9Q8F4MUfD3M2Pa9eriOEEEJURJKQxsjBC/y6qu/rqTYEYHpkK24KcCa7sIQnVuyXYbtCCCEalCQhjVU9N8kAWJqb8eH9nXGwtmB/Qgbvb/i33q4lhBBCXEuSkMaq9eUp3OO2QmF2vV3G39WWeSM7ArBoyym2xV6st2sJIYQQV5MkpLFybwWuoaArgtiN9XqpYR19GN3dH0WB6d8d4GJOYb1eTwghhABJQhovjeaqicvqr0mm1Kw72hHmac+F7EJmrDyIXl+3E6UJIYQQ1zJpEhIdHU23bt1wcHDA09OTqKgoTpw4UelxK1eupHXr1lhbW9OhQwd++834R1pRFGbNmoWPjw82NjZERkZy8uTJ+rqN+tP6DvX15HrQFdfrpWyszFnwn85oLcyIOXGBL7bF1ev1hBBCCJMmIVu2bGHq1Kns2LGDDRs2UFxczMCBA8nNza3wmL///pvRo0czceJE9u/fT1RUFFFRURw5csRQZv78+Xz00UcsXryYnTt3Ymdnx6BBgygoKGiI26o7ft3A1h0KMiF+W71frrW3Iy/f0RaAt9Yd54/jKfV+TSGEEM2XRlHqeIGSWrhw4QKenp5s2bKFvn37lltm1KhR5ObmsmbNGsO+m2++mU6dOrF48WIURcHX15dnnnmGGTNmAJCZmYmXlxdLly7l/vvvrzSOrKwsnJycyMzMxNHRsW5urqZ+mgr7v4buj8DQ+fV+OUVRmLZ8P78eTsJMAy8Pa8uDvYPQaDT1fm0hhBBNX3V+QxtVn5DMzEwAXF1dKyyzfft2IiMjjfYNGjSI7du3AxAXF0dycrJRGScnJ3r06GEoc63CwkKysrKMtkYj/PIomRO/1fmCduXRaDR8cH8n7u/mj16BuWuO8vLqIzKHiBBCiDrXaJIQvV7P9OnT6d27N+3bt6+wXHJyMl5eXkb7vLy8SE5ONnxfuq+iMteKjo7GycnJsPn7+9fmVupWSH+wsIHMs5B8uEEuaWluRvTIDrw0tA0aDXyzM4GHlu4mM79++6UIIYRoXhpNEjJ16lSOHDnCihUrGvzaM2fOJDMz07CdPXu2wWOokJUthN6qvq+HBe0qotFoeLhvCJ880AUbS3P+PHmRkf+3jfi0ivvrCCGEENXRKJKQadOmsWbNGjZv3oyfn991y3p7e5OSYtxhMiUlBW9vb8P3pfsqKnMtrVaLo6Oj0daolE5cdqLhkpBSA9t5s/LRnng7WnPqQi5RH29jV1x6g8chhBDixmPSJERRFKZNm8aqVav4448/CA4OrvSYnj17smnTJqN9GzZsoGfPngAEBwfj7e1tVCYrK4udO3cayjQ5rQaDxkxtjslIaPDLt2/hxE/TetPRz4lLecWM+WwHP+w91+BxCCGEuLGYNAmZOnUqX3/9NcuXL8fBwYHk5GSSk5PJz883lBk3bhwzZ840fH7yySdZt24d7777LsePH2f27Nns2bOHadOmAWozwvTp03n99df5+eefOXz4MOPGjcPX15eoqKiGvsW6YecG/jer70+sNUkIXo7WfDe5J0Pae1OsU3hm5UHeWnccnUxqJoQQooZMmoQsWrSIzMxM+vfvj4+Pj2H77rvvDGUSEhJISrqynH2vXr1Yvnw5n376KREREXz//fesXr3aqDPrc889x+OPP87kyZPp1q0bOTk5rFu3Dmtr6wa9vzplmD214ZtkStlYmfPxf27isf6hACyKOcX4L3aRJtO8CyGEqIFGNU9IY9Go5gkplXYKFtwEZhbwbCzYuJg0nJ8OnOeFHw6TX6zDx8ma/xtzE50DTBuTEEII02uy84SI63ALBY/WoC+BE+tMHQ0jOrVg9dTehLjbkZRZwH2fbOer7WeQnFYIIURVSRLSlLS/W33d/nGDTFxWmXBvB36a1pvB7dR+Iq/89A9PfXeAvKISU4cmhBCiCZAkpCnpNgms7CHlMPy73tTRAOBgbcmiB27ipaFtMDfTsPpAIlEfb+P0hRxThyaEEKKRkySkKbF1hW4T1fdb324UtSFwZWKz5ZN64OGg5d+UHO5cuI11R5IqP1gIIUSzJUlIU9NzGlhYw/k9ELfF1NEY6RHixq+P30L3IFdyCkt49Ot9PLvyIKnZTWz1YiGEEA1CkpCmxt4Tbhqvvt/6jmljKYenozXfPNyDh/uoE8+t3HuOW9/ZwqdbT1FUIovgCSGEuEKSkKao9xNgZgln/oSEHaaOpgxLczNeGtaWH6b0oqOfEzmFJbz523EGfbCVP46nVH4CIYQQzYIkIU2Rkx90Gq2+b4S1IaW6BLqw+rHezL+nI+72WuIu5vLQ0j1MWLKL2FTpuCqEEM2dJCFNVe/p6noysRsg8YCpo6mQmZmG+7r6s3lGPx7pG4KluYaYExcY/MFWXl9zlKyCYlOHKIQQwkQkCWmq3EKh/T3q+z/fNW0sVeBgbcnMoW1YP70vt7X2pESv8NlfcfR/O4aPN8dKMiKEEM2QTNtejkY5bXt5Uo/B/11e2O6xneDZ2rTxVEPMiVReW3OUUxdyAXCwtmB8zyAe7B2Em73WxNEJIYSoKZm2vbnwbANthqvv/3rPtLFUU/9wT9ZP78v7oyII87Qnu6CEhZtjueWtzcz95ShJmfmVn0QIIUSTJjUh5WgyNSEAifvh0/5q/5DH94JriKkjqja9XuH3oyl8vDmWw+czAbA013BPFz8e6RtKkLudiSMUQghRVdX5DZUkpBxNKgkB+PpuiN2ozh9y50emjqbGFEXhz5MX+XhzLDvj0gEw08DQDj483CeECH9n0wYohBCiUpKE1FKTS0ISdsAXg9S5Q548oA7hbeL2nEnn482xbD5xwbCvW5ALE28J4fa2XpibaUwYnRBCiIpIElJLTS4JAVgyDOL/gh6PwpC3TB1NnTmamMVnf53ml4OJFOvUP9VAN1se6h3MPV38sNNamDhCIYQQV5MkpJaaZBJyajN8FaWuKzP9sDq9+w0kJauAL/8+wzc7E8jMV4fzOtlY8p8eAYzvGYS3k7WJIxRCCAGShNRak0xCFAU+uw3O71UnMrt9jqkjqhd5RSX8sPccn/8Vx5m0PAAszDT0bunOsA4+DGznhbOtlYmjFEKI5kuSkFpqkkkIwIm18O39YGUPj20H5wBTR1RvdHqFTcdS+OyvOHZd7sQKkpAIIYSpSRJSS002CVEU+HwgnNsFft3hwd/A3NLUUdW7Uxdy+O1QEr8eTuJ4crZhv4WZhl4t3RnWwZtB7bwlIRFCiAYgSUgtNdkkBODSGVjcFwozoc8zcNssU0fUoCpKSGytzHm4TwiT+4ZIZ1YhhKhHkoTUUpNOQgD+WQUrJwAaGLsKQgeYOiKTOH0hh98OJ/HzwUT+TVFX7XW31/LU7WGM6uqPhblMGCyEEHVNkpBaavJJCMAvT8LepWDvBY/+dcONlqkORVH47XAy89cfJ/5yZ9ZQDzueH9ya29t6odHInCNCCFFXJAmppRsiCSnKg//eCheOQehtMOZ7MGve/+dfVKJn+c54Ptx0kkt56jDf7kGuzBzams4BLkZlFUXhYk4RCem5nLmYR3x6Hnq9wgM3B8pwYCGEuA5JQmrphkhCQF1l99MBUJIPt8+F3k+aOqJGIaugmMUxp/j8rzgKS/QADO3gjb+LLfFpasKRkJZLbpGuzLH2WgtmDGzF2J5BMmurEEKUo8msort161aGDx+Or68vGo2G1atXX7f8hAkT0Gg0ZbZ27doZysyePbvM961bN50l7uuUZxsYMk99v2kunNtj2ngaCUdrS54b3JqYZ/tzbxc/NBr47XAyn2w9zbp/kjmWlEVukQ6NBlo429AzxI37u/nTyd+ZnMISZv9ylLv+bxtHLi+2J4QQomZMOkwgNzeXiIgIHnroIUaOHFlp+Q8//JB58+YZPpeUlBAREcG9995rVK5du3Zs3LjR8NnCohmPhrhpPJyOUTurfv8gPPIn2DibOqpGwcfJhrfvjeChW4L5akc8VuZmBLjaEuRuS4CrHX4uNlhbmhvK6/UKy3cl8Na64xw6l8mdC//iwd7BPH17KxlxI4QQNWDS/3IOGTKEIUOGVLm8k5MTTk5Ohs+rV6/m0qVLPPjgg0blLCws8Pb2rrM4mzSNBoZ/qM6kmpGgdli9d6m6XwDQxseRN+/qUGk5MzMND9wcyMC2Xsxdc5Q1h5L4/K841h5OYs6I9tze1qsBohVCiBtHk+6p+PnnnxMZGUlgYKDR/pMnT+Lr60tISAhjxowhISHhuucpLCwkKyvLaLuhWDvBPUvAzAKOroZ9X5o6oibN09Gahf+5iaUPdsPf1YbEzAIeXraHR77aw9n0PFOHJ4QQTUaTTUISExNZu3YtkyZNMtrfo0cPli5dyrp161i0aBFxcXH06dOH7OzsCs4E0dHRhloWJycn/P396zv8hufX9crEZWufh5Sjpo3nBtA/3JPfp/djSv9QLMw0rP8nhT7zNxP53hZm//wPm46lkFNYUq1zFhTryCoorqeIhRCicWk0o2M0Gg2rVq0iKiqqSuWjo6N59913SUxMxMqq4um4MzIyCAwM5L333mPixInlliksLKSwsNDwOSsrC39//6Y/OuZaej18cw+c2gROAfDgrzf0+jIN6URyNq+tOcrfpy6iv+rfKAszDTcFuHBLmDt9wtzp6OdMUYme+NKhv2m5nEm78j4xswCAEA87ugW60iXIha6BLgS728l8JkKIJqE6o2OaZG86RVH44osvGDt27HUTEABnZ2datWpFbGxshWW0Wi1arbauw2x8zMzgrk9gyWBIi4Uvh8OE38Cphakja/LCvR34elIPMvOK+fvURf6MvchfJy+SkJ7HrjPp7DqTznsb/sXa0oyCYn2l5zt9IZfTF3L5bs9ZANzsrOgS6ELXIBe6BLrS0c8JS5nxVQjRxDXJJGTLli3ExsZWWLNxtZycHE6dOsXYsWMbILImwN4Dxv0MS4eq68x8OVxd6M5BOvLWBSdbS4Z08GFIBx8AEtLy+DP2An/+e5G/T10kq0BtnnG0tiDY3Y5ANzuC3O0IcrMl0M1OrfEA9sZfYk/8JfbGp3PwXCZpuUX8fjSF34+mAODhoGVMjwD+0yMATweZPE0I0TSZtDkmJyfHUEPRuXNn3nvvPQYMGICrqysBAQHMnDmT8+fPs2zZMqPjxo4dy8mTJ9mxY0eZc86YMYPhw4cTGBhIYmIir776KgcOHODo0aN4eHhUKa4bZrKy68lIgCXDIDMB3MNhwq9qgiLqjU6vEHcxFzc7K5xtLavcvFJYouPI+Sz2nElnT/wl9pxJN8z4ammuYVgHH8b3Cioz66sQQphCk5kxNSYmhgEDyi6uNn78eJYuXcqECRM4c+YMMTExhu8yMzPx8fHhww8/5OGHHy5z7P3338/WrVtJS0vDw8ODW265hTfeeIPQ0NAqx9UskhCA9DhYOgyyzoNnOxj/C9i5mToqUYmiEj3r/knmy7/PsDf+kmF/hJ8T43sFMayjD1oL8+ucQQgh6k+TSUIaq2aThACknYIlQyEnGbw7qE01tq6mjkpU0eFzmSz9+wy/HEykSKf2NXG3t+Lerv74OlljaW6mbhZmWJlrrnw2N8PZ1pJgdzujCdmEEKK2JAmppWaVhABcOKHWiOReAN/OMO4ndW4R0WSk5RSyYvdZvtoeT3JWQZWPM9NAoJsdoR72hHnZE+ZpT0tPe0I97GUWWCFEjUgSUkvNLgkBdd6QpcMgPx38usPYH0HrYOqoRDUV6/T8/k8Km46lkF+so1inp0inUFyip1inN3wuKtFxIbvQ0FG2PC2cbWjr60gnf2c6+jnRsYUzTraWVYqjsERHQloepy7kYqc1p1uQq9S4CNFMSBJSS80yCQFIOqSOlinIgIBeMGYlaO1NHZWoJ4qicCGnkNiUHE6m5hCbmsPJ1GxiU3O4mFNU7jHB7nZqQuLnTISfEwFutpxNz+NUai6nLuRc3nJJSM9Dd9WEKVoLM7oHu9KvlQd9W3kQ5mkv854IcYOSJKSWmm0SAnB+HywbAYVZ0KKrmohIH5Fm51JuEf+mZHP4fCYHz2Vy6FwG8WnVm5LeXmtBiIcdKVkFpGQVGn3n7WhNnzB3+rby4JaW7rjYXX++HyFE0yFJSC016yQE4Nxe+OZuyL8EHm1g7Cpw9DF1VMLELuUWceh8JofOZnDwXAYHz2VyIbuQFs42hHio/UpCPe0J9bCjpYc9Hg5aNBoNiqJwMjWHrf9eYOvJi+w8nUZhifGEbS62lng4aHG31+LhoMXDXov7Va8BrrYEu9uZ6M6FENUhSUgtNfskBCD1GHx1F2QnqVO7j10NblUf5ixufIqiUKxTsLKo3sytBcU6dsWl8+fJC2z99yInUipe1+lqLT3tGdremyEdfGjt7SDNOUI0UpKE1JIkIZddilebZi7FgZ2nWiPi3d7UUYkbTEZeESlZhVzILuRijvHrhcuvpy/kGoYgg9o3ZUh7b4Z28KGdr2OZhERRFC7mFHH6Qg5xF3M5fTGXpMwC3Oys8HW2xsfJxvDq6aDFQqbAF6LOSBJSS5KEXCU7Bb4eCSlH1GG7/1kJAT1MHZVoZrIKivnjWCq/Hk5iy78XKLqqOSfA1ZYhHbxx0Fpw+kIupy7mcvpCDtnXGflzNXMzDZ4OWnycrAnxsKd7kCs9QlwJcLWV2hYhakCSkFqSJOQa+RmwfBSc3QEWNjDqawiLNHVUopnKKSzhj+Op/HYoic0nUsv0Lyml0XC5v4o9Ie52tHC2IS23iKTMfBIz8knMKCAlq4ASffn/CfR2tObmEFd6hLjRI9hVVjIWoookCaklSULKUZQH/xsHsRvAzBJGfgLt7zZ1VKKZyy0sIebEBTYeS0GjgVAPe4Ld7QjxsCPIrfLZYHV6hYs5hSRm5JOUWcA/iZnsPJ3OwXMZFOuM/9Po4aClR7Arvs42WFuYobU0x9rSHGtLM6wtrrx3trWko5+zrHIsmi1JQmpJkpAKlBTB6kfhyA+ABga+Bt0fAQsZXiluLPlFOvYnXGLH6TR2xKVz4GyGURNQZRysLRgQ7klkWy/6h3vgaF21Sd6EuBFIElJLkoRch14Hv82APV+onx39oPeTcNNYsLQxbWxC1JOCYh0HzmawN/4SmfnFFBTrKCjWkV+sN7wvLNZTUKLj/KV80nKvTPZmaa7h5hA3Itt4EdnWixbOxv+eKIpCTmEJqdlqJ9zU7ELScgop0SkoKCgKKIBeUd+XHuNgbUnvlu6EekgzkWhcJAmpJUlCKqEosPsz2PqOuvAdqKNnej0OXR+SWVZFs6bXK+w/m8GGoylsPJZCbGqO0fftfB0JdLMlNavQkHjkF+tqfD1/VxsGhHsyINyTm0PcsLGq2vT4RSV6UrIKKLxqSv9inf7y5ytT/TtYW9Il0KXK5xVCkpBakiSkiooL4MDX8NcHkHlW3WfjAjdPhe4Pg42zKaMTolGIu5jLhqPJbDyayp74dCroB4u91gJPB61h0jYrCzM0ABrQoEGjAQ1cftWQmJnPztPpRkOXtRZm3BzixoBwDwa09sROa0FCeh5nL28Jl7ez6fkkZeZXGMu1LM01dA5woXeoO71buhHhL31eRMUkCaklSUKqSVcMh76DP9+F9NPqPq0jdJ+sNtVYyzMUAtTVjrf8e4HM/GI8HazxdNQaEg9bq+qvWpxbWML2U2lsPpFKzIkLnM/Ir9bxVhZm2FqZY2luhpW5GZbmGizNzdTNwgwrcw3nL+WTmGm8MrOdlTndg13p3dKdXqHuuDtYodMrlOgU9VWvvpZuBSU60nIKuZBTRFqOOg/Mxewi0nILuZhTxMWcQrQWZobVnFt62BPm5UBLT3s8L8+8K5oOSUJqSZKQGtLr4J9VajPNhWPqPs928MAPMu27EPWsdHr8zcdT2XwilT1nLqFTFHwcrfF3tSXg8uZ/eQtwtcXd3qrSH3hFUTiTlse22Iv8feoi20+lcSmvuIHuSu3k29LTnhB3ezQayCsqIa9IR16hjtyiEvKL1Ne8Qh0W5ho6+TvTNciVroEuRPg7y+rNJiBJSC1JElJLej2c+BV+fQZyUsApQJ1t1b2lqSMTotnIL9JhZgZai7r9EdbrFY4mZfH3qYtsi01j95l08op0WJprMDfTYGFmdvlVY3i1tDDDzc4KN/vL6wPZW+HuoMXNTou7vbo/v0hnWMX5ZGoOp1JzOJOWW+Umo/JYmmvo0MLJkJR0DXLF1c7KsORAkU5v6PtSpNNTVKJHAfxdbKu9HIG4QpKQWpIkpI5cOgNfjYT0U2Drps626tfF1FEJIeqQoij11lxSWKLjzMU8Yi8nJGYaDbZW5thamWOntcDGyhw7KwvDvuyCEvbGX2JPfDq7z1ziQnZhmXNammvKzAFzLStzM1r7ONC+hRMdLm+tvBwqTEwURSEzv5jEjAKSMvNJzirAwdqSQFdbAt1scbatfBoDvV7hfEY+J1Oz+Tclh5MpORSU6NTkzU6Lq70V7nZWuF5O5tzsrHCyscTMrPE1VUkSUkuShNSh3IvwzT2QuB8s7WDUMmgps60KIeqXoiicTc9n95l09sRfYs+ZdE5eM1KplLmZBktzDVbmZuj0CrlFZUcrWZmbEe6tJiYe9lYkZRaQlFlAYmY+SRkF1x3h5GhtQaCbHQFutkaJyZmLuWrCcbkGKK+c616PhZmGADdbWnk60MrLnlbeDrTyciDY3c6kHYclCaklSULqWGE2fDcWTm8GMwuIWgQd7zN1VEKIZiYzv5i8ohK1I65FaWdctfmoVGnycvh8JofPZ3Lk8mtmfuX9YNzsrPBxtsbb0ZrM/GLi0/JILac2piJW5maEeNgR5uVAmKc99loL0nOLSMtVO/SWvr+YU3jdtZEszDSG87TxdqBrkCudGrB/jCQhtSRJSD0oKYLVU+DI9+rnQW9Cz6mmjUkIIapAURTOXbqSmGTmF+PjaI2Psw2+Tuqrj5N1uT/y+UU6EtLziE/LvfyaR3x6HpdyiwhytyPM055WXupooEBX2yqv6FxUoudCTiGnUnP4NyWbkyk5nEjJ5mRKdvk1ORZmdPJ3pkewKz2C3bgp0LlGI7KqQpKQWpIkpJ7o9bD+Rdi5SP3c+0mInKNOfCCEEKLWFEUhMbOAf5Oz+Tclm0PnM9kVl16mf4yFmYYOfk50D3bl5mA3erd0r7POuJKE1JIkIfVIUeCv92HTHPVzm+EQehs4+4NzIDj5yfTvQghRhxRFIe5iLrvi0tkZl87O02lGc79YWZhx6NWBddZcI0lILUkS0gD2fw0/PwFKOR2x7DwvJyUB6hY2CIJ6N3yMQghxgzqbnnc5KUmjRKfw3qhOdXZuSUJqSZKQBhL/Nxz5UZ3yPSNB3YrK771O6zvUVXtdQxo2RiGEENVSnd9Qk87GsnXrVoYPH46vry8ajYbVq1dft3xMTAwajabMlpycbFTu448/JigoCGtra3r06MGuXbvq8S5EjQX2gmHvwH++g8e2w8xz8FwcTN4Co75WO69GjAaNORxfAx/3gA2zoCDL1JELIYSoAyZNQnJzc4mIiODjjz+u1nEnTpwgKSnJsHl6ehq+++6773j66ad59dVX2bdvHxEREQwaNIjU1NS6Dl/UNY0GbF3Bt5PaV6TnVLhrMUzZBiEDQFcE2z6EBTfB3i/VaeKFEEI0WY2mOUaj0bBq1SqioqIqLBMTE8OAAQO4dOkSzs7O5Zbp0aMH3bp1Y+HChQDo9Xr8/f15/PHHeeGFF6oUizTHNEKKAv+uV0fXpJ9S93l3gMHzIOgW08YmhBDCoMk0x9RUp06d8PHx4fbbb2fbtm2G/UVFRezdu5fIyCszcpqZmREZGcn27dsrPF9hYSFZWVlGm2hkNBoIHwyP7VCbabROkHwYlg6D7x6A2E1QUvVJgYQQQphek0pCfHx8WLx4MT/88AM//PAD/v7+9O/fn3379gFw8eJFdDodXl5eRsd5eXmV6TdytejoaJycnAybv79/vd6HqAULK7WZ5ol90HUiaMzg2C/w9UiYH6LOzHrgW8hNM3WkQgghKlE/06XVk/DwcMLDww2fe/XqxalTp3j//ff56quvanzemTNn8vTTTxs+Z2VlSSLS2Nm5wx3vQbeJsHOx2lSTkwLHflY3jRn494BWgyF8KLiHyaRoQgjRyDSpJKQ83bt356+//gLA3d0dc3NzUlJSjMqkpKTg7e1d4Tm0Wi1arbZe4xT1xKsd3LlAnY01aT+cWAcn1kLKYUjYrm4bX1XnHnHyA0ffK6+OLS5vvuDgo9ayCCGEaDBNPgk5cOAAPj4+AFhZWdGlSxc2bdpk6OCq1+vZtGkT06ZNM2GUot6ZmUGLLup260uQcRb+XaducVshN1XdEvdVcAINuIWCTwT4dLr82hFsXBryLoQQolkxaRKSk5NDbGys4XNcXBwHDhzA1dWVgIAAZs6cyfnz51m2bBkAH3zwAcHBwbRr146CggI+++wz/vjjD37//XfDOZ5++mnGjx9P165d6d69Ox988AG5ubk8+OCDDX5/woSc/aH7w+pWmANpsZB1HrIS1dfMq95nJYKuUC2TFgtHfrjqPIGXE5II8OsKgbeAeZPP3YUQolEw6X9N9+zZw4ABAwyfS/tljB8/nqVLl5KUlERCQoLh+6KiIp555hnOnz+Pra0tHTt2ZOPGjUbnGDVqFBcuXGDWrFkkJyfTqVMn1q1bV6azqmhGtPbq3CO+ncr/XlEgJxVSjkDSAUg6qG6XzkBGvLod+1kt6+ALN42Fm8apzTpCCCFqrNHME9KYyDwhAoD8S5B06HJScgBObYb8dPU7jRm0vB26Pqi+1kXtiF4PZ/5UE6L2I8GsbhaTEkKIhiRrx9SSJCGiXCWF6nDgvUvVZKFUbWtHshLhwDew7yu11gXUkT13LZa1coQQTY4kIbUkSYio1MVY2LcUDiyHvMtzkpQOC27RBXw7q5trSPlDg3UlcPJ32Pel+qro1f1aJ/V9UTZY2sHgN+Gm8TK8WAjRZEgSUkuShIgqKylUF9fbs8S4dqSUtdOVhMS3MzgHwNGf1eQl56oJ9AJ7qzUpbe6E3AuwegrEX54NuNVgdRiyvWfZ8wshRCMjSUgtSRIiaiQ9Tp2XJHE/nN+nTiuvu85U8rbu0Ok/avLhHmb8nV4H2z+GP15TF+6zdYPhH0GbO+r3HoQQopYkCaklSUJEndAVQ+oxdW6SxP3qlnYKAnqqiUerwZVPkJbyD/w4WR25A9DpARgcDdbydymEaJwkCaklSUJEo1JSCJvfhG0fAorapDP0HXVUjlmTWv5JCNEM3PCr6ArRrFho4fY58OBvagKSkQDL74OFXeDvhZCXbuoIhRCiRqQmpBxSEyIarYIs2PIW7FsGhVnqPgtr6HAPdJukdn4VQggTkuaYWpIkRDR6hTlweCXs/uxKfxGAFl3VZKTdXWoNSkEG5F5UR9zkpKqvuRfVdXRsXNW+KS6BJrsNIcSNR5KQWpIkRDQZigJnd8Ku/8LRn0BfrO63tFU7xpZ+rojGDFoPg5sfUzvMynwkQohakiSkliQJEU1STqo6+dmepZB17sp+rRPYuYOdB9h7qK+27nBuN5zefKWcT4SajJTWolREr4P00+oQ5Ix49TMKKFx+Va56BbQOal8WZ39wCgBbV0l2hLiBSRJSS5KEiCZNVwJpJ9Uff1t3sLSuuGzKUdi5GA59ByUF6j57L+g6Ebo+BJY2kHoUkg9B8hE18Ug9CsV5NY/P0u5yQuKvJieOvpdnic1Vz1uUe2Ur/azo1UTK9nIyZed2JZkq/ewcKOvtCNEISBJSS5KEiGYnN02dhn7XfyE7Sd1nZnGlluNaFjbg1RbcwsDc8nLNhqbsK6gLAWaeVUf15KTU3z04B0C/56Hj/XWzoKAQokYkCaklSUJEs6UrVvuW7Pg/OL9X3efgA17twbs9eHcArw7gFlqzWofiAsg8B5kJalKScVZdwM/cEqzs1M3Stux7UNfoKe1km5d2uZPtBTWBykm5Mjutayj0nykrEQthIpKE1JIkIUKg9vvQOqrNII1dUZ46UmjbB1cWFPRoDQNehNbDazepm6KoyVlJPpQUqX1aJLkRokKShNSSJCFCNFGF2bDzE/j7IyjIVPd5d4ABL0OrQWozkaKoE7xlnIFL8XDpjNrB9lK8WtNSkq/W2Fz9WrrKMYCNCwT3heB+ENK/4pWSSykKXDgOcX/Cma0Qvx0cvCFyDoRF1uPDEMI0JAmpJUlChGji8jPUJqXt/wdF2eo+z3ZqsnAp/sq+uuAUACF9IWSAmpzYeUBaLMRtVVdWPvOX2mxUnvChMOhNcA2uu3iEMDFJQmpJkhAhbhB56eqaO7s+LTuix8FHHVHjEnj5NUgdGWRpo44osrC5/N5GnZXW0kadVyVxP5yOUbezu8rOxWLjonbGvZqFDQT0gKBbIKAXnPhNHZWkLwFzLfR+Am55Gqxs6/FhCNEwJAmpJUlChLjB5KTCqT/A9vJQXmd/NamoraJctXnl9GY4vQVSDqv7za3ArzsE91FrR1p0KTv3yoUTsPY5NZkBcPSDQa9D2yiZR0U0aZKE1JIkIUKIGsm5oI768WpbtSRHUeDYL7D+JXXEEKhJy5D54NmmfmOtjK5YnY03/5Lar8Y5UJIjUSWShNSSJCFCiAZVlKc2G237QJ00TmOuLkbo2Ro826oJiWdbtbmookSgtMNt5ll1GHTWebB2Au+O4N6qanOn5KZB7Eb4dx3EboLCzCvf2biATyfw7XT5tbM6N8u18ZQUqWsT5aRAdor6WpQDTn5qk5dLMNg41+QpXV9xvrrZutb9uUW1SBJSS5KECCFM4tIZtVbk+Jryv7dxAY82alJi76nOsVKadGSeq3gmW3OtWjvj3UFNSnwi1KTGyk6dAfffdfDvenUq/6tHAtm6qTPaph4vfx0iGxf1XIqiNnnlJJftD1Mea2e1M65L0JXExMEbrOzVmLQOl+eKsVfniikdYl2cD+lxkH5KHUKedvk1/bSadAE4+EKLm9QkqfTVxqXymESdkSSkliQJEUKYVNopdar81ONqkpB6TP3hvTpBqIidp9rnxdFXHXKcfKSC0UCay51o0413e3VQhzO3Gqz+iJuZQ0mhGkfiAbVjbtIBdcr/ihZINLNQa23sPcHeW+1wm3FWTbJyU6v3LNCoCYmF9socMNXlGgK+N6n349hCjc+wmRt/NrdUn4utm3rd+mqCUpQbtnlLkpBakiRECNHoFBfAxX/VOUdSj6oJhpPf5c1ffXVsUXatIL0eLsWp6/4kH1Jfkw6ptRagjvwJ6a8mHmED1fNURUkhpPwDKUfUjrj2Xlc2G5eKJ4grzFHnZUmPU5OSS3Hq+7y0y2sG5Vx5LS/psnZSZ8V1C1WTC9fLr26hahzJh+D8Pkjcp75eiqvqEy7LXHt5zSJXNSmxdb9cO+RzpUbKyb/yyfAUBS6ehLM7IGGn+pp+Wh3O7dgCnFqoHZOdWlz+fPmfpcYMshMhK0ldTiEr0fg1Lw1adIVO/4HwIddfeLIBSRJSS5KECCFueDmpau2EZ5vGOTRYUdTml9KEpDhPHVZd3T4feelq7U3iPrUmJz9DHRqtL778qrv8WqJ2xtUVqceULgNQGSt7dXbe0n47nm3UPjgZ8ZCwQx3GfXZn2RqnumbjAh3uVRMSn04mrWVpMknI1q1befvtt9m7dy9JSUmsWrWKqKioCsv/+OOPLFq0iAMHDlBYWEi7du2YPXs2gwYNMpSZPXs2c+bMMTouPDyc48ePVzkuSUKEEKIZUxQ16SldrygvXX2flwZ5F9URUKnH1JopXVHVzmlhrQ7V9u8BATerCUveRcg8r/ZnKe1MXPo5KxFQ1JolR181Abv21cpO7T90cMWVhSdBPXen/0CH+8DBq14e0fVU5zfUpEtN5ubmEhERwUMPPcTIkSMrLb9161Zuv/123nzzTZydnVmyZAnDhw9n586ddO7c2VCuXbt2bNy40fDZwkJW1BRCCFFFGs2VRRSdAyoupytWm1VK++0Y+u+cVptuAnqA/81q0uHdESysjI939lc7zpZHr1NfK1unyK8r3PqKOlfNgeVwbI0ax+8vw4ZXIbDX5f4t9lfu6dpN6whht1f9+dShRtMco9FoKq0JKU+7du0YNWoUs2bNAtSakNWrV3PgwIEaxyI1IUIIIWpMV6x2cjVFk0h+Bvzzo5qQnNtdtWO0jjDzbJ2F0GRqQmpLr9eTnZ2Nq6txG+HJkyfx9fXF2tqanj17Eh0dTUBAxdlsYWEhhYVX2v+ysrLqLWYhhBA3OHNL013bxhm6PqRuF/6Fc7su96u5aiu+5rOFdaWnrS9NOgl55513yMnJ4b777jPs69GjB0uXLiU8PJykpCTmzJlDnz59OHLkCA4ODuWeJzo6ukw/EiGEEKJJ82ilbo1Yk22OWb58OQ8//DA//fQTkZEVL4edkZFBYGAg7733HhMnTiy3THk1If7+/tIcI4QQQlTTDd8cs2LFCiZNmsTKlSuvm4AAODs706pVK2JjYysso9Vq0Wobx/hqIYQQormoZIaVxufbb7/lwQcf5Ntvv2XYsGGVls/JyeHUqVP4+Pg0QHRCCCGEqCqT1oTk5OQY1VDExcVx4MABXF1dCQgIYObMmZw/f55ly5YBahPM+PHj+fDDD+nRowfJyeqMfzY2Njg5OQEwY8YMhg8fTmBgIImJibz66quYm5szevTohr9BIYQQQlTIpDUhe/bsoXPnzoY5Pp5++mk6d+5sGG6blJREQkKCofynn35KSUkJU6dOxcfHx7A9+eSThjLnzp1j9OjRhIeHc9999+Hm5saOHTvw8PBo2JsTQgghxHU1mo6pjYnMEyKEEELUTHV+Q5tcnxAhhBBC3BgkCRFCCCGESUgSIoQQQgiTkCRECCGEECYhSYgQQgghTKJJzpha30oHDMlCdkIIIUT1lP52VmXwrSQh5cjOzgbA39/fxJEIIYQQTVN2drZhItGKyDwh5dDr9SQmJuLg4IBGo6mTc5Yuinf27FmZe6QOyXOtP/Js64c81/ohz7X+VPfZKopCdnY2vr6+mJldv9eH1ISUw8zMDD8/v3o5t6Ojo/wLUg/kudYfebb1Q55r/ZDnWn+q82wrqwEpJR1ThRBCCGESkoQIIYQQwiQkCWkgWq2WV199Fa1Wa+pQbijyXOuPPNv6Ic+1fshzrT/1+WylY6oQQgghTEJqQoQQQghhEpKECCGEEMIkJAkRQgghhElIEiKEEEIIk5AkpIF8/PHHBAUFYW1tTY8ePdi1a5epQ2pStm7dyvDhw/H19UWj0bB69Wqj7xVFYdasWfj4+GBjY0NkZCQnT540TbBNSHR0NN26dcPBwQFPT0+ioqI4ceKEUZmCggKmTp2Km5sb9vb23H333aSkpJgo4qZh0aJFdOzY0TC5U8+ePVm7dq3he3mmdWPevHloNBqmT59u2CfPtmZmz56NRqMx2lq3bm34vr6eqyQhDeC7777j6aef5tVXX2Xfvn1EREQwaNAgUlNTTR1ak5Gbm0tERAQff/xxud/Pnz+fjz76iMWLF7Nz507s7OwYNGgQBQUFDRxp07JlyxamTp3Kjh072LBhA8XFxQwcOJDc3FxDmaeeeopffvmFlStXsmXLFhITExk5cqQJo278/Pz8mDdvHnv37mXPnj3ceuutjBgxgn/++QeQZ1oXdu/ezSeffELHjh2N9suzrbl27dqRlJRk2P766y/Dd/X2XBVR77p3765MnTrV8Fmn0ym+vr5KdHS0CaNqugBl1apVhs96vV7x9vZW3n77bcO+jIwMRavVKt9++60JImy6UlNTFUDZsmWLoijqc7S0tFRWrlxpKHPs2DEFULZv326qMJskFxcX5bPPPpNnWgeys7OVsLAwZcOGDUq/fv2UJ598UlEU+XutjVdffVWJiIgo97v6fK5SE1LPioqK2Lt3L5GRkYZ9ZmZmREZGsn37dhNGduOIi4sjOTnZ6Bk7OTnRo0cPecbVlJmZCYCrqysAe/fupbi42OjZtm7dmoCAAHm2VaTT6VixYgW5ubn07NlTnmkdmDp1KsOGDTN6hiB/r7V18uRJfH19CQkJYcyYMSQkJAD1+1xlAbt6dvHiRXQ6HV5eXkb7vby8OH78uImiurEkJycDlPuMS78TldPr9UyfPp3evXvTvn17QH22VlZWODs7G5WVZ1u5w4cP07NnTwoKCrC3t2fVqlW0bduWAwcOyDOthRUrVrBv3z52795d5jv5e625Hj16sHTpUsLDw0lKSmLOnDn06dOHI0eO1OtzlSRECAGo/3d55MgRo3ZgUXPh4eEcOHCAzMxMvv/+e8aPH8+WLVtMHVaTdvbsWZ588kk2bNiAtbW1qcO5oQwZMsTwvmPHjvTo0YPAwED+97//YWNjU2/XleaYeubu7o65uXmZXsQpKSl4e3ubKKobS+lzlGdcc9OmTWPNmjVs3rwZPz8/w35vb2+KiorIyMgwKi/PtnJWVla0bNmSLl26EB0dTUREBB9++KE801rYu3cvqamp3HTTTVhYWGBhYcGWLVv46KOPsLCwwMvLS55tHXF2dqZVq1bExsbW69+sJCH1zMrKii5durBp0ybDPr1ez6ZNm+jZs6cJI7txBAcH4+3tbfSMs7Ky2LlzpzzjSiiKwrRp01i1ahV//PEHwcHBRt936dIFS0tLo2d74sQJEhIS5NlWk16vp7CwUJ5pLdx2220cPnyYAwcOGLauXbsyZswYw3t5tnUjJyeHU6dO4ePjU79/s7Xq1iqqZMWKFYpWq1WWLl2qHD16VJk8ebLi7OysJCcnmzq0JiM7O1vZv3+/sn//fgVQ3nvvPWX//v1KfHy8oiiKMm/ePMXZ2Vn56aeflEOHDikjRoxQgoODlfz8fBNH3rhNmTJFcXJyUmJiYpSkpCTDlpeXZyjz6KOPKgEBAcoff/yh7NmzR+nZs6fSs2dPE0bd+L3wwgvKli1blLi4OOXQoUPKCy+8oGg0GuX3339XFEWeaV26enSMosizralnnnlGiYmJUeLi4pRt27YpkZGRiru7u5KamqooSv09V0lCGsiCBQuUgIAAxcrKSunevbuyY8cOU4fUpGzevFkBymzjx49XFEUdpvvKK68oXl5eilarVW677TblxIkTpg26CSjvmQLKkiVLDGXy8/OVxx57THFxcVFsbW2Vu+66S0lKSjJd0E3AQw89pAQGBipWVlaKh4eHcttttxkSEEWRZ1qXrk1C5NnWzKhRoxQfHx/FyspKadGihTJq1CglNjbW8H19PVeNoihK7epShBBCCCGqT/qECCGEEMIkJAkRQgghhElIEiKEEEIIk5AkRAghhBAmIUmIEEIIIUxCkhAhhBBCmIQkIUIIIYQwCUlChBBCCGESkoQIIZoNjUbD6tWrTR2GEOIySUKEEA1iwoQJaDSaMtvgwYNNHZoQwkQsTB2AEKL5GDx4MEuWLDHap9VqTRSNEMLUpCZECNFgtFot3t7eRpuLiwugNpUsWrSIIUOGYGNjQ0hICN9//73R8YcPH+bWW2/FxsYGNzc3Jk+eTE5OjlGZL774gnbt2qHVavHx8WHatGlG31+8eJG77roLW1tbwsLC+Pnnn+v3poUQFZIkRAjRaLzyyivcfffdHDx4kDFjxnD//fdz7NgxAHJzcxk0aBAuLi7s3r2blStXsnHjRqMkY9GiRUydOpXJkydz+PBhfv75Z1q2bGl0jTlz5nDfffdx6NAhhg4dypgxY0hPT2/Q+xRCXFbrdXiFEKIKxo8fr5ibmyt2dnZG2xtvvKEoiqIAyqOPPmp0TI8ePZQpU6YoiqIon376qeLi4qLk5OQYvv/1118VMzMzJTk5WVEURfH19VVeeumlCmMAlJdfftnwOScnRwGUtWvX1tl9CiGqTvqECCEazIABA1i0aJHRPldXV8P7nj17Gn3Xs2dPDhw4AMCxY8eIiIjAzs7O8H3v3r3R6/WcOHECjUZDYmIit91223Vj6Nixo+G9nZ0djo6OpKam1vSWhBC1IEmIEKLB2NnZlWkeqSs2NjZVKmdpaWn0WaPRoNfr6yMkIUQlpE+IEKLR2LFjR5nPbdq0AaBNmzYcPHiQ3Nxcw/fbtm3DzMyM8PBwHBwcCAoKYtOmTQ0asxCi5qQmRAjRYAoLC0lOTjbaZ2Fhgbu7OwArV66ka9eu3HLLLXzzzTfs2rWLzz//HIAxY8bw6quvMn78eGbPns2FCxd4/PHHGTt2LF5eXgDMnj2bRx99FE9PT4YMGUJ2djbbtm3j8ccfb9gbFUJUiSQhQogGs27dOnx8fIz2hYeHc/z4cUAdubJixQoee+wxfHx8+Pbbb2nbti0Atra2rF+/nieffJJu3bpha2vL3XffzXvvvWc41/jx4ykoKOD9999nxowZuLu7c8899zTcDQohqkWjKIpi6iCEEEKj0bBq1SqioqJMHYoQooFInxAhhBBCmIQkIUIIIYQwCekTIoRoFKRlWIjmR2pChBBCCGESkoQIIYQQwiQkCRFCCCGESUgSIoQQQgiTkCRECCGEECYhSYgQQgghTEKSECGEEEKYhCQhQgghhDCJ/wdpj5rmoDDW9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(best_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(best_history.history['loss'], label='Training Loss')\n",
    "plt.plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cA7qrcgzSsiK",
    "outputId": "4ff2a0ae-1c02-4176-851b-ed8f6ead33d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 1.3261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3242542743682861, 0.5914999842643738]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
